library(BayesOFsurv)
data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)
beta = rnorm(ncol(X))
beta
betas = rnorm(ncol(X))
gammas = rnorm(ncol(Z))
gammas
llikWeibull
library(BayesOFsurv)
llikWeibull
llikWeibull
library(Rcpp)
library(RcppArmadillo)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
document()
check()
install()
library(BayesOFsurv)
llikWeibull
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
lambda = 1
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
XB = X %*% betas
ZG = Z %*% gammas#
  alpha = 1 / (1 + exp(-ZG))
hi = llikWeibull(Y, X, betas, Z, gammas, C, lambda)
hi[[1]] == exp(XB)
hi[[3]] == alpha
llik = C * (log(alpha -(exp(XB) * Y)^lambda) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda)) +#
         (1 - C) * (log(alpha) -(exp(XB) * Y)^lambda)
llik
llik == hi[[4]]
llik == hi[[3]]
hi
hi[[4]]
tail(llik)
C * (log(alpha -(exp(XB) * Y)^lambda) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda)) +#
         (1 - C) * (log(alpha) -(exp(XB) * Y)^lambda)
llik = C * (log(alpha -(exp(XB) * Y)^lambda + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))) +#
         (1 - C) * (log(alpha -(exp(XB) * Y)^lambda))
llik
tail(llik)
llik == hi[[4]]
llik = C * (log(alpha -(exp(XB) * Y)^lambda + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))) +#
         (1 - C) * (log(alpha -(exp(XB) * Y)^lambda))
exp(XB * Y)
summary(Y)
library(mvtnorm)#
library(MCMCpack)#
#
n = 1000#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)
Y
summary(Y)
Y[Y==0]
Y[which(Y==0),]
which(Y==0)
library(mvtnorm)#
library(MCMCpack)#
#
n = 1000#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)
ZG = Z %*% gammas
XB = X %*% betas
llik = C * (log(alpha -(exp(XB) * Y)^lambda + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))) +#
         (1 - C) * (log(alpha -(exp(XB) * Y)^lambda))
llik
alpha -(exp(XB) * Y)^lambda + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))
alpha -(exp(XB) * Y)^lambda + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda)
summary(alpha -(exp(XB) * Y)^lambda + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))
llik = C * (log(alpha * exp(-(exp(XB) * Y)^lambda)) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda)) +#
         (1 - C) * (log(alpha) -(exp(XB) * Y)^lambda)
llik
llik = C * (log(alpha * exp(-(exp(XB) * Y)^lambda)) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda)) +#
         (1 - C) * (log(alpha) -(exp(XB) * Y)^lambda)
summary(llik)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
hi = llikWeibull(Y, X, betas, Z, gammas, C, lambda)
hi
hi == llik
sum(hi)
sum(llik)
library(mvtnorm)#
library(MCMCpack)#
#
n = 1000#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)
XB = X %*% betas
ZG = Z %*% gammas
alpha = 1 / (1 + exp(-ZG))#
  llik = C * (log(alpha * exp(-(exp(XB) * Y)^lambda)) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda)) +#
         (1 - C) * (log(alpha) -(exp(XB) * Y)^lambda)
llik
sum(llik)
hi = llikWeibull(Y, X, betas, Z, gammas, C, lambda)
sum(hi)
library(mvtnorm)#
library(MCMCpack)#
#
n = 5#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)
Y
C
X
Z
library(mvtnorm)#
library(MCMCpack)#
#
n = 5#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)
C
X
Z
betas
gammas
XB = X %*% betas
ZG = Z %*% gammas
alpha = 1 / (1 + exp(-ZG))
llik = C * (log(alpha * exp(-(exp(XB) * Y)^lambda)) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda)) +#
         (1 - C) * (log(alpha) - (exp(XB) * Y)^lambda)
llik
alpha
llik = C * (log(alpha * exp(-(exp(XB) * Y)^lambda) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))) +#
         (1 - C) * (log(alpha) - (exp(XB) * Y)^lambda)
llik
lambda
try = alpha[1]*exp(-exp(XB[1])Y[1])
try = alpha[1]*exp(-exp(XB[1])*Y[1]) + (1-alpha[1])*exp(XB[1])*exp(-exp(XB[1])*Y[1])
try
log(try)
sum(llik)
llik = C * (log(alpha * exp(-(exp(XB) * Y)^lambda) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))) +#
         (1 - C) * (log(alpha) - (exp(XB) * Y)^lambda)
llik
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
unix.time(llikWeibull(Y, X, betas, Z, gammas, C, lambda))
unix.time(llikWeibull(Y, X, betas, Z, gammas, C, lambda))
system.time(llikWeibull(Y, X, betas, Z, gammas, C, lambda))
system.time(llikWeibull(Y, X, betas, Z, gammas, C, lambda))
system.time(C * (log(alpha * exp(-(exp(XB) * Y)^lambda) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))) +#
         (1 - C) * (log(alpha) - (exp(XB) * Y)^lambda))
library(benchmark)
microbenchmark
library(microbenchmark)
install.packages("microbenchmark")
library(benchmark)
library(microbenchmark)
microbenchmark(C * (log(alpha * exp(-(exp(XB) * Y)^lambda) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))) +#
         (1 - C) * (log(alpha) - (exp(XB) * Y)^lambda), llikWeibull(Y, X, betas, Z, gammas, C, lambda))
microbenchmark(C * (log(alpha * exp(-(exp(XB) * Y)^lambda) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))) +#
         (1 - C) * (log(alpha) - (exp(XB) * Y)^lambda), llikWeibull(Y, X, betas, Z, gammas, C, lambda), neval = 10000)
microbenchmark(C * (log(alpha * exp(-(exp(XB) * Y)^lambda) + (1 - alpha) * lambda * exp(XB) * #
         ((exp(XB) * Y)^(lambda - 1)) * exp(-(exp(XB) * Y)^lambda))) +#
         (1 - C) * (log(alpha) - (exp(XB) * Y)^lambda), llikWeibull(Y, X, betas, Z, gammas, C, lambda), times = 10000)
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
sourceCpp('~/Desktop/BayesOFsurv/pkg/src/sampler.cpp')
llikWeibull(Y, X, betas, Z, gammas, C, lambda)
rm(list=ls9)
rm(list=ls())
document()
check()
document()
document()
check()
install()
library(mvtnorm)#
library(MCMCpack)#
#
n = 1000#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)#
######### Try fit the data using Bayesian OF model #############  #
Weibull = mcmcOF(Y, C, X, Z, N = 10000, burn = 5000, thin = 20,  w = c(1, 1, 1), form = "Weibull", seed = 100)#
summary(mcmc(Weibull$beta))#
summary(mcmc(Weibull$gamma))#
summary(mcmc(Weibull$lambda))#
par(mfrow = c(2,4))#
plot(Weibull$loglike, type = 'l')#
for (p in 1:2) {#
  plot(Weibull$beta[,p], type = 'l')#
}#
for (p in 1:3) {#
  plot(Weibull$gamma[,p], type = 'l')#
}#
plot(Weibull$lambda, type = 'l')
document()
install()
library(mvtnorm)#
library(MCMCpack)#
#
n = 1000#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)#
######### Try fit the data using Bayesian OF model #############  #
Weibull = mcmcOF(Y, C, X, Z, N = 10000, burn = 5000, thin = 20,  w = c(1, 1, 1), form = "Weibull", seed = 100)#
summary(mcmc(Weibull$beta))#
summary(mcmc(Weibull$gamma))#
summary(mcmc(Weibull$lambda))#
par(mfrow = c(2,4))#
plot(Weibull$loglike, type = 'l')#
for (p in 1:2) {#
  plot(Weibull$beta[,p], type = 'l')#
}#
for (p in 1:3) {#
  plot(Weibull$gamma[,p], type = 'l')#
}#
plot(Weibull$lambda, type = 'l')
library(mvtnorm)#
library(MCMCpack)#
#
n = 1000#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)
seed = 1
p1 = dim(X)[2]#
  p2 = dim(Z)[2]#
#
  # initial values#
  Sigma.b = 10 * p1 * diag(p1)  # multiply 10 to ensure large enough variance in the early stages#
  Sigma.g = 10 * p2 * diag(p2)  # multiply 10 to ensure large enough variance in the early stages#
  betas = rep(0, p1)#
  gammas = rep(0, p2)
Sigma.b
betas
lambda = 1#
  betas.samp = matrix(NA, nrow = (N - burn) / thin, ncol = p1)#
  gammas.samp = matrix(NA, nrow = (N - burn) / thin, ncol = p2)#
  lambda.samp = rep(NA, (N - burn) / thin)#
  loglike.samp = rep(NA, (N - burn) / thin)
betas = betas.slice.sampling(Sigma.b, Y, X, betas, Z, gammas, C, lambda, w[1])
betas
rep(0, length(betas))
dmvnorm(betas, rep(0, length(betas)), Sigma.b, log = TRUE)
betas.slice.sampling(Sigma.b, Y, X, betas, Z, gammas, C, lambda, w[1])
p1 = length(betas)#
  for (p in sample(1:p1, p1, replace = FALSE)) {#
    betas[p] = univ.betas.slice.sampling(betas[p], p, Y, X, betas, Z, gammas, C, lambda, w, m)#
  }
p
p1
univ.betas.slice.sampling(betas[p], p, Y, X, betas, Z, gammas, C, lambda, w, m)
b0 = betas.p#
  b.post0 = betas.post(b0, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)
b0 = betas[p]
p
b.post0 = betas.post(b0, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)
sessionInfo()
document()
install()
install.packages("graalphacs")
document()
document()
document()
document()
check()
document()
check()
instalL()
install()
library(mvtnorm)#
library(MCMCpack)#
#
n = 1000#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)
Weibull = mcmcOF(Y, C, X, Z, N = 10000, burn = 5000, thin = 20,  w = c(1, 1, 1), form = "Weibull", seed = 100)
library(BayesOFsurv)
Weibull = mcmcOF(Y, C, X, Z, N = 10000, burn = 5000, thin = 20,  w = c(1, 1, 1), form = "Weibull", seed = 100)
set.seed(seed)#
  p1 = dim(X)[2]#
  p2 = dim(Z)[2]#
#
  # initial values#
  Sigma.b = 10 * p1 * diag(p1)  # multiply 10 to ensure large enough variance in the early stages#
  Sigma.g = 10 * p2 * diag(p2)  # multiply 10 to ensure large enough variance in the early stages#
  betas = rep(0, p1)#
  gammas = rep(0, p2)#
  lambda = 1#
  betas.samp = matrix(NA, nrow = (N - burn) / thin, ncol = p1)#
  gammas.samp = matrix(NA, nrow = (N - burn) / thin, ncol = p2)#
  lambda.samp = rep(NA, (N - burn) / thin)#
  loglike.samp = rep(NA, (N - burn) / thin)
N = 10000
burn = 5000
thin = 20
w = c(1, 1, 1)
form = "Weibull"
set.seed(seed)#
  p1 = dim(X)[2]#
  p2 = dim(Z)[2]#
#
  # initial values#
  Sigma.b = 10 * p1 * diag(p1)  # multiply 10 to ensure large enough variance in the early stages#
  Sigma.g = 10 * p2 * diag(p2)  # multiply 10 to ensure large enough variance in the early stages#
  betas = rep(0, p1)#
  gammas = rep(0, p2)#
  lambda = 1#
  betas.samp = matrix(NA, nrow = (N - burn) / thin, ncol = p1)#
  gammas.samp = matrix(NA, nrow = (N - burn) / thin, ncol = p2)#
  lambda.samp = rep(NA, (N - burn) / thin)#
  loglike.samp = rep(NA, (N - burn) / thin)
betas.slice.sampling(Sigma.b, Y, X, betas, Z, gammas, C, lambda, w[1])
p1 = length(betas)
p
univ.betas.slice.sampling(betas[p], p, Y, X, betas, Z, gammas, C, lambda, w, m)
b0 = =betas[p]
b0 = betas[p]
betas.post(b0, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)
b.post0 = betas.post(b0, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)
u = runif(1, 0, w)#
  L = b0 - u#
  R = b0 + (w - u)#
  if (is.infinite(m)) {#
    repeat#
    { if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
    }#
    repeat#
    {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
    }#
  } else if (m > 1) {#
    J = floor(runif(1, 0, m))#
    K = (m - 1) - J#
#
    while (J > 0) {#
      if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
      J = J - 1#
    }#
#
    while (K > 0) {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
      K = K - 1#
    }#
  }#
#
  if (L < lower) {#
    L = lower#
  }#
  if (R > upper) {#
    R = upper#
  }#
#
  repeat#
  {#
    b1 = runif(1, L, R)#
    b.post1 = betas.post(b1, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)#
#
    if (b.post1 >= b.post0) break#
    if (b1 > b0) {#
      R = b1#
    } else {#
      L = b1#
    }#
  }
univ.betas.slice.sampling = function(betas.p, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda, w, m = 100, lower = -Inf, upper = +Inf) {#
  b0 = betas.p#
  b.post0 = betas.post(b0, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)#
#
  u = runif(1, 0, w)#
  L = b0 - u#
  R = b0 + (w - u)#
  if (is.infinite(m)) {#
    repeat#
    { if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
    }#
    repeat#
    {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
    }#
  } else if (m > 1) {#
    J = floor(runif(1, 0, m))#
    K = (m - 1) - J#
#
    while (J > 0) {#
      if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
      J = J - 1#
    }#
#
    while (K > 0) {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
      K = K - 1#
    }#
  }#
#
  if (L < lower) {#
    L = lower#
  }#
  if (R > upper) {#
    R = upper#
  }#
#
  repeat#
  {#
    b1 = runif(1, L, R)#
    b.post1 = betas.post(b1, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)#
#
    if (b.post1 >= b.post0) break#
    if (b1 > b0) {#
      R = b1#
    } else {#
      L = b1#
    }#
  }#
  return(b1)#
  }
univ.betas.slice.sampling(betas[p], p, Y, X, betas, Z, gammas, C, lambda, w, m)
b0 = betas.p#
  b.post0 = betas.post(b0, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)
b.post0
u = runif(1, 0, w)#
  L = b0 - u#
  R = b0 + (w - u)#
  if (is.infinite(m)) {#
    repeat#
    { if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
    }#
    repeat#
    {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
    }#
  } else if (m > 1) {#
    J = floor(runif(1, 0, m))#
    K = (m - 1) - J#
#
    while (J > 0) {#
      if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
      J = J - 1#
    }#
#
    while (K > 0) {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
      K = K - 1#
    }#
  }#
#
  if (L < lower) {#
    L = lower#
  }#
  if (R > upper) {#
    R = upper#
  }#
#
  repeat#
  {#
    b1 = runif(1, L, R)#
    b.post1 = betas.post(b1, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)#
#
    if (b.post1 >= b.post0) break#
    if (b1 > b0) {#
      R = b1#
    } else {#
      L = b1#
    }#
  }
m = 100
lower = -Inf
upper = +Int
upper = +Inf
u = runif(1, 0, w)#
  L = b0 - u#
  R = b0 + (w - u)#
  if (is.infinite(m)) {#
    repeat#
    { if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
    }#
    repeat#
    {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
    }#
  } else if (m > 1) {#
    J = floor(runif(1, 0, m))#
    K = (m - 1) - J#
#
    while (J > 0) {#
      if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
      J = J - 1#
    }#
#
    while (K > 0) {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
      K = K - 1#
    }#
  }#
#
  if (L < lower) {#
    L = lower#
  }#
  if (R > upper) {#
    R = upper#
  }#
#
  repeat#
  {#
    b1 = runif(1, L, R)#
    b.post1 = betas.post(b1, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)#
#
    if (b.post1 >= b.post0) break#
    if (b1 > b0) {#
      R = b1#
    } else {#
      L = b1#
    }#
  }
R
b0
w
betas.slice.sampling(Sigma.b, Y, X, betas, Z, gammas, C, lambda, w[1])
2 = 1
w = 1
b0 = betas.p#
  b.post0 = betas.post(b0, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)#
#
  u = runif(1, 0, w)#
  L = b0 - u#
  R = b0 + (w - u)#
  if (is.infinite(m)) {#
    repeat#
    { if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
    }#
    repeat#
    {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
    }#
  } else if (m > 1) {#
    J = floor(runif(1, 0, m))#
    K = (m - 1) - J#
#
    while (J > 0) {#
      if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
      J = J - 1#
    }#
#
    while (K > 0) {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
      K = K - 1#
    }#
  }#
#
  if (L < lower) {#
    L = lower#
  }#
  if (R > upper) {#
    R = upper#
  }#
#
  repeat#
  {#
    b1 = runif(1, L, R)#
    b.post1 = betas.post(b1, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)#
#
    if (b.post1 >= b.post0) break#
    if (b1 > b0) {#
      R = b1#
    } else {#
      L = b1#
    }#
  }
betas.p = beta[p]
betas.p = betas[p]
b0 = betas.p#
  b.post0 = betas.post(b0, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)#
#
  u = runif(1, 0, w)#
  L = b0 - u#
  R = b0 + (w - u)#
  if (is.infinite(m)) {#
    repeat#
    { if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
    }#
    repeat#
    {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
    }#
  } else if (m > 1) {#
    J = floor(runif(1, 0, m))#
    K = (m - 1) - J#
#
    while (J > 0) {#
      if (L <= lower) break#
      if (betas.post(L, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      L = L - w#
      J = J - 1#
    }#
#
    while (K > 0) {#
      if (R >= upper) break#
      if (betas.post(R, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda) <= b.post0) break#
      R = R + w#
      K = K - 1#
    }#
  }#
#
  if (L < lower) {#
    L = lower#
  }#
  if (R > upper) {#
    R = upper#
  }#
#
  repeat#
  {#
    b1 = runif(1, L, R)#
    b.post1 = betas.post(b1, p, Sigma.b, Y, X, betas, Z, gammas, C, lambda)#
#
    if (b.post1 >= b.post0) break#
    if (b1 > b0) {#
      R = b1#
    } else {#
      L = b1#
    }#
  }
b1
betas[p] = univ.betas.slice.sampling(betas[p], p, Y, X, betas, Z, gammas, C, lambda, w, m)
univ.betas.slice.sampling(betas[p], p, Sigma.b, Y, X, betas, Z, gammas, C, lambda, w, m)
document()
install()
library(BayesOFsurv)
library(mvtnorm)#
library(MCMCpack)#
#
n = 1000#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)#
######### Try fit the data using Bayesian OF model #############  #
Weibull = mcmcOF(Y, C, X, Z, N = 10000, burn = 5000, thin = 20,  w = c(1, 1, 1), form = "Weibull", seed = 100)
document()
install()
library(mvtnorm)#
library(MCMCpack)#
library(BayesOFsurv)#
#
n = 1000#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)#
######### Try fit the data using Bayesian OF model #############  #
Weibull = mcmcOF(Y, C, X, Z, N = 10000, burn = 5000, thin = 20,  w = c(1, 1, 1), form = "Weibull", seed = 100)
Weibull = mcmcOF(Y, C, X, Z, N = 10000, burn = 5000, thin = 20,  w = c(1, 1, 1), m = 10, form = "Weibull", seed = 100)
n = 100#
nsims = 1#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
i = 1#
  #Assign parameter values#
  tru.est[i,1]<-1#
  tru.est[i,2]<-3.5#
  tru.est[i,3]<--2#
  tru.est[i,4]<-2#
  tru.est[i,5]<-3#
  tru.est[i,6]<-1#
  myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
  y <- rexp(n, rate = myrates) # generates the r.v.#
  cen <- rexp(n, rate = 1 )#
  ycen <- pmin(y, cen)#
  di <- as.numeric(y <= cen)#
  tru.est[i,7]<-table(di)[1]#
  #create parameters for ZG#
  alpha<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
  print(mean(alpha))#
  yzero<-matrix(1,n,1)#
  error<--1*rlogis(n)#
  flag<-error<qlogis(alpha)#
  yzero[flag]<-error[flag]#
  flag<-yzero==1#
  di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
  tru.est[i,8]<-table(di)[1]#
  data<-cbind(ycen,di,x,z)#
  data<-data#
  Y<-ycen#
  C<-di#
  X<-cbind(1,x)#
  Z<-cbind(1,z,x)#
######### Try fit the data using Bayesian OF model #############  #
Weibull = mcmcOF(Y, C, X, Z, N = 10000, burn = 5000, thin = 20,  w = c(1, 1, 1), m = 10, form = "Weibull", seed = 100)
Weibull = mcmcOF(Y, C, X, Z, N = 5000, burn = 1000, thin = 20,  w = c(1, 1, 1), m = 10, form = "Weibull", seed = 100)
names(Weibull)
plot(Weibull$loglike, type= 'l')
par(mfrow = c(2,4))#
plot(Weibull$loglike, type = 'l')#
for (p in 1:2) {#
  plot(Weibull$beta[,p], type = 'l')#
}#
for (p in 1:3) {#
  plot(Weibull$gamma[,p], type = 'l')#
}#
plot(Weibull$lambda, type = 'l')
