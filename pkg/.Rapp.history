load('/Users/bomin8319/Desktop/IPTM/paper/Darenew.RData')
load('/Users/bomin8319/Desktop/IPTM/paper/code/Darenew.RData')
length(Dare$edge)
load('~/Desktop/IPTM/paper/code/Daretest.RData')
output$Z
# 762 - #
attach(Dare)#
Dare$node = 1:nrow(Dare$node)#
Dare$text = Dare$text[1:length(Dare$edge)]#
Dare$edge = Dare$edge[762:length(Dare$edge)]#
Dare$edge = Dare$edge[-which(sapply(Dare$text, function(d){length(d)})==0)]#
Dare$text = Dare$text[-which(sapply(Dare$text, function(d){length(d)})==0)]#
mintime = Dare$edge[[1]][[3]]#
for (n in 1:length(Dare$edge)){#
  Dare$edge[[n]][3] = (Dare$edge[[n]][[3]] - mintime) / 3600#
}#
Dare$edge = lapply(Dare$edge, function(x){x[1:3]})
load("/Users/bomin8319/Desktop/IPTM/paper/code/Daretest.RData")
Daretest1 = output#
Daretest1$C
TableWord = function(Zchain, K, textlist, vocabulary) {#
  # Generate a table of token-topic assignments with high probabilities for each IP#
  ##
  # Args #
  #  Zchain summary of Z obtained using MCMC function#
  #  K total number of topics specified by the user#
  #  textlist list of text containing the words in each document#
  #  vocabulary all vocabularies used over the corpus#
  ##
  # Returns#
  #  List of table that summarize token-topic assignments for each IP#
  W = length(vocabulary)#
    Zsummary = list()#
    topic.word = matrix(0, nrow = K, ncol = W)#
    colnames(topic.word) = vocabulary#
    iter = 1#
    for (d in seq(along = textlist)) {#
      if (length(Zchain[[d]]) > 0){#
        Zsummary[[iter]] = Zchain[[d]]#
        names(Zsummary[[iter]])<- vocabulary[textlist[[d]]]#
        iter = iter+1#
      }#
    }#
    topic.dist = t(tabulate(unlist(Zsummary), K)/length(unlist(Zsummary)))#
    colnames(topic.dist) = c(1L:K)#
    top.topic = topic.dist[, order(topic.dist, decreasing = TRUE)]#
    all.word = unlist(Zsummary)#
    for (i in seq(along = all.word)){#
      matchWZ = which(colnames(topic.word) == names(all.word[i]))#
      topic.word[all.word[i], matchWZ] = topic.word[all.word[i], matchWZ] + 1#
    }#
    table.word = top.topic.words(topic.word, num.words = 15, by.score = TRUE)#
    colnames(table.word) = names(top.topic)#
  return(table.word)#
}#
#
which(Sandy$date %in% unique(Sandy$date)[20:27])
TableWord(Daretest1$Z, 20, Dare$text, Dare$vocab)
#IPTM model results#
load('/Users/bomin8319/Desktop/IPTM/paper/code/Darenew.RData')#
# 762 - #
attach(Dare)#
Dare$node = 1:nrow(Dare$node)#
Dare$text = Dare$text[762:length(Dare$edge)]#
Dare$edge = Dare$edge[762:length(Dare$edge)]#
Dare$edge = Dare$edge[-which(sapply(Dare$text, function(d){length(d)})==0)]#
Dare$text = Dare$text[-which(sapply(Dare$text, function(d){length(d)})==0)]#
mintime = Dare$edge[[1]][[3]]#
for (n in 1:length(Dare$edge)){#
  Dare$edge[[n]][3] = (Dare$edge[[n]][[3]] - mintime) / 3600#
}#
Dare$edge = lapply(Dare$edge, function(x){x[1:3]})#
#
load("/Users/bomin8319/Desktop/IPTM/paper/code/Daretest.RData")#
Daretest1 = output#
Daretest1$C#
#
TableWord = function(Zchain, K, textlist, vocabulary) {#
  # Generate a table of token-topic assignments with high probabilities for each IP#
  ##
  # Args #
  #  Zchain summary of Z obtained using MCMC function#
  #  K total number of topics specified by the user#
  #  textlist list of text containing the words in each document#
  #  vocabulary all vocabularies used over the corpus#
  ##
  # Returns#
  #  List of table that summarize token-topic assignments for each IP#
  W = length(vocabulary)#
    Zsummary = list()#
    topic.word = matrix(0, nrow = K, ncol = W)#
    colnames(topic.word) = vocabulary#
    iter = 1#
    for (d in seq(along = textlist)) {#
      if (length(Zchain[[d]]) > 0){#
        Zsummary[[iter]] = Zchain[[d]]#
        names(Zsummary[[iter]])<- vocabulary[textlist[[d]]]#
        iter = iter+1#
      }#
    }#
    topic.dist = t(tabulate(unlist(Zsummary), K)/length(unlist(Zsummary)))#
    colnames(topic.dist) = c(1L:K)#
    top.topic = topic.dist[, order(topic.dist, decreasing = TRUE)]#
    all.word = unlist(Zsummary)#
    for (i in seq(along = all.word)){#
      matchWZ = which(colnames(topic.word) == names(all.word[i]))#
      topic.word[all.word[i], matchWZ] = topic.word[all.word[i], matchWZ] + 1#
    }#
    table.word = top.topic.words(topic.word, num.words = 15, by.score = TRUE)#
    colnames(table.word) = names(top.topic)#
  return(table.word)#
}#
TableWord(Daretest1$Z, 20, Dare$text, Dare$vocab)
rm(list=ls())
library(anytime)#
library(ggplot2)#
library(MCMCpack)#
library(reshape2)#
library(gridExtra)#
library(ggrepel)#
library(RColorBrewer)#
library(lda)#
#
load('/Users/bomin8319/Desktop/IPTM/paper/Darenew.RData')#
# 762 - #
attach(Dare)#
Dare$text = Dare$text[762:length(Dare$edge)]#
Dare$edge = Dare$edge[762:length(Dare$edge)]#
Dare$edge = Dare$edge[-which(sapply(Dare$text, function(d){length(d)})==0)]#
Dare$text = Dare$text[-which(sapply(Dare$text, function(d){length(d)})==0)]#
#mintime = Dare$edge[[1]][[3]]#
#for (n in 1:length(Dare$edge)){#
#  Dare$edge[[n]][3] = (Dare$edge[[n]][[3]] - mintime) / 3600#
#}#
#
sender = sapply(Dare$edge, function(d){d[[1]]})#
sender = data.frame(sender=sender, dept = Dare$node[sender, 3], time = sapply(Dare$edge, function(d){d[[3]]}), date = anydate(sapply(Dare$edge, function(d){d[[3]]})))#
sender$date = format(sender$date, format = "%m/%d")#
Dept = data.frame(Date = c(sapply(unique(sender$date), function(d){rep(as.character(d), 22)})), #
				  Department = c(sapply(unique(sender$date), function(d){sort(unique(Dare$node[,3]))#
})), Send = NA)#
i = 1#
for (date in unique(sender$date)) {#
Dept[(22*(i-1)+1) : (22*i),3]= tabulate(sender[which(sender[,4] == date),2], 22)#
i = i + 1#
}#
ave = c()#
i = 1#
for (date in unique(Dept$Date)) {#
	ave[i] = mean(Dept[which(Dept$Date == date),3])#
	i = i + 1#
}#
colourCount = 22#
getPalette = colorRampPalette(brewer.pal(9, "Set1"))#
#
Dept2 = data.frame(Date = unique(Dept$Date), Send = ave)#
	f <- ggplot(Dept, aes(Date, Send, colour = Department), show.legend=FALSE)#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=22)) + scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/20)]) + theme(legend.text = element_text(size = 8)) +geom_vline(xintercept = 48, colour = "red", size = 1) +geom_vline(xintercept = 52, colour = "red", size = 1) + #
	geom_vline(xintercept = 45, colour = "red", size = 0.5, linetype = "dashed")+ annotate("text", x =50, y = 21, label = "Sandy", colour= "red", size = 3 ) +#
	annotate("segment", x = 40, xend = 44, y = 15, yend = 14, colour = "red", size = 0.1, arrow = arrow()) + annotate("text", x =40, y = 15.5, label = "First Sandy", colour= "red", size = 3)  +scale_colour_manual(values = getPalette(colourCount)) + theme_bw()#
#+ stat_summary(aes(group = 1), size = 1.2, fun.y=mean, geom="line", colour = "grey35")
load('/Users/bomin8319/Desktop/IPTM/paper/code/Darenew.RData')#
# 762 - #
attach(Dare)#
Dare$text = Dare$text[762:length(Dare$edge)]#
Dare$edge = Dare$edge[762:length(Dare$edge)]#
Dare$edge = Dare$edge[-which(sapply(Dare$text, function(d){length(d)})==0)]#
Dare$text = Dare$text[-which(sapply(Dare$text, function(d){length(d)})==0)]#
#mintime = Dare$edge[[1]][[3]]#
#for (n in 1:length(Dare$edge)){#
#  Dare$edge[[n]][3] = (Dare$edge[[n]][[3]] - mintime) / 3600#
#}#
#
sender = sapply(Dare$edge, function(d){d[[1]]})#
sender = data.frame(sender=sender, dept = Dare$node[sender, 3], time = sapply(Dare$edge, function(d){d[[3]]}), date = anydate(sapply(Dare$edge, function(d){d[[3]]})))#
sender$date = format(sender$date, format = "%m/%d")#
Dept = data.frame(Date = c(sapply(unique(sender$date), function(d){rep(as.character(d), 22)})), #
				  Department = c(sapply(unique(sender$date), function(d){sort(unique(Dare$node[,3]))#
})), Send = NA)#
i = 1#
for (date in unique(sender$date)) {#
Dept[(22*(i-1)+1) : (22*i),3]= tabulate(sender[which(sender[,4] == date),2], 22)#
i = i + 1#
}#
ave = c()#
i = 1#
for (date in unique(Dept$Date)) {#
	ave[i] = mean(Dept[which(Dept$Date == date),3])#
	i = i + 1#
}#
colourCount = 22#
getPalette = colorRampPalette(brewer.pal(9, "Set1"))#
#
Dept2 = data.frame(Date = unique(Dept$Date), Send = ave)#
	f <- ggplot(Dept, aes(Date, Send, colour = Department), show.legend=FALSE)#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=22)) + scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/20)]) + theme(legend.text = element_text(size = 8)) +geom_vline(xintercept = 48, colour = "red", size = 1) +geom_vline(xintercept = 52, colour = "red", size = 1) + #
	geom_vline(xintercept = 45, colour = "red", size = 0.5, linetype = "dashed")+ annotate("text", x =50, y = 21, label = "Sandy", colour= "red", size = 3 ) +#
	annotate("segment", x = 40, xend = 44, y = 15, yend = 14, colour = "red", size = 0.1, arrow = arrow()) + annotate("text", x =40, y = 15.5, label = "First Sandy", colour= "red", size = 3)  +scale_colour_manual(values = getPalette(colourCount)) + theme_bw()#
#+ stat_summary(aes(group = 1), size = 1.2, fun.y=mean, geom="line", colour = "grey35")
f <- ggplot(Dept, aes(Date, Send, colour = Department), show.legend=FALSE)#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=22)) + scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 10)) +geom_vline(xintercept = 23, colour = "red", size = 1) +geom_vline(xintercept = 27, colour = "red", size = 1) + #
	geom_vline(xintercept = 20, colour = "red", size = 0.5, linetype = "dashed")+ annotate("text", x =25, y = 21, label = "Sandy", colour= "red" ) + #
	annotate("segment", x = 18, xend = 20, y = 15, yend = 14, colour = "red", size = 0.1, arrow = arrow()) + annotate("text", x =18, y = 15.5, label = "First Sandy", colour= "red", size = 3)  +scale_colour_manual(values = getPalette(colourCount))#
#+ stat_summary(aes(group = 1), size = 1.2, fun.y=mean, geom="line", colour = "grey35")
receiver = unlist(sapply(Dare$edge, function(d){d[[2]]}))#
time = unlist(sapply(Dare$edge, function(d){rep(d[[3]], length(d[[2]]))}))#
date = anydate(unlist(sapply(Dare$edge, function(d){rep(d[[3]], length(d[[2]]))})))#
receiver  = data.frame(receiver =receiver, dept = Dare$node[receiver , 3], time = time, date = date)#
receiver$date = format(receiver$date, format = "%m/%d")#
Dept = data.frame(Date = c(sapply(unique(receiver$date), function(d){rep(as.character(d), 22)})), #
				  Department = c(sapply(unique(receiver$date), function(d){sort(unique(Dare$node[,3]))#
})), Receive = NA)#
i = 1#
for (date in unique(receiver$date)) {#
Dept[(22*(i-1)+1) : (22*i),3]= tabulate(receiver[which(receiver[,4] == date),2], 22)#
i = i + 1#
}#
#
	f <- ggplot(Dept, aes(Date, Receive, colour = Department))#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=22))+ scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 5)) +geom_vline(xintercept = 23, colour = "red", size = 1) +geom_vline(xintercept = 27, colour = "red", size = 1) + #
	geom_vline(xintercept = 20, colour = "red", size = 0.5, linetype = "dashed")+ annotate("text", x =25, y = 27, label = "Sandy", colour= "red" ) + #
	annotate("segment", x = 18, xend = 20, y = 20, yend = 19, colour = "red", size = 0.1, arrow = arrow()) + annotate("text", x =18, y = 20.5, label = "First Sandy", colour= "red", size = 3)  +scale_colour_manual(values = getPalette(colourCount))
f <- ggplot(Dept, aes(Date, Receive, colour = Department))#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=22))+ scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 10)) +geom_vline(xintercept = 23, colour = "red", size = 1) +geom_vline(xintercept = 27, colour = "red", size = 1) + #
	geom_vline(xintercept = 20, colour = "red", size = 0.5, linetype = "dashed")+ annotate("text", x =25, y = 27, label = "Sandy", colour= "red" ) + #
	annotate("segment", x = 18, xend = 20, y = 20, yend = 19, colour = "red", size = 0.1, arrow = arrow()) + annotate("text", x =18, y = 20.5, label = "First Sandy", colour= "red", size = 3)  +scale_colour_manual(values = getPalette(colourCount))#
	#+ stat_summary(aes(group = 1), size = 1.2, fun.y=mean, geom="line", colour = "grey35")+
Sandy = sapply(Dare$text, function(d){sum(49 == d)})#
Sandy = data.frame(Sandy=Sandy, time = sapply(Dare$edge, function(d){d[[3]]}), date = anydate(sapply(Dare$edge, function(d){d[[3]]})))#
Sandy$date = format(Sandy$date, format = "%m/%d")#
Hurr = sapply(Dare$text, function(d){sum(81 == d)})#
Hurr = data.frame(Hurr =Hurr , time = sapply(Dare$edge, function(d){d[[3]]}), date = anydate(sapply(Dare$edge, function(d){d[[3]]})))#
Hurr $date = format(Hurr$date, format = "%m/%d")#
#
Dept = data.frame(Date = c(sapply(unique(Sandy$date), function(d){rep(as.character(d), 2)})), Word = c(sapply(unique(Sandy$date), function(d){c("Hurricane", "Sandy")})), Count = NA)#
i = 1#
for (date in unique(Sandy$date)) {#
Dept[(2*(i-1)+1) : (2*i),3]= c(sum(Hurr[which(Hurr[,3] == date),1]), sum(Sandy[which(Sandy[,3] == date),1]))#
i = i + 1#
}#
	f <- ggplot(Dept, aes(Date, Count, colour = Word))#
	f + geom_line(aes(group = Word))+ guides(col = guide_legend(nrow=2))+ scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/20)])  +geom_vline(xintercept = 48, colour = "red", size = 1) +geom_vline(xintercept = 52, colour = "red", size = 1) + #
	geom_vline(xintercept = 45, colour = "red", size = 0.5, linetype = "dashed")+ annotate("text", x =50, y = 27, label = "Sandy", colour= "red", size = 3) + theme_bw() +#
	annotate("segment", x = 40, xend = 44, y = 15, yend = 14, colour = "red", size = 0.1, arrow = arrow()) + annotate("text", x =40, y = 15.5, label = "First Sandy", colour= "red", size = 3)
f <- ggplot(Dept, aes(Date, Count, colour = Word))#
	f + geom_line(aes(group = Word))+ guides(col = guide_legend(nrow=2))+ scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) +geom_vline(xintercept = 23, colour = "red", size = 1) +geom_vline(xintercept = 27, colour = "red", size = 1) + #
	geom_vline(xintercept = 20, colour = "red", size = 0.5, linetype = "dashed")+ annotate("text", x =25, y = 27, label = "Sandy", colour= "red" ) + #
	annotate("segment", x = 18, xend = 20, y = 20, yend = 19, colour = "red", size = 0.1, arrow = arrow()) + annotate("text", x =18, y = 20.5, label = "First Sandy", colour= "red", size = 3)
library(GGally)#
library(network)#
library(sna)#
#
Network = list()#
Network[[1]]= Dare$edge[which(Sandy$date %in% unique(Sandy$date)[1:18])] #pre-sandy#
Network[[2]]= Dare$edge[which(Sandy$date %in% unique(Sandy$date)[19:39])] #sandy #
Network[[3]]= Dare$edge[which(Sandy$date %in% unique(Sandy$date)[40:55])] #post-sandy#
ggplotColours <- function(n = 6, h = c(0, 360) + 15){#
  if ((diff(h) %% 360) < 1) h[2] <- h[2] - 360/n#
  hcl(h = (seq(h[1], h[2], length = n)), c = 100, l = 65)#
}#
titles = c("Pre-Sandy", "Sandy", "Post-Sandy")#
colors = getPalette(colourCount)#
names(colors) = (unique(sort(Dare$node[,3])))#
g= list()#
for (i in 1:3) {#
	edge= matrix(unlist(sapply(Network[[i]], function(d){cbind(rep(d[[1]], length(d[[2]])), d[[2]])})), ncol = 2)#
	net = as.network(edge, matrix.type = "edgelist", directed = TRUE)#
	network.vertex.names(net) = 1:27#
	net %v% "Dept" <- as.character(Dare$node[,3])#
	g[[i]] = ggnet2(net, size = "degree", arrow.size =8, color = colors[net %v% "Dept"],  color.legend = "Dept",label.color = colors[net %v% "Dept"], mode = "kamadakawai",legend.position = "none", size.min=1) + ggtitle(titles[i]) +  theme(panel.border = element_rect(color = "grey50", fill = NA),#
          aspect.ratio = 1)#
}#
grid.arrange <- getFromNamespace("grid.arrange", asNamespace("gridExtra"))#
grid.arrange(grobs = g, nrow = 1)
#Vance EDA#
load('/Users/bomin8319/Desktop/IPTM/paper/code/Vancenew.RData')#
# 762 - #
attach(Vance)#
Vance$text = Vance$text[1:length(Vance$edge)]#
Vance$edge = Vance$edge[1:length(Vance$edge)]#
Vance$edge = Vance$edge[-which(sapply(Vance$text, function(d){length(d)})==0)]#
Vance$text = Vance$text[-which(sapply(Vance$text, function(d){length(d)})==0)]#
#mintime = Dare$edge[[1]][[3]]#
#for (n in 1:length(Dare$edge)){#
#  Dare$edge[[n]][3] = (Dare$edge[[n]][[3]] - mintime) / 3600#
#}#
#
sender = sapply(Vance$edge, function(d){d[[1]]})#
sender = data.frame(sender=sender, dept =Vance$node[sender, 3], time = sapply(Vance$edge, function(d){d[[3]]}), date = anydate(sapply(Vance$edge, function(d){d[[3]]})))#
sender$date = format(sender$date, format = "%m/%d")#
Dept = data.frame(Date = c(sapply(unique(sender$date), function(d){rep(as.character(d), 17)})), #
				  Department = c(sapply(unique(sender$date), function(d){sort(unique(Vance$node[,3]))#
})), Send = NA)#
i = 1#
for (date in unique(sender$date)) {#
Dept[(17*(i-1)+1) : (17*i),3]= tabulate(sender[which(sender[,4] == date),2], 17)#
i = i + 1#
}#
ave = c()#
i = 1#
for (date in unique(Dept$Date)) {#
	ave[i] = mean(Dept[which(Dept$Date == date),3])#
	i = i + 1#
}#
colourCount = 17#
getPalette = colorRampPalette(brewer.pal(9, "Set1"))#
#
Dept2 = data.frame(Date = unique(Dept$Date), Send = ave)#
	f <- ggplot(Dept, aes(Date, Send, colour = Department), show.legend=FALSE)#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=17)) + scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 8)) +geom_vline(xintercept = 33, colour = "red", size = 1) +geom_vline(xintercept = 31, colour = "red", size = 1) + theme_bw()+#
	geom_vline(xintercept = 30, colour = "red", size = 0.5, linetype = "dashed")+ annotate("text", x =32, y = 5, label = "Sandy", colour= "red", size = 3 ) +#
	annotate("segment", x = 29, xend = 30, y = 4.2, yend = 4, colour = "red", size = 0.1, arrow = arrow()) + annotate("text", x =28, y = 4.3, label = "First Sandy", colour= "red", size = 3)  +scale_colour_manual(values = getPalette(colourCount))#
#+ stat_summary(aes(group = 1), size = 1.2, fun.y=mean, geom="line", colour = "grey35")
sender = sapply(Vance$edge, function(d){d[[1]]})#
sender = data.frame(sender=sender, dept =Vance$node[sender, 3], time = sapply(Vance$edge, function(d){d[[3]]}), date = anydate(sapply(Vance$edge, function(d){d[[3]]})))#
sender$date = format(sender$date, format = "%m/%d")#
Dept = data.frame(Date = c(sapply(unique(sender$date), function(d){rep(as.character(d), 17)})), #
				  Department = c(sapply(unique(sender$date), function(d){sort(unique(Vance$node[,3]))#
})), Send = NA)#
i = 1#
for (date in unique(sender$date)) {#
Dept[(17*(i-1)+1) : (17*i),3]= tabulate(sender[which(sender[,4] == date),2], 17)#
i = i + 1#
}#
ave = c()#
i = 1#
for (date in unique(Dept$Date)) {#
	ave[i] = mean(Dept[which(Dept$Date == date),3])#
	i = i + 1#
}#
colourCount = 17#
getPalette = colorRampPalette(brewer.pal(9, "Set1"))#
#
Dept2 = data.frame(Date = unique(Dept$Date), Send = ave)#
	f <- ggplot(Dept, aes(Date, Send, colour = Department), show.legend=FALSE)#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=17)) + scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 8)) +geom_vline(xintercept = 33, colour = "red", size = 1) +geom_vline(xintercept = 31, colour = "red", size = 1) + 	 annotate("text", x =32, y = 5, label = "Sandy", colour= "red", size = 3 ) +
annotate("segment", x = 29, xend = 30, y = 4.2, yend = 4, colour = "red", size = 0.1, arrow = arrow())   +scale_colour_manual(values = getPalette(colourCount))
Dept2 = data.frame(Date = unique(Dept$Date), Send = ave)#
	f <- ggplot(Dept, aes(Date, Send, colour = Department), show.legend=FALSE)#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=17)) + scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 8)) +geom_vline(xintercept = 33, colour = "red", size = 1) +geom_vline(xintercept = 31, colour = "red", size = 1) + 	 annotate("text", x =32, y = 5, label = "Sandy", colour= "red", size = 3 )  +scale_colour_manual(values = getPalette(colourCount))
Dept2 = data.frame(Date = unique(Dept$Date), Send = ave)#
	f <- ggplot(Dept, aes(Date, Send, colour = Department), show.legend=FALSE)#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=17)) + scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 10)) +geom_vline(xintercept = 33, colour = "red", size = 1) +geom_vline(xintercept = 31, colour = "red", size = 1) + 	 annotate("text", x =32, y = 5, label = "Sandy", colour= "red", size = 3 )  +scale_colour_manual(values = getPalette(colourCount))#
#+ stat_summary(aes(group = 1), size = 1.2, fun.y=mean, geom="line", colour = "grey35") #
#geom_vline(xintercept = 30, colour = "red", size = 0.5, linetype = "dashed")+#
#+ annotate("text", x =28, y = 4.3, label = "First Sandy", colour= "red", size = 3)#
#	annotate("segment", x = 29, xend = 30, y = 4.2, yend = 4, colour = "red", size = 0.1, arrow = arrow())
receiver = unlist(sapply(Vance$edge, function(d){d[[2]]}))#
time = unlist(sapply(Vance$edge, function(d){rep(d[[3]], length(d[[2]]))}))#
date = anydate(unlist(sapply(Vance$edge, function(d){rep(d[[3]], length(d[[2]]))})))#
receiver  = data.frame(receiver =receiver, dept = Vance$node[receiver , 3], time = time, date = date)#
receiver$date = format(receiver$date, format = "%m/%d")#
Dept = data.frame(Date = c(sapply(unique(receiver$date), function(d){rep(as.character(d), 17)})), #
				  Department = c(sapply(unique(receiver$date), function(d){sort(unique(Vance$node[,3]))#
})), Receive = NA)#
i = 1#
for (date in unique(receiver$date)) {#
Dept[(17*(i-1)+1) : (17*i),3]= tabulate(receiver[which(receiver[,4] == date),2], 17)#
i = i + 1#
}#
#
	f <- ggplot(Dept, aes(Date, Receive, colour = Department))#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=17)) +scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 8)) +geom_vline(xintercept = 33, colour = "red", size = 1) +geom_vline(xintercept = 31, colour = "red", size = 1) +annotate("text", x =32, y = 6, label = "Sandy", colour= "red", size = 3 ) + annotate("text", x =28, y = 5.3, label = "First Sandy", colour= "red", size = 3)  +scale_colour_manual(values = getPalette(colourCount))
f <- ggplot(Dept, aes(Date, Receive, colour = Department))#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=17)) +scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 8)) +geom_vline(xintercept = 33, colour = "red", size = 1) +geom_vline(xintercept = 31, colour = "red", size = 1) +annotate("text", x =32, y = 6, label = "Sandy", colour= "red", size = 3 )  +scale_colour_manual(values = getPalette(colourCount))#
#
#+ stat_summary(aes(group = 1), size = 1.2, fun.y=mean, geom="line", colour = "grey35")+
f <- ggplot(Dept, aes(Date, Receive, colour = Department))#
	f + geom_line(aes(group = Department)) + guides(col = guide_legend(nrow=17)) +scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 10)) +geom_vline(xintercept = 33, colour = "red", size = 1) +geom_vline(xintercept = 31, colour = "red", size = 1) +annotate("text", x =32, y = 6, label = "Sandy", colour= "red", size = 3 )  +scale_colour_manual(values = getPalette(colourCount))
Sandy = sapply(Vance$text, function(d){sum(244 == d)})#
Sandy = data.frame(Sandy=Sandy, time = sapply(Vance$edge, function(d){d[[3]]}), date = anydate(sapply(Vance$edge, function(d){d[[3]]})))#
Sandy$date = format(Sandy$date, format = "%m/%d")#
Hurr = sapply(Vance$text, function(d){sum(243 == d)})#
Hurr = data.frame(Hurr =Hurr , time = sapply(Vance$edge, function(d){d[[3]]}), date = anydate(sapply(Vance$edge, function(d){d[[3]]})))#
Hurr $date = format(Hurr$date, format = "%m/%d")#
#
Dept = data.frame(Date = c(sapply(unique(Sandy$date), function(d){rep(as.character(d), 2)})), Word = c(sapply(unique(Sandy$date), function(d){c("Hurricane", "Sandy")})), Count = NA)#
i = 1#
for (date in unique(Sandy$date)) {#
Dept[(2*(i-1)+1) : (2*i),3]= c(sum(Hurr[which(Hurr[,3] == date),1]), sum(Sandy[which(Sandy[,3] == date),1]))#
i = i + 1#
}#
	f <- ggplot(Dept, aes(Date, Count, colour = Word))#
	f + geom_line(aes(group = Word))+ guides(col = guide_legend(nrow=2))+scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 8)) +geom_vline(xintercept = 33, colour = "red", size = 1) +geom_vline(xintercept = 31, colour = "red", size = 1) + theme_bw()+#
	geom_vline(xintercept = 30, colour = "red", size = 0.5, linetype = "dashed")+ annotate("text", x =32, y = 4.5, label = "Sandy", colour= "red", size = 3 ) +#
	annotate("segment", x = 29, xend = 30, y = 4.2, yend = 4, colour = "red", size = 0.1, arrow = arrow()) + annotate("text", x =28, y = 4.3, label = "First Sandy", colour= "red", size = 3)
f <- ggplot(Dept, aes(Date, Count, colour = Word))#
	f + geom_line(aes(group = Word))+ guides(col = guide_legend(nrow=2))+scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 8)) +geom_vline(xintercept = 33, colour = "red", size = 1) +geom_vline(xintercept = 31, colour = "red", size = 1) + annotate("text", x =32, y = 4.5, label = "Sandy", colour= "red", size = 3 ) +#
	annotate("segment", x = 29, xend = 30, y = 4.2, yend = 4, colour = "red", size = 0.1, arrow = arrow())
f <- ggplot(Dept, aes(Date, Count, colour = Word))#
	f + geom_line(aes(group = Word))+ guides(col = guide_legend(nrow=2))+scale_x_discrete(breaks = function(n) n[seq(0, length(n), by = length(n)/10)]) + theme(legend.text = element_text(size = 8)) +geom_vline(xintercept = 33, colour = "red", size = 1) +geom_vline(xintercept = 31, colour = "red", size = 1) + annotate("text", x =32, y = 4.5, label = "Sandy", colour= "red", size = 3 )
library(GGally)#
library(network)#
library(sna)#
#
Network = list()#
Network[[1]]= Vance$edge[which(Sandy$date %in% unique(Sandy$date)[1:28])] #pre-sandy#
Network[[2]]= Vance$edge[which(Sandy$date %in% unique(Sandy$date)[29:35])] #sandy #
Network[[3]]= Vance$edge[which(Sandy$date %in% unique(Sandy$date)[36:48])] #post-sandy#
ggplotColours <- function(n = 6, h = c(0, 360) + 15){#
  if ((diff(h) %% 360) < 1) h[2] <- h[2] - 360/n#
  hcl(h = (seq(h[1], h[2], length = n)), c = 100, l = 65)#
}#
titles = c("Pre-Sandy", "Sandy", "Post-Sandy")#
colors = getPalette(colourCount)#
names(colors) = (unique(sort(Vance$node[,3])))#
g= list()#
for (i in 1:3) {#
	edge= matrix(unlist(sapply(Network[[i]], function(d){cbind(rep(d[[1]], length(d[[2]])), d[[2]])})), ncol = 2)#
	net = as.network(edge, matrix.type = "edgelist", directed = TRUE)#
	network.vertex.names(net) = 1:27#
	net %v% "Dept" <- as.character(Vance$node[,3])#
	g[[i]] = ggnet2(net, size = "degree", arrow.size =8, color = colors[net %v% "Dept"],  color.legend = "Dept",label.color = colors[net %v% "Dept"], mode = "kamadakawai",legend.position = "none", size.min=1) + ggtitle(titles[i]) +  theme(panel.border = element_rect(color = "grey50", fill = NA),#
          aspect.ratio = 1)#
}#
grid.arrange <- getFromNamespace("grid.arrange", asNamespace("gridExtra"))#
grid.arrange(grobs = g, nrow = 1)
load('~/Desktop/output55.RData')
plot(output$D, type = 'l')
plot(output$B[[1]][1,], type = 'l')
plot(output$B[[2]][1,], type = 'l')
plot(output$B[[2]][2,], type = 'l')
plot(output$B[[1]][2,], type = 'l')
plot(output$B[[1]][3,], type = 'l')
plot(output$B[[2]][3,], type = 'l')
plot(output$B[[3]][3,], type = 'l')
plot(output$B[[2]][4,], type = 'l')
plot(output$B[[2]][5,], type = 'l')
plot(output$B[[2]][6,], type = 'l')
plot(output$B[[2]][7,], type = 'l')
plot(output$B[[2]][8,], type = 'l')
plot(output$B[[2]][9,], type = 'l')
plot(output$B[[2]][10,], type = 'l')
plot(output$B[[2]][11,], type = 'l')
plot(output$B[[2]][12,], type = 'l')
plot(output$B[[2]][13,], type = 'l')
plot(output$B[[2]][14,], type = 'l')
plot(output$B[[2]][15,], type = 'l')
plot(output$B[[2]][16,], type = 'l')
plot(output$B[[2]][17,], type = 'l')
plot(output$B[[2]][18,], type = 'l')
plot(output$B[[2]][19,], type = 'l')
plot(output$B[[2]][20,], type = 'l')
plot(output$B[[2]][21,], type = 'l')
plot(output$B[[2]][22,], type = 'l')
plot(output$B[[2]][23,], type = 'l')
plot(output$B[[2]][24,], type = 'l')
plot(output$B[[2]][25,], type = 'l')
plot(output$B[[1]][25,], type = 'l')
plot(output$B[[1]][24,], type = 'l')
plot(output$B[[1]][23,], type = 'l')
plot(output$B[[1]][22,], type = 'l')
plot(output$B[[1]][21,], type = 'l')
plot(output$B[[1]][20,], type = 'l')
plot(output$B[[1]][19,], type = 'l')
plot(output$B[[1]][18,], type = 'l')
plot(output$B[[1]][17,], type = 'l')
plot(output$B[[1]][16,], type = 'l')
plot(output$B[[1]][15,], type = 'l')
plot(output$B[[1]][14,], type = 'l')
plot(output$B[[1]][13,], type = 'l')
plot(output$B[[1]][12,], type = 'l')
plot(output$B[[1]][11,], type = 'l')
plot(output$B[[1]][10,], type = 'l')
plot(output$B[[1]][9,], type = 'l')
plot(output$B[[1]][8,], type = 'l')
plot(output$B[[1]][7,], type = 'l')
plot(output$B[[1]][6,], type = 'l')
plot(output$B[[1]][5,], type = 'l')
plot(output$B[[1]][4,], type = 'l')
plot(output$B[[1]][3,], type = 'l')
plot(output$B[[1]][2,], type = 'l')
plot(output$B[[1]][1,], type = 'l')
plot(output$B[[2]][1,], type = 'l')
#Dare EDA#
library(anytime)#
library(ggplot2)#
library(MCMCpack)#
library(reshape2)#
library(gridExtra)#
library(ggrepel)#
library(RColorBrewer)#
library(lda)
load('/Users/bomin8319/Desktop/IPTM/paper/code/Darenew.RData')#
# 762 - #
attach(Dare)#
Dare$node = 1:nrow(Dare$node)#
Dare$text = Dare$text[762:length(Dare$edge)]#
Dare$edge = Dare$edge[762:length(Dare$edge)]#
Dare$edge = Dare$edge[-which(sapply(Dare$text, function(d){length(d)})==0)]#
Dare$text = Dare$text[-which(sapply(Dare$text, function(d){length(d)})==0)]#
mintime = Dare$edge[[1]][[3]]#
for (n in 1:length(Dare$edge)){#
  Dare$edge[[n]][3] = (Dare$edge[[n]][[3]] - mintime) / 3600#
}#
Dare$edge = lapply(Dare$edge, function(x){x[1:3]})
Daretest1 = output#
Daretest1$C
TableWord = function(Zchain, K, textlist, vocabulary) {#
  # Generate a table of token-topic assignments with high probabilities for each IP#
  ##
  # Args #
  #  Zchain summary of Z obtained using MCMC function#
  #  K total number of topics specified by the user#
  #  textlist list of text containing the words in each document#
  #  vocabulary all vocabularies used over the corpus#
  ##
  # Returns#
  #  List of table that summarize token-topic assignments for each IP#
  W = length(vocabulary)#
    Zsummary = list()#
    topic.word = matrix(0, nrow = K, ncol = W)#
    colnames(topic.word) = vocabulary#
    iter = 1#
    for (d in seq(along = textlist)) {#
      if (length(Zchain[[d]]) > 0){#
        Zsummary[[iter]] = Zchain[[d]]#
        names(Zsummary[[iter]])<- vocabulary[textlist[[d]]]#
        iter = iter+1#
      }#
    }#
    topic.dist = t(tabulate(unlist(Zsummary), K)/length(unlist(Zsummary)))#
    colnames(topic.dist) = c(1L:K)#
    top.topic = topic.dist[, order(topic.dist, decreasing = TRUE)]#
    all.word = unlist(Zsummary)#
    for (i in seq(along = all.word)){#
      matchWZ = which(colnames(topic.word) == names(all.word[i]))#
      topic.word[all.word[i], matchWZ] = topic.word[all.word[i], matchWZ] + 1#
    }#
    table.word = top.topic.words(topic.word, num.words = 15, by.score = TRUE)#
    colnames(table.word) = names(top.topic)#
  return(table.word)#
}#
TableWord(Daretest1$Z, 20, Dare$text, Dare$vocab)
table(unlist(Daretest1$Z)) / sum(table(unlist(Daretest1$Z)))
dim(Daretest1$B[[1]])
DareB = matrix(NA, 500, 25)#
DareB[,1:25] = t(Daretest1$B[[1]])#
colnames(DareB)= c( "intercept",#
"outdegree1", "outdegree2", "outdegree3", "indegree1", "indegree2", "indegree3",#
"send1", "send2", "send3" ,"receive1", "receive2", "receive3",#
"2-send1", "2-send2", "2-send3", "2-receive1", "2-receive2" ,"2-receive3",#
"sibling1", "sibling2" ,"sibling3", "cosibling1", "cosibling2", "cosibling3")#
DareB = melt(DareB)#
#
DareB2 = matrix(NA, 500, 25)#
DareB2[,1:25] = t(Daretest1$B[[2]])#
colnames(DareB2)= c( "intercept",#
"outdegree1", "outdegree2", "outdegree3", "indegree1", "indegree2", "indegree3",#
"send1", "send2", "send3" ,"receive1", "receive2", "receive3",#
"2-send1", "2-send2", "2-send3", "2-receive1", "2-receive2" ,"2-receive3",#
"sibling1", "sibling2" ,"sibling3", "cosibling1", "cosibling2", "cosibling3")#
DareB2 = melt(DareB2)#
#
DareB$IP = 1#
DareB2$IP = 2#
DareBnew = rbind(DareB, DareB2)[,-1]#
DareBnew$IP = as.factor(DareBnew$IP)#
colnames(DareBnew) = c("Netstat", "Estimate", "IP")#
DareBnew$Netstat = factor(DareBnew$Netstat, levels =  c( "intercept",#
"outdegree1", "outdegree2", "outdegree3", "indegree1", "indegree2", "indegree3",#
"send1", "send2", "send3" ,"receive1", "receive2", "receive3",#
"2-send1", "2-send2", "2-send3", "2-receive1", "2-receive2" ,"2-receive3",#
"sibling1", "sibling2" ,"sibling3", "cosibling1", "cosibling2", "cosibling3"))#
colnames(DareBnew) = c("Netstat", "Estimate", "IP")#
p <- ggplot(DareBnew, aes(Netstat, Estimate, colour = IP)) + geom_boxplot(aes(colour = factor(IP)), position = position_dodge()) + coord_flip() + geom_hline(yintercept = 0.0, colour = "black", size = 0.5)
p
sum(table(unlist(Daretest1$Z)) / sum(table(unlist(Daretest1$Z)))[c(1,3,5,7,9,11,13,15,17,19)]
)
sum((table(unlist(Daretest1$Z)) / sum(table(unlist(Daretest1$Z))))[c(1,3,5,7,9,11,13,15,17,19)]
)
sum((table(unlist(Daretest1$Z)) / sum(table(unlist(Daretest1$Z))))[c(2,4,6,8,10,12,14,16,18,20)])
TableWord = function(Zchain, K, textlist, vocabulary) {#
  # Generate a table of token-topic assignments with high probabilities for each IP#
  ##
  # Args #
  #  Zchain summary of Z obtained using MCMC function#
  #  K total number of topics specified by the user#
  #  textlist list of text containing the words in each document#
  #  vocabulary all vocabularies used over the corpus#
  ##
  # Returns#
  #  List of table that summarize token-topic assignments for each IP#
  W = length(vocabulary)#
    Zsummary = list()#
    topic.word = matrix(0, nrow = K, ncol = W)#
    colnames(topic.word) = vocabulary#
    iter = 1#
    for (d in seq(along = textlist)) {#
      if (length(Zchain[[d]]) > 0){#
        Zsummary[[iter]] = Zchain[[d]]#
        names(Zsummary[[iter]])<- vocabulary[textlist[[d]]]#
        iter = iter+1#
      }#
    }#
    topic.dist = t(tabulate(unlist(Zsummary), K)/length(unlist(Zsummary)))#
    colnames(topic.dist) = c(1L:K)#
    top.topic = topic.dist[, order(topic.dist, decreasing = TRUE)]#
    all.word = unlist(Zsummary)#
    for (i in seq(along = all.word)){#
      matchWZ = which(colnames(topic.word) == names(all.word[i]))#
      topic.word[all.word[i], matchWZ] = topic.word[all.word[i], matchWZ] + 1#
    }#
    table.word = top.topic.words(topic.word, num.words = 15, by.score = TRUE)#
    colnames(table.word) = names(top.topic)#
  return(table.word)#
}#
TableWord(Daretest1$Z, 20, Dare$text, Dare$vocab)
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_AMEN.RData")#
UN1 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_Dunson1.RData")#
UN2 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_Dunson2.RData")#
UN3 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_UNRE.RData")#
UN = UN
names(UN1)
UN1$kappas
mean(UN1$s2)
mean(UN2$s2)
mean(UN3$s2)
mean(UN$s2)
attach(UN)#
library(ggplot2)#
library(MCMCpack)#
library(reshape2)#
library(gridExtra)#
library(ggrepel)#
library(RColorBrewer)#
years = c(1983:2014)#
load("/Users/bomin8319/Desktop/DLFM/UNfit/UNdatafull.RData")#
attach(UNdatafull)#
library(FastGP)#
library(mvtnorm)#
library(fields)#
library(reshape)#
library(MCMCpack)#
library(expm)#
library(igraph)#
#library(devtools)#
#install_github('bomin8319/DLFM/pkg')#
library(DLFM)#
reduced <-which(dimnames(Y)[[2]] %in% c("USA", "CHN", "IND", "UKG", "FRN", "GFR", "TUR", "JPN", "ISR", "SYR", "LEB", "SUD", "IRN", "AUL", "PAK", "EGY", "AFG", "PRK", "RUS", "GRG", "UKR", "ROK", "IRQ"))#
#
#reduced <-which(dimnames(Y)[[2]] %in% c("USA", "CHN", "IND", "UKG", "FRN", "GFR", "TUR", "JPN", "ISR", "SYR", "LEB", "SUD", "IRN", "AUL", "PAK", "EGY"))#
Y = Y[, reduced, reduced]#
X = X[, reduced, reduced, 1:5]#
#
for(tp in 1:32){#
	diag(X[tp,,,2]) = 0#
}#
# not existing countries -> all missing values imputed using model (biased)#
avail1 = matrix(1, 32, 23)#
avail1[1:8, c(12, 20)] =0 #North and South Korea did not joined UN voting until 1990#
avail1[1:10, 21] = 0 #GRG no voted until 1992#
avail1[1:9, 22] = 0 #RUS X variables not existed until 1991#
avail1[1:9, 23] = 0 #UKR not existed until 1991#
avail1[13:21, 9] = 0 #IRQ under sanction#
#
load("/Users/bomin8319/Desktop/DLFM/UNfit/clang.RData")#
rownames(clang)[36] = "GFR"#
diag(clang) = 1#
Xnew = array(NA, dim = c(32,23,23,6))#
dimnames(Xnew)[1] =dimnames(X)[1]#
dimnames(Xnew)[2] =dimnames(X)[2]#
dimnames(Xnew)[3] =dimnames(X)[3]#
dimnames(Xnew)[[4]] = c("intercept", "log(distance)", "polity", "alliance", "Trade/GDP", "language")#
Xnew[,,,1:5] = X#
order = rep(NA, 23)#
for (i in 1:23){#
	if (rownames(Y[1,,])[i] %in% rownames(clang) ) {#
order[i] = which(rownames(clang)==rownames(Y[1,,])[i])#
}#
}#
order2 = order[!is.na(order)]#
clang2 = matrix(NA, 23, 23)#
rownames(clang2) = colnames(clang2)=rownames(Y[1,,])#
clang2[-c(9, 21), -c(9, 21)] = clang[order2,order2]#
clang2[9, ] = clang2[10,]#
clang2[,9 ] = clang2[,10]#
clang2[21,] = 0#
clang2[,21]  =0#
diag(clang2)= 1#
for (t in 1:32){#
	Xnew[t,,,6] = clang2#
}
Y[1,,]
UN$kappas
UN1$kappas
UN2$kappas
UN3$kappas
mean(UN$s2)
mean(UN1$s2)
mean(UN2$s2)
mean(UN3$s2)
library(DLFM)
DLFM
DLFM_Dunson
UN$kappas
UN1$kappas
UN2$kappas
DLFM_AMEN
UN$kappas
UN1$kappas
UN2$kappas
UN3$kappas
mean(UN$s2)
mean(UN1$s2)
mean(UN2$s2)
mean(UN3$s2)
DAME = UN
AMEN = UN1
Dunson1 = UN2
Dunson2 = UN3
DAME$kappas
AMEN$kappas
Dunson1$kappas
Dunson2$kappas
mean(DAME$s2)
mean(AMEN$s2)
mean(Dunson1$s2)
mean(Dunson2$s2)
dist_ij = c()#
                for (i in 1:Time) {#
                  for (j in 1:Time) {#
                    dist_ij = c(dist_ij, abs(i - j))#
                  }#
                }
Time
dist
dist_ij
matrix(Exponential(dist_ij, #
                    1.215233), Time, Time, byrow = TRUE)
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_AMEN.RData")
UN$kappas
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_UNRE.RData")
UN$kappas
load('~/Desktop/DLFM/UNfit/DLFM_UN.RData')
UN$kappas
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_AMEN.RData")#
UN1 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_Dunson1.RData")#
UN2 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_Dunson2.RData")#
UN3 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_UN.RData")#
UN = UN
attach(UN)#
library(ggplot2)#
library(MCMCpack)#
library(reshape2)#
library(gridExtra)#
library(ggrepel)#
library(RColorBrewer)#
years = c(1983:2014)#
load("/Users/bomin8319/Desktop/DLFM/UNfit/UNdatafull.RData")#
attach(UNdatafull)#
library(FastGP)#
library(mvtnorm)#
library(fields)#
library(reshape)#
library(MCMCpack)#
library(expm)#
library(igraph)#
#library(devtools)#
#install_github('bomin8319/DLFM/pkg')#
library(DLFM)#
reduced <-which(dimnames(Y)[[2]] %in% c("USA", "CHN", "IND", "UKG", "FRN", "GFR", "TUR", "JPN", "ISR", "SYR", "LEB", "SUD", "IRN", "AUL", "PAK", "EGY", "AFG", "PRK", "RUS", "GRG", "UKR", "ROK", "IRQ"))#
#
#reduced <-which(dimnames(Y)[[2]] %in% c("USA", "CHN", "IND", "UKG", "FRN", "GFR", "TUR", "JPN", "ISR", "SYR", "LEB", "SUD", "IRN", "AUL", "PAK", "EGY"))#
Y = Y[, reduced, reduced]#
X = X[, reduced, reduced, 1:5]#
#
for(tp in 1:32){#
	diag(X[tp,,,2]) = 0#
}#
# not existing countries -> all missing values imputed using model (biased)#
avail1 = matrix(1, 32, 23)#
avail1[1:8, c(12, 20)] =0 #North and South Korea did not joined UN voting until 1990#
avail1[1:10, 21] = 0 #GRG no voted until 1992#
avail1[1:9, 22] = 0 #RUS X variables not existed until 1991#
avail1[1:9, 23] = 0 #UKR not existed until 1991#
avail1[13:21, 9] = 0 #IRQ under sanction#
#
load("/Users/bomin8319/Desktop/DLFM/UNfit/clang.RData")#
rownames(clang)[36] = "GFR"#
diag(clang) = 1#
Xnew = array(NA, dim = c(32,23,23,6))#
dimnames(Xnew)[1] =dimnames(X)[1]#
dimnames(Xnew)[2] =dimnames(X)[2]#
dimnames(Xnew)[3] =dimnames(X)[3]#
dimnames(Xnew)[[4]] = c("intercept", "log(distance)", "polity", "alliance", "Trade/GDP", "language")#
Xnew[,,,1:5] = X#
order = rep(NA, 23)#
for (i in 1:23){#
	if (rownames(Y[1,,])[i] %in% rownames(clang) ) {#
order[i] = which(rownames(clang)==rownames(Y[1,,])[i])#
}#
}#
order2 = order[!is.na(order)]#
clang2 = matrix(NA, 23, 23)#
rownames(clang2) = colnames(clang2)=rownames(Y[1,,])#
clang2[-c(9, 21), -c(9, 21)] = clang[order2,order2]#
clang2[9, ] = clang2[10,]#
clang2[,9 ] = clang2[,10]#
clang2[21,] = 0#
clang2[,21]  =0#
diag(clang2)= 1#
for (t in 1:32){#
	Xnew[t,,,6] = clang2#
}
## side by side #
hi = factor(1983:2014)#
hello = list()#
hello2 = list()#
hello3 = list()#
hello4 = list()#
hellonew = list()#
mean = list()#
countrynames = sort(rownames(U[[32]]))#
#
n2 = 1#
for 	(n in 1:23){#
	hello[[n]] = matrix(NA, nrow = 0, ncol = 3)#
	mean[[n]] = matrix(NA, nrow = 0, ncol = 2)#
	for (d in 1:32){#
	hello[[n]]  = rbind(hello[[n]], cbind(UN$Degree[[d]][,n2], rep(hi[d], length(UN$Degree[[d]][,n2])), rep("DAME", length(UN$Degree[[d]][,n2]))))#
	diag(Y[d,, ])= 0#
	Y[d, which(avail1[d,]==0), ] = 0#
	Y[d, , which(avail1[d,]==0)] = 0#
	mean[[n]] = rbind(mean[[n]], c(rowSums(Y[d,,], na.rm=TRUE)[n2], hi[d]))#
}#
colnames(hello[[n]]) = c("Degree", "Year", "Model")#
hello[[n]] = as.data.frame(hello[[n]])#
hello[[n]]$Year = factor(sort(as.numeric(hello[[n]]$Year)), labels = c(1983:2014))#
#
	hello2[[n]] = matrix(NA, nrow = 0, ncol = 3)#
	for (d in 1:32){#
	hello2[[n]]  = rbind(hello2[[n]], cbind(UN1$Degree[[d]][,n2], rep(hi[d], length(UN1$Degree[[d]][,n2])), rep("AMEN", length(UN1$Degree[[d]][,n2]))))#
	}#
colnames(hello2[[n]]) = c("Degree", "Year", "Model")#
hello2[[n]] = as.data.frame(hello2[[n]])#
hello2[[n]]$Year = factor(sort(as.numeric(hello2[[n]]$Year)), labels = c(1983:2014))#
#
#hello3[[n]] = matrix(NA, nrow = 0, ncol = 3)#
#	for (d in 1:32){#
#	hello3[[n]]  = rbind(hello3[[n]], cbind(UN2$Degree[[d]][,n2], rep(hi[d], length(UN2$Degree[[d]][,n2])), rep("Dunson1", length(UN2$Degree[[d]][,n2]))))#
#	}#
#colnames(hello3[[n]]) = c("Degree", "Year", "Model")#
#hello3[[n]] = as.data.frame(hello3[[n]])#
#hello3[[n]]$Year = factor(sort(as.numeric(hello3[[n]]$Year)), labels = c(1983:2014))#
#
hello4[[n]] = matrix(NA, nrow = 0, ncol = 3)#
	for (d in 1:32){#
	hello4[[n]]  = rbind(hello4[[n]], cbind(UN3$Degree[[d]][,n2], rep(hi[d], length(UN3$Degree[[d]][,n2])), rep("DLSM", length(UN3$Degree[[d]][,n2]))))#
	}#
colnames(hello4[[n]]) = c("Degree", "Year", "Model")#
hello4[[n]] = as.data.frame(hello4[[n]])#
hello4[[n]]$Year = factor(sort(as.numeric(hello4[[n]]$Year)), labels = c(1983:2014))#
#
hellonew[[n]] = as.data.frame(rbind(hello[[n]], hello2[[n]], hello4[[n]]))#
colnames(mean[[n]]) =  c("Degree", "Year")#
mean[[n]] = as.data.frame(mean[[n]])#
n2 = n2 + 1#
}#
#
countryname = (rownames(U[[32]]))#
countryname2 = (rownames(U[[32]]))#
ggplotColours <- function(n = 6, h = c(0, 360) + 15){#
  if ((diff(h) %% 360) < 1) h[2] <- h[2] - 360/n#
  hcl(h = (seq(h[1], h[2], length = n)), c = 100, l = 65)#
}#
#
countrynames = ggplotColours(23)#
p10 = list()#
n2 = 1#
MSE = list()#
for (n in 1:23){#
	hellonew[[n]]$Degree = as.numeric(as.character(hellonew[[n]]$Degree))#
p10[[n]] = ggplot(hellonew[[n]], aes(x = Year, y = Degree, colour = as.factor(Model))) + geom_boxplot(outlier.size = 0.5, position = position_dodge()) + theme_bw() + scale_colour_discrete(name = countryname[n]) + geom_line(data = mean[[n]], colour = "grey60", size = 0.8)#
#annotate("text", 30, 10, size = 5, label = countryname2[n], colour = countrynames[n])#
print(countryname2[n])#
MSE[[n]] = rowSums(#
rbind(sapply(1:32, function(t){ mean((hellonew[[n]][which(hellonew[[n]]$Year == years[t] & hellonew[[n]]$Model == "DAME"), 1] - mean[[n]][t, 1])^2)}),#
sapply(1:32, function(t){ mean((hellonew[[n]][which(hellonew[[n]]$Year == years[t] & hellonew[[n]]$Model == "AMEN"), 1] - mean[[n]][t, 1])^2)}),#
sapply(1:32, function(t){ mean((hellonew[[n]][which(hellonew[[n]]$Year == years[t] & hellonew[[n]]$Model == "DLSM"), 1] - mean[[n]][t, 1])^2)}))#
)#
print(MSE[[n]])#
n2 = n2 + 1#
#
mname = paste0(countryname2[n], n, "three", ".png")#
print(p10[[n]])
}
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_AMEN.RData")#
UN1 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_Dunson1.RData")#
UN2 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_Dunson2.RData")#
UN3 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_UN.RData")#
UN = UN
attach(UN)#
library(ggplot2)#
library(MCMCpack)#
library(reshape2)#
library(gridExtra)#
library(ggrepel)#
library(RColorBrewer)#
years = c(1983:2014)#
load("/Users/bomin8319/Desktop/DLFM/UNfit/UNdatafull.RData")#
attach(UNdatafull)#
library(FastGP)#
library(mvtnorm)#
library(fields)#
library(reshape)#
library(MCMCpack)#
library(expm)#
library(igraph)#
#library(devtools)#
#install_github('bomin8319/DLFM/pkg')#
library(DLFM)#
reduced <-which(dimnames(Y)[[2]] %in% c("USA", "CHN", "IND", "UKG", "FRN", "GFR", "TUR", "JPN", "ISR", "SYR", "LEB", "SUD", "IRN", "AUL", "PAK", "EGY", "AFG", "PRK", "RUS", "GRG", "UKR", "ROK", "IRQ"))#
#
#reduced <-which(dimnames(Y)[[2]] %in% c("USA", "CHN", "IND", "UKG", "FRN", "GFR", "TUR", "JPN", "ISR", "SYR", "LEB", "SUD", "IRN", "AUL", "PAK", "EGY"))#
Y = Y[, reduced, reduced]#
X = X[, reduced, reduced, 1:5]#
#
for(tp in 1:32){#
	diag(X[tp,,,2]) = 0#
}#
# not existing countries -> all missing values imputed using model (biased)#
avail1 = matrix(1, 32, 23)#
avail1[1:8, c(12, 20)] =0 #North and South Korea did not joined UN voting until 1990#
avail1[1:10, 21] = 0 #GRG no voted until 1992#
avail1[1:9, 22] = 0 #RUS X variables not existed until 1991#
avail1[1:9, 23] = 0 #UKR not existed until 1991#
avail1[13:21, 9] = 0 #IRQ under sanction#
#
load("/Users/bomin8319/Desktop/DLFM/UNfit/clang.RData")#
rownames(clang)[36] = "GFR"#
diag(clang) = 1#
Xnew = array(NA, dim = c(32,23,23,6))#
dimnames(Xnew)[1] =dimnames(X)[1]#
dimnames(Xnew)[2] =dimnames(X)[2]#
dimnames(Xnew)[3] =dimnames(X)[3]#
dimnames(Xnew)[[4]] = c("intercept", "log(distance)", "polity", "alliance", "Trade/GDP", "language")#
Xnew[,,,1:5] = X#
order = rep(NA, 23)#
for (i in 1:23){#
	if (rownames(Y[1,,])[i] %in% rownames(clang) ) {#
order[i] = which(rownames(clang)==rownames(Y[1,,])[i])#
}#
}#
order2 = order[!is.na(order)]#
clang2 = matrix(NA, 23, 23)#
rownames(clang2) = colnames(clang2)=rownames(Y[1,,])#
clang2[-c(9, 21), -c(9, 21)] = clang[order2,order2]#
clang2[9, ] = clang2[10,]#
clang2[,9 ] = clang2[,10]#
clang2[21,] = 0#
clang2[,21]  =0#
diag(clang2)= 1#
for (t in 1:32){#
	Xnew[t,,,6] = clang2#
}#
beta = lapply(1:32, function(t){summary(mcmc(BETA[[t]][101:500,]))[[2]]})#
betas = list()#
for (i in 1:6) {betas[[i]] = sapply(1:32, function(t){beta[[t]][i,]})}#
#
number_ticks <- function(n) {function(limits) pretty(limits, n)}#
plots = list()#
i= 1#
years = c(1983:2014)#
data = data.frame(cbind(years,t(betas[[i]])))#
 colnames(data)[4] = "beta"#
 f = ggplot(data, aes(x = years))#
f + geom_line(aes(y = beta), colour="blue") + geom_ribbon(aes(ymin = X2.5., ymax = X97.5.), alpha = 0.1) + scale_x_continuous(breaks=number_ticks(8))+ylab("Intercept") + theme_bw()#
#
color = c("red", "orange", "green", "purple", "pink")#
varname = c("log(distance)", "Polity", "Alliance", "Lower trade-to-GDP ratio", "Common Language")#
for (i in 2:6){#
years = c(1983:2014)#
data = data.frame(cbind(years,t(betas[[i]])))#
 colnames(data)[4] = "beta"#
 f = ggplot(data, aes(x = years))#
 plots[[i]] <- f + geom_line(aes(y = beta), colour=color[i-1]) + geom_ribbon(aes(ymin = X2.5., ymax = X97.5.), alpha = 0.1) + ylab(varname[i-1]) + scale_x_continuous(breaks=number_ticks(8)) + geom_hline(yintercept = 0) + theme_bw()#
#
 }
marrangeGrob(plots[2:6], nrow = 2, ncol = 3, top = NULL)
#external comparison#
#
## side by side #
hi = factor(1983:2014)#
hello = list()#
hello2 = list()#
hello3 = list()#
hello4 = list()#
hellonew = list()#
mean = list()#
countrynames = sort(rownames(U[[32]]))#
#
n2 = 1#
for 	(n in 1:23){#
	hello[[n]] = matrix(NA, nrow = 0, ncol = 3)#
	mean[[n]] = matrix(NA, nrow = 0, ncol = 2)#
	for (d in 1:32){#
	hello[[n]]  = rbind(hello[[n]], cbind(UN$Degree[[d]][,n2], rep(hi[d], length(UN$Degree[[d]][,n2])), rep("DAME", length(UN$Degree[[d]][,n2]))))#
	diag(Y[d,, ])= 0#
	Y[d, which(avail1[d,]==0), ] = 0#
	Y[d, , which(avail1[d,]==0)] = 0#
	mean[[n]] = rbind(mean[[n]], c(rowSums(Y[d,,], na.rm=TRUE)[n2], hi[d]))#
}#
colnames(hello[[n]]) = c("Degree", "Year", "Model")#
hello[[n]] = as.data.frame(hello[[n]])#
hello[[n]]$Year = factor(sort(as.numeric(hello[[n]]$Year)), labels = c(1983:2014))#
#
	hello2[[n]] = matrix(NA, nrow = 0, ncol = 3)#
	for (d in 1:32){#
	hello2[[n]]  = rbind(hello2[[n]], cbind(UN1$Degree[[d]][,n2], rep(hi[d], length(UN1$Degree[[d]][,n2])), rep("AMEN", length(UN1$Degree[[d]][,n2]))))#
	}#
colnames(hello2[[n]]) = c("Degree", "Year", "Model")#
hello2[[n]] = as.data.frame(hello2[[n]])#
hello2[[n]]$Year = factor(sort(as.numeric(hello2[[n]]$Year)), labels = c(1983:2014))#
#
#hello3[[n]] = matrix(NA, nrow = 0, ncol = 3)#
#	for (d in 1:32){#
#	hello3[[n]]  = rbind(hello3[[n]], cbind(UN2$Degree[[d]][,n2], rep(hi[d], length(UN2$Degree[[d]][,n2])), rep("Dunson1", length(UN2$Degree[[d]][,n2]))))#
#	}#
#colnames(hello3[[n]]) = c("Degree", "Year", "Model")#
#hello3[[n]] = as.data.frame(hello3[[n]])#
#hello3[[n]]$Year = factor(sort(as.numeric(hello3[[n]]$Year)), labels = c(1983:2014))#
#
hello4[[n]] = matrix(NA, nrow = 0, ncol = 3)#
	for (d in 1:32){#
	hello4[[n]]  = rbind(hello4[[n]], cbind(UN3$Degree[[d]][,n2], rep(hi[d], length(UN3$Degree[[d]][,n2])), rep("DLSM", length(UN3$Degree[[d]][,n2]))))#
	}#
colnames(hello4[[n]]) = c("Degree", "Year", "Model")#
hello4[[n]] = as.data.frame(hello4[[n]])#
hello4[[n]]$Year = factor(sort(as.numeric(hello4[[n]]$Year)), labels = c(1983:2014))#
#
hellonew[[n]] = as.data.frame(rbind(hello[[n]], hello2[[n]], hello4[[n]]))#
colnames(mean[[n]]) =  c("Degree", "Year")#
mean[[n]] = as.data.frame(mean[[n]])#
n2 = n2 + 1#
}#
#
countryname = (rownames(U[[32]]))#
countryname2 = (rownames(U[[32]]))#
ggplotColours <- function(n = 6, h = c(0, 360) + 15){#
  if ((diff(h) %% 360) < 1) h[2] <- h[2] - 360/n#
  hcl(h = (seq(h[1], h[2], length = n)), c = 100, l = 65)#
}#
#
countrynames = ggplotColours(23)#
p10 = list()#
n2 = 1#
MSE = list()#
for (n in 1:23){#
	hellonew[[n]]$Degree = as.numeric(as.character(hellonew[[n]]$Degree))#
p10[[n]] = ggplot(hellonew[[n]], aes(x = Year, y = Degree, colour = as.factor(Model))) + geom_boxplot(outlier.size = 0.5, position = position_dodge()) + theme_bw() + scale_colour_discrete(name = countryname[n]) + geom_line(data = mean[[n]], colour = "grey60", size = 0.8)#
#annotate("text", 30, 10, size = 5, label = countryname2[n], colour = countrynames[n])#
print(countryname2[n])#
MSE[[n]] = rowSums(#
rbind(sapply(1:32, function(t){ mean((hellonew[[n]][which(hellonew[[n]]$Year == years[t] & hellonew[[n]]$Model == "DAME"), 1] - mean[[n]][t, 1])^2)}),#
sapply(1:32, function(t){ mean((hellonew[[n]][which(hellonew[[n]]$Year == years[t] & hellonew[[n]]$Model == "AMEN"), 1] - mean[[n]][t, 1])^2)}),#
sapply(1:32, function(t){ mean((hellonew[[n]][which(hellonew[[n]]$Year == years[t] & hellonew[[n]]$Model == "DLSM"), 1] - mean[[n]][t, 1])^2)}))#
)#
print(MSE[[n]])#
n2 = n2 + 1#
#
mname = paste0(countryname2[n], n, "three", ".png")#
print(p10[[n]])
}
names(UN)
head(UN$BETA[[1]])
mean(UN$s2)
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_AMEN.RData")#
UN1 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_Dunson1.RData")#
UN2 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_Dunson2.RData")#
UN3 = UN#
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_UNRE.RData")#
UN = UN#
#
attach(UN)#
library(ggplot2)#
library(MCMCpack)#
library(reshape2)#
library(gridExtra)#
library(ggrepel)#
library(RColorBrewer)#
years = c(1983:2014)#
load("/Users/bomin8319/Desktop/DLFM/UNfit/UNdatafull.RData")#
attach(UNdatafull)#
library(FastGP)#
library(mvtnorm)#
library(fields)#
library(reshape)#
library(MCMCpack)#
library(expm)#
library(igraph)#
#library(devtools)#
#install_github('bomin8319/DLFM/pkg')#
library(DLFM)#
reduced <-which(dimnames(Y)[[2]] %in% c("USA", "CHN", "IND", "UKG", "FRN", "GFR", "TUR", "JPN", "ISR", "SYR", "LEB", "SUD", "IRN", "AUL", "PAK", "EGY", "AFG", "PRK", "RUS", "GRG", "UKR", "ROK", "IRQ"))#
#
#reduced <-which(dimnames(Y)[[2]] %in% c("USA", "CHN", "IND", "UKG", "FRN", "GFR", "TUR", "JPN", "ISR", "SYR", "LEB", "SUD", "IRN", "AUL", "PAK", "EGY"))#
Y = Y[, reduced, reduced]#
X = X[, reduced, reduced, 1:5]#
#
for(tp in 1:32){#
	diag(X[tp,,,2]) = 0#
}#
# not existing countries -> all missing values imputed using model (biased)#
avail1 = matrix(1, 32, 23)#
avail1[1:8, c(12, 20)] =0 #North and South Korea did not joined UN voting until 1990#
avail1[1:10, 21] = 0 #GRG no voted until 1992#
avail1[1:9, 22] = 0 #RUS X variables not existed until 1991#
avail1[1:9, 23] = 0 #UKR not existed until 1991#
avail1[13:21, 9] = 0 #IRQ under sanction#
#
load("/Users/bomin8319/Desktop/DLFM/UNfit/clang.RData")#
rownames(clang)[36] = "GFR"#
diag(clang) = 1#
Xnew = array(NA, dim = c(32,23,23,6))#
dimnames(Xnew)[1] =dimnames(X)[1]#
dimnames(Xnew)[2] =dimnames(X)[2]#
dimnames(Xnew)[3] =dimnames(X)[3]#
dimnames(Xnew)[[4]] = c("intercept", "log(distance)", "polity", "alliance", "Trade/GDP", "language")#
Xnew[,,,1:5] = X#
order = rep(NA, 23)#
for (i in 1:23){#
	if (rownames(Y[1,,])[i] %in% rownames(clang) ) {#
order[i] = which(rownames(clang)==rownames(Y[1,,])[i])#
}#
}#
order2 = order[!is.na(order)]#
clang2 = matrix(NA, 23, 23)#
rownames(clang2) = colnames(clang2)=rownames(Y[1,,])#
clang2[-c(9, 21), -c(9, 21)] = clang[order2,order2]#
clang2[9, ] = clang2[10,]#
clang2[,9 ] = clang2[,10]#
clang2[21,] = 0#
clang2[,21]  =0#
diag(clang2)= 1#
for (t in 1:32){#
	Xnew[t,,,6] = clang2#
}
## side by side #
hi = factor(1983:2014)#
hello = list()#
hello2 = list()#
hello3 = list()#
hello4 = list()#
hellonew = list()#
mean = list()#
countrynames = sort(rownames(U[[32]]))#
#
n2 = 1#
for 	(n in 1:23){#
	hello[[n]] = matrix(NA, nrow = 0, ncol = 3)#
	mean[[n]] = matrix(NA, nrow = 0, ncol = 2)#
	for (d in 1:32){#
	hello[[n]]  = rbind(hello[[n]], cbind(UN$Degree[[d]][,n2], rep(hi[d], length(UN$Degree[[d]][,n2])), rep("DAME", length(UN$Degree[[d]][,n2]))))#
	diag(Y[d,, ])= 0#
	Y[d, which(avail1[d,]==0), ] = 0#
	Y[d, , which(avail1[d,]==0)] = 0#
	mean[[n]] = rbind(mean[[n]], c(rowSums(Y[d,,], na.rm=TRUE)[n2], hi[d]))#
}#
colnames(hello[[n]]) = c("Degree", "Year", "Model")#
hello[[n]] = as.data.frame(hello[[n]])#
hello[[n]]$Year = factor(sort(as.numeric(hello[[n]]$Year)), labels = c(1983:2014))#
#
	hello2[[n]] = matrix(NA, nrow = 0, ncol = 3)#
	for (d in 1:32){#
	hello2[[n]]  = rbind(hello2[[n]], cbind(UN1$Degree[[d]][,n2], rep(hi[d], length(UN1$Degree[[d]][,n2])), rep("AMEN", length(UN1$Degree[[d]][,n2]))))#
	}#
colnames(hello2[[n]]) = c("Degree", "Year", "Model")#
hello2[[n]] = as.data.frame(hello2[[n]])#
hello2[[n]]$Year = factor(sort(as.numeric(hello2[[n]]$Year)), labels = c(1983:2014))#
#
#hello3[[n]] = matrix(NA, nrow = 0, ncol = 3)#
#	for (d in 1:32){#
#	hello3[[n]]  = rbind(hello3[[n]], cbind(UN2$Degree[[d]][,n2], rep(hi[d], length(UN2$Degree[[d]][,n2])), rep("Dunson1", length(UN2$Degree[[d]][,n2]))))#
#	}#
#colnames(hello3[[n]]) = c("Degree", "Year", "Model")#
#hello3[[n]] = as.data.frame(hello3[[n]])#
#hello3[[n]]$Year = factor(sort(as.numeric(hello3[[n]]$Year)), labels = c(1983:2014))#
#
hello4[[n]] = matrix(NA, nrow = 0, ncol = 3)#
	for (d in 1:32){#
	hello4[[n]]  = rbind(hello4[[n]], cbind(UN3$Degree[[d]][,n2], rep(hi[d], length(UN3$Degree[[d]][,n2])), rep("DLSM", length(UN3$Degree[[d]][,n2]))))#
	}#
colnames(hello4[[n]]) = c("Degree", "Year", "Model")#
hello4[[n]] = as.data.frame(hello4[[n]])#
hello4[[n]]$Year = factor(sort(as.numeric(hello4[[n]]$Year)), labels = c(1983:2014))#
#
hellonew[[n]] = as.data.frame(rbind(hello[[n]], hello2[[n]], hello4[[n]]))#
colnames(mean[[n]]) =  c("Degree", "Year")#
mean[[n]] = as.data.frame(mean[[n]])#
n2 = n2 + 1#
}#
#
countryname = (rownames(U[[32]]))#
countryname2 = (rownames(U[[32]]))#
ggplotColours <- function(n = 6, h = c(0, 360) + 15){#
  if ((diff(h) %% 360) < 1) h[2] <- h[2] - 360/n#
  hcl(h = (seq(h[1], h[2], length = n)), c = 100, l = 65)#
}#
#
countrynames = ggplotColours(23)#
p10 = list()#
n2 = 1#
MSE = list()#
for (n in 1:23){#
	hellonew[[n]]$Degree = as.numeric(as.character(hellonew[[n]]$Degree))#
p10[[n]] = ggplot(hellonew[[n]], aes(x = Year, y = Degree, colour = as.factor(Model))) + geom_boxplot(outlier.size = 0.5, position = position_dodge()) + theme_bw() + scale_colour_discrete(name = countryname[n]) + geom_line(data = mean[[n]], colour = "grey60", size = 0.8)#
#annotate("text", 30, 10, size = 5, label = countryname2[n], colour = countrynames[n])#
print(countryname2[n])#
MSE[[n]] = rowSums(#
rbind(sapply(1:32, function(t){ mean((hellonew[[n]][which(hellonew[[n]]$Year == years[t] & hellonew[[n]]$Model == "DAME"), 1] - mean[[n]][t, 1])^2)}),#
sapply(1:32, function(t){ mean((hellonew[[n]][which(hellonew[[n]]$Year == years[t] & hellonew[[n]]$Model == "AMEN"), 1] - mean[[n]][t, 1])^2)}),#
sapply(1:32, function(t){ mean((hellonew[[n]][which(hellonew[[n]]$Year == years[t] & hellonew[[n]]$Model == "DLSM"), 1] - mean[[n]][t, 1])^2)}))#
)#
print(MSE[[n]])#
n2 = n2 + 1#
#
mname = paste0(countryname2[n], n, "three", ".png")#
print(p10[[n]])
}
library(DLFM)
DLFM
DLFM_AMEN
library(IPTM)
set.seed(100)#
load('/Users/bomin8319/Desktop/IPTM/paper/code/Darenew.RData')#
# 762 - #
attach(Dare)#
Dare$node = 1:nrow(Dare$node)#
Dare$text = Dare$text[762:length(Dare$edge)]#
Dare$edge = Dare$edge[762:length(Dare$edge)]#
Dare$edge = Dare$edge[-which(sapply(Dare$text, function(d){length(d)})==0)]#
Dare$text = Dare$text[-which(sapply(Dare$text, function(d){length(d)})==0)]#
mintime = Dare$edge[[1]][[3]]#
for (n in 1:length(Dare$edge)){#
  Dare$edge[[n]][3] = (Dare$edge[[n]][[3]] - mintime) / 3600#
}#
Dare$edge = lapply(Dare$edge, function(x){x[1:3]})
load("/Users/bomin8319/Desktop/IPTM/paper/code/Daretest.RData")#
output = Daretest#
initial = list(C = output$C, D = output$D[200], B = lapply(1:2, function(IP){output$B[[IP]][,500]}), Z =output$Z)
Daretest1 <- IPTM_inference.data2(Dare$edge, Dare$node, Dare$text, Dare$vocab, nIP = 2, K = 20, sigma_Q = c(0.00005, 0.0075),#
                        alpha = 2, mvec = rep(1/20, 20), betas = 2, nvec = rep(1/length(Dare$vocab), length(Dare$vocab)), #
                        prior.b.mean = c(-3, rep(0, 24)), #
                       prior.b.var = 1 * diag(25), prior.delta = c(0, 1), out = 1, n_B = 10000, n_d = 1000, burn = c(0,0), #
                       thinning =  c(1,1), netstat = c("intercept", "dyadic", "degree", "triadic"), plot = FALSE, optimize = TRUE, #
                       initial = initial)
Daretest1 <- IPTM_inference.data2(Dare$edge, Dare$node, Dare$text, Dare$vocab, nIP = 2, K = 20, sigma_Q = c(0.00005, 0.0075),#
                        alpha = 2, mvec = rep(1/20, 20), betas = 2, nvec = rep(1/length(Dare$vocab), length(Dare$vocab)), #
                        prior.b.mean = c(-3, rep(0, 24)), #
                       prior.b.var = 1 * diag(25), prior.delta = c(0, 1), out = 1, n_B = 15000, n_d = 1500, burn = c(0,0), #
                       thinning =  c(1,1), netstat = c("intercept", "dyadic", "degree", "triadic"), plot = FALSE, optimize = TRUE, #
                       initial = initial)
load("/Users/bomin8319/Desktop/DLFM/UNfit/DLFM_UNRE.RData")#
UN = UN#
#
kappas = UN$kappas
kappas
beta = lapply(1:32, function(t){summary(mcmc(UN1[[t]]$BETA))[[2]]})
library(MCMCpack)
library(coda)
beta = lapply(1:32, function(t){summary(mcmc(UN1[[t]]$BETA))[[2]]})
beta = lapply(1:32, function(t){summary(mcmc(UN[[t]]$BETA))[[2]]})
beta
beta = lapply(1:32, function(t){summary(mcmc(UN$BETA[[t]]))[[2]]})
beta
head(UN$BETA[[t]])
t = 1
head(UN$BETA[[t]])
beta = lapply(1:32, function(t){colMeans(UN$BETA[[t]])})
beta
median_absolute_error
library(car)#
library(Hmisc)                                                     #
library(mvtnorm)#
library(foreign)#
library(graphics)#
library(MASS)#
library(lattice)#
library(tseries)#
library(Matrix)#
library(Design)#
library(msm)#
library(corpcor)#
library(Zelig)#
Results1000<-read.dta("/Users/bomin8319/Desktop/BayesOFsurv/coding material/Monte Carlos/Mixture DGP/main.data1000.dta")
head(Results1000)
#clear memory#
rm( list=ls() )#
#
#load necessary libraries 						                                 #
library(foreign)#
library(Zelig)#
library(car)#
library(MASS)#
library(VGAM)#
library(plotrix)#
library(pscl)#
library(survival)#
library(msm)#
library(verification)#
library(corpcor)#
library(Design)#
library(coda)#
library(mcmcse)#
#library(devtools)#
#install_github('bomin8319/BayesOFsurv/pkg')#
library(BayesOFsurv)#
#set working directory#
setwd("/Users/bomin8319/Desktop/BayesOFsurv/coding material/Monte Carlos/Mixture DGP/")#
#
###########################################################################
###########################################################################
############################Monte Carlo####################################
###########################################################################
#
#set seed#
set.seed(3)   #
#
#set the number of observations#
n<-1000#
#
#set the number of simulations, and create matrices to store the results#
nsims<-10#
#history matrix for true estimates#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
#history matrix for cox estimates#
cox.est<-matrix(NA,nrow=nsims,ncol=2)#
#history matrix for exp estimates#
exp.est<-matrix(NA,nrow=nsims,ncol=24)#
#history matrix for weibull estimates#
weib.est<-matrix(NA,nrow=nsims,ncol=30)#
#history matrix for cox RMSE#
cox.rmse<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp RMSE#
exp.rmse<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp RMSE#
weib.rmse<-matrix(NA,nrow=nsims,ncol=15)#
#history matrix for cox CP#
cox.cp<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp CP#
exp.cp<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp CP#
weib.cp<-matrix(NA,nrow=nsims,ncol=15)#
main.data<-cbind(tru.est,cox.est,exp.est,weib.est,cox.rmse,exp.rmse,weib.rmse,cox.cp,exp.cp,weib.cp)#
colnames(main.data)<-c("true.x0","true.x1","true.z0","true.z1","true.z2","true.p","cen.lat","cen.obs",#
                       "cox.x1","cox.x1.se",#
                       "exp.x0","exp.x0.se","exp.x1","exp.x1.se",#
                       "zexp.z0","zexp.z0.se","zexp.z1","zexp.z1.se","zexp.z2","zexp.z2.se","zexp.x0","zexp.x0.se","zexp.x1","zexp.x1.se",#
                       "bzexp.x0","zexp.x0.se","bzexp.x1","bzexp.x1.se","bzexp.z0","bzexp.z0.se","bzexp.z1","bzexp.z1.se","bzexp.z2","bzexp.z2.se",#
                       "wei.x0","wei.x0.se","wei.x1","wei.x1.se","wei.p","wei.p.se",#
                       "zwei.z0","zwei.z0.se","zwei.z1","zwei.z1.se","zwei.z2","zwei.z2.se","zwei.x0","zwei.x0.se","zwei.x1","zwei.x1.se","zwei.p","zwei.p.se",#
                       "bzwei.x0","bzwei.x0.se","bzwei.x1","bzwei.x1.se","bzwei.z0","bzwei.z0.se","bzwei.z1","bzwei.z1.se","bzwei.z2","bzwei.z2.se","bzwei.p","bzwei.p.se",#
                       "cox.x1.rmse",#
                       "exp.x0.rmse","exp.x1.rmse","zexp.z0.rmse","zexp.z1.rmse","zexp.z2.rmse","zexp.x0.rmse","zexp.x1.rmse","bzexp.x0.rmse","bzexp.x1.rmse","bzexp.z0.rmse","bzexp.z1.rmse","bzexp.z2.rmse",#
                       "wei.x0.rmse","wei.x1.rmse","wei.p.rmse","zwei.z0.rmse","zwei.z1.rmse","zwei.z2.rmse",#
                       "zwei.x0.rmse","zwei.x1.rmse","zwei.p.rmse", "bzwei.x0.rmse","bzwei.x1.rmse","bzwei.z0.rmse","bzwei.z1.rmse","bzwei.z2.rmse","bzwei.p.rmse",#
                       "cox.x1.cp","exp.x0.cp","exp.x1.cp","zexp.z0.cp","zexp.z1.cp","zexp.z2.cp","zexp.x0.cp","zexp.x1.cp","bzexp.x0.cp","bzexp.x1.cp","bzexp.z0.cp","bzexp.z1.cp","bzexp.z2.cp",#
                       "wei.x0.cp","wei.x1.cp","wei.p.cp",#
                       "zwei.z0.cp","zwei.z1.cp","zwei.z2.cp","zwei.x0.cp","zwei.x1.cp","zwei.p.cp", "bzwei.x0.cp","bzwei.x1.cp","bzwei.z0.cp","bzwei.z1.cp","bzwei.z2.cp","bzwei.p.cp")#
#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
#create a dependent variable, begin the simmulations#
for(i in 1:nsims){#
  print(i)#
#Assign parameter values#
tru.est[i,1]<-1#
tru.est[i,2]<-3.5#
tru.est[i,3]<--2#
tru.est[i,4]<-2#
tru.est[i,5]<-3#
tru.est[i,6]<-1#
#
myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
y <- rexp(n, rate = myrates) # generates the r.v.#
cen <- rexp(n, rate = 1 )#
ycen <- pmin(y, cen)#
di <- as.numeric(y <= cen)#
tru.est[i,7]<-table(di)[1]#
#
#create parameters for ZG#
phi<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
print(mean(phi))#
yzero<-matrix(1,n,1)#
error<--1*rlogis(n)#
flag<-error<qlogis(phi)#
yzero[flag]<-error[flag]#
flag<-yzero==1#
di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
tru.est[i,8]<-table(di)[1]#
#
data<-cbind(ycen,di,x,z)#
######################################################################################
###################################COX Model##########################################
######################################################################################
#
#store estimate and se#
cox.est[i,1]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[1]#
cox.est[i,2]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[3]#
#
#store rmse#
cox.rmse[i,1]<-sqrt((tru.est[i,2]-cox.est[i,1])^2)#
#
#calculate upper and lower 95% CI's#
b1.lower<-cox.est[i,1]-(1.959964*cox.est[i,2])#
b1.upper<-cox.est[i,1]+(1.959964*cox.est[i,2])#
#
#store coverage parameters#
cox.cp[i,1]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
##############################################################################
########################Simple Exponential Model##############################
##############################################################################
Exponential<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)]#
	XB<-X%*%beta#
	llik<-C*(XB-exp(XB)*Y)+(1-C)*(-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Exponential<-try(optim(f=Exponential,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Exponential)=="list"){#
	ifelse(is.positive.definite(output.Exponential$hessian)==TRUE,vcv<-solve(output.Exponential$hessian),vcv<-matrix(data=NA,nrow=2,ncol=2))#
#
#store betas and ses#
exp.est[i,1]<-output.Exponential$par[1]#
exp.est[i,2]<-sqrt(vcv[1,1])#
exp.est[i,3]<-output.Exponential$par[2]#
exp.est[i,4]<-sqrt(vcv[2,2])#
#
#store rmse#
exp.rmse[i,1]<-sqrt((tru.est[i,1]-exp.est[i,1])^2)#
exp.rmse[i,2]<-sqrt((tru.est[i,2]-exp.est[i,3])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-exp.est[i,1]-(1.959964*exp.est[i,2])#
b0.upper<-exp.est[i,1]+(1.959964*exp.est[i,2])#
b1.lower<-exp.est[i,3]-(1.959964*exp.est[i,4])#
b1.upper<-exp.est[i,3]+(1.959964*exp.est[i,4])#
#store coverage parameters#
exp.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
#################################################################################
#########################Simple Weibull Model ###################################
#################################################################################
#
#Note this estiamtes the model via hazard rates, a la Stata#
#
test<-survreg(Surv(ycen, di)~x, dist="weibull")#
summary(test)#
Weibull<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)-1]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	llik<-C*(log(exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*log(exp(-(exp(XB+1/p)*Y)^p))#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(exp.est[i,1],exp.est[i,3],.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Weibull<-try(optim(f=Weibull,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Weibull)=="list"){#
	ifelse(is.positive.definite(output.Weibull$hessian)==TRUE,vcv<-solve(output.Weibull$hessian),vcv<-matrix(data=NA,nrow=3,ncol=3))#
#
#store betas and ses#
weib.est[i,1]<-output.Weibull$par[1]+1/exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,1],output.Weibull$par[3])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,3]#
varcov[2,1]<-vcv[3,1]#
varcov[2,2]<-vcv[3,3]#
weib.est[i,2]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,3]<-output.Weibull$par[2]#
weib.est[i,4]<-sqrt(vcv[2,2])#
weib.est[i,5]<-exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,5])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[3,3]#
weib.est[i,6]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,1]<-sqrt((tru.est[i,1]-weib.est[i,1])^2)#
weib.rmse[i,2]<-sqrt((tru.est[i,2]-weib.est[i,3])^2)#
weib.rmse[i,3]<-sqrt((tru.est[i,6]-weib.est[i,5])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-weib.est[i,1]-(1.959964*weib.est[i,2])#
b0.upper<-weib.est[i,1]+(1.959964*weib.est[i,2])#
b1.lower<-weib.est[i,3]-(1.959964*weib.est[i,4])#
b1.upper<-weib.est[i,3]+(1.959964*weib.est[i,4])#
p.lower<-weib.est[i,5]-(1.959964*weib.est[i,6])#
p.upper<-weib.est[i,5]+(1.959964*weib.est[i,6])#
#
#store coverage parameters#
weib.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,3]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
}#
#
###logit estimates####
dataset<-as.data.frame(data)#
logitcoef1<-glm(di~ z+x, data = dataset, family = "binomial")$coef[1]#
logitcoef2<-glm(di~ z+x, data = dataset, family = "binomial")$coef[2]#
logitcoef3<-glm(di~ z+x, data = dataset, family = "binomial")$coef[3]#
#
################################################################################
##########################Zombie Exponential Model##############################
################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZExponential<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):length(est)]#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-ZG))#
	llik<-C*(log((1-phi)+phi*exp(XB)*exp(-exp(XB)*Y)))+(1-C)*(log(phi)+-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,exp.est[i,1],exp.est[i,3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZExponential<-try(optim(f=ZExponential,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZExponential)=="list"){#
	ifelse(is.positive.definite(output.ZExponential$hessian)==TRUE,vcv<-solve(output.ZExponential$hessian),vcv<-matrix(data=NA,nrow=5,ncol=5))#
#
#store betas and ses#
exp.est[i,5]<-output.ZExponential$par[1]#
exp.est[i,6]<-sqrt(vcv[1,1])#
exp.est[i,7]<-output.ZExponential$par[2]#
exp.est[i,8]<-sqrt(vcv[2,2])#
exp.est[i,9]<-output.ZExponential$par[3]#
exp.est[i,10]<-sqrt(vcv[3,3])#
exp.est[i,11]<-output.ZExponential$par[4]#
exp.est[i,12]<-sqrt(vcv[4,4])#
exp.est[i,13]<-output.ZExponential$par[5]#
exp.est[i,14]<-sqrt(vcv[5,5])#
#
#store rmse#
exp.rmse[i,3]<-sqrt((tru.est[i,3]-exp.est[i,5])^2)#
exp.rmse[i,4]<-sqrt((tru.est[i,4]-exp.est[i,7])^2)#
exp.rmse[i,5]<-sqrt((tru.est[i,5]-exp.est[i,9])^2)#
exp.rmse[i,6]<-sqrt((tru.est[i,1]-exp.est[i,11])^2)#
exp.rmse[i,7]<-sqrt((tru.est[i,2]-exp.est[i,13])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-exp.est[i,5]-(1.959964*exp.est[i,6])#
g0.upper<-exp.est[i,5]+(1.959964*exp.est[i,6])#
g1.lower<-exp.est[i,7]-(1.959964*exp.est[i,8])#
g1.upper<-exp.est[i,7]+(1.959964*exp.est[i,8])#
g2.lower<-exp.est[i,9]-(1.959964*exp.est[i,10])#
g2.upper<-exp.est[i,9]+(1.959964*exp.est[i,10])#
b0.lower<-exp.est[i,11]-(1.959964*exp.est[i,12])#
b0.upper<-exp.est[i,11]+(1.959964*exp.est[i,12])#
b1.lower<-exp.est[i,13]-(1.959964*exp.est[i,14])#
b1.upper<-exp.est[i,13]+(1.959964*exp.est[i,14])#
#store coverage parameters#
exp.cp[i,3]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,4]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,5]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,6]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,7]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
######################################################################################
##########################Zombie Weibull Model #######################################
######################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZWeibull<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):(length(est)-1)]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-(ZG+1/p)))#
	llik<-C*(log((1-phi)+phi*exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*(log(phi)+-(exp(XB+1/p)*Y)^p)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,output.Weibull$par[1],output.Weibull$par[2],output.Weibull$par[3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZWeibull<-try(optim(f=ZWeibull,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZWeibull)=="list"){#
	ifelse(is.positive.definite(output.ZWeibull$hessian)==TRUE,vcv<-solve(output.ZWeibull$hessian),vcv<-matrix(data=NA,nrow=6,ncol=6))#
#
#store betas and ses#
weib.est[i,7]<-output.ZWeibull$par[1]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,7],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,6]#
varcov[2,1]<-vcv[6,1]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,8]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,9]<-output.ZWeibull$par[2]#
weib.est[i,10]<-sqrt(vcv[2,2])#
weib.est[i,11]<-output.ZWeibull$par[3]#
weib.est[i,12]<-sqrt(vcv[3,3])#
weib.est[i,13]<-output.ZWeibull$par[4]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,13],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[4,4]#
varcov[1,2]<-vcv[4,6]#
varcov[2,1]<-vcv[6,4]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,14]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,15]<-output.ZWeibull$par[5]#
weib.est[i,16]<-sqrt(vcv[5,5])#
weib.est[i,17]<-exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,17])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[6,6]#
weib.est[i,18]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,4]<-sqrt((tru.est[i,3]-weib.est[i,7])^2)#
weib.rmse[i,5]<-sqrt((tru.est[i,4]-weib.est[i,9])^2)#
weib.rmse[i,6]<-sqrt((tru.est[i,5]-weib.est[i,11])^2)#
weib.rmse[i,7]<-sqrt((tru.est[i,1]-weib.est[i,13])^2)#
weib.rmse[i,8]<-sqrt((tru.est[i,2]-weib.est[i,15])^2)#
weib.rmse[i,9]<-sqrt((tru.est[i,6]-weib.est[i,17])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-weib.est[i,7]-(1.959964*weib.est[i,8])#
g0.upper<-weib.est[i,7]+(1.959964*weib.est[i,8])#
g1.lower<-weib.est[i,9]-(1.959964*weib.est[i,10])#
g1.upper<-weib.est[i,9]+(1.959964*weib.est[i,10])#
g2.lower<-weib.est[i,11]-(1.959964*weib.est[i,12])#
g2.upper<-weib.est[i,11]+(1.959964*weib.est[i,12])#
b0.lower<-weib.est[i,13]-(1.959964*weib.est[i,14])#
b0.upper<-weib.est[i,13]+(1.959964*weib.est[i,14])#
b1.lower<-weib.est[i,15]-(1.959964*weib.est[i,16])#
b1.upper<-weib.est[i,15]+(1.959964*weib.est[i,16])#
p.lower<-weib.est[i,17]-(1.959964*weib.est[i,18])#
p.upper<-weib.est[i,17]+(1.959964*weib.est[i,18])#
#
#store coverage parameters#
weib.cp[i,4]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,5]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,6]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,7]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,8]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,9]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
}#
################################################################################
######################Bayesian Zombie Exponential Model#########################
################################################################################
##set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZExponential = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Exponential")#
output.BayesZExponential = list(par = c(summary(mcmc(BayesZExponential$beta))[[1]][,1], summary(mcmc(BayesZExponential$gamma))[[1]][,1]), #
                                se = c(summary(mcmc(BayesZExponential$beta))[[1]][,4], summary(mcmc(BayesZExponential$gamma))[[1]][,4]),#
                                CI = rbind(summary(mcmc(BayesZExponential$beta))[[2]], summary(mcmc(BayesZExponential$gamma))[[2]]))#
exp.est[i,15]<-output.BayesZExponential$par[1]#
exp.est[i,16]<-output.BayesZExponential$se[1]#
exp.est[i,17]<-output.BayesZExponential$par[2]#
exp.est[i,18]<-output.BayesZExponential$se[2]#
exp.est[i,19]<-output.BayesZExponential$par[3]#
exp.est[i,20]<-output.BayesZExponential$se[3]#
exp.est[i,21]<-output.BayesZExponential$par[4]#
exp.est[i,22]<-output.BayesZExponential$se[4]#
exp.est[i,23]<-output.BayesZExponential$par[5]#
exp.est[i,24]<-output.BayesZExponential$se[5]#
#
##store rmse#
exp.rmse[i,8]<-sqrt((tru.est[i,1]-exp.est[i,15])^2)#
exp.rmse[i,9]<-sqrt((tru.est[i,2]-exp.est[i,17])^2)#
exp.rmse[i,10]<-sqrt((tru.est[i,3]-exp.est[i,19])^2)#
exp.rmse[i,11]<-sqrt((tru.est[i,4]-exp.est[i,21])^2)#
exp.rmse[i,12]<-sqrt((tru.est[i,5]-exp.est[i,23])^2)#
##calculate upper and lower 95% CI's#
b0.lower<-output.BayesZExponential$CI[1,1]#
b0.upper<-output.BayesZExponential$CI[1,5]#
b1.lower<-output.BayesZExponential$CI[2,1]#
b1.upper<-output.BayesZExponential$CI[2,5]#
g0.lower<-output.BayesZExponential$CI[3,1]#
g0.upper<-output.BayesZExponential$CI[3,5]#
g1.lower<-output.BayesZExponential$CI[4,1]#
g1.upper<-output.BayesZExponential$CI[4,5]#
g2.lower<-output.BayesZExponential$CI[5,1]#
g2.upper<-output.BayesZExponential$CI[5,5]#
#b0.lower<-exp.est[i,15]-(1.959964*exp.est[i,16])#
#b0.upper<-exp.est[i,15]+(1.959964*exp.est[i,16])#
#b1.lower<-exp.est[i,17]-(1.959964*exp.est[i,18])#
#b1.upper<-exp.est[i,17]+(1.959964*exp.est[i,18])#
#g0.lower<-exp.est[i,19]-(1.959964*exp.est[i,20])#
#g0.upper<-exp.est[i,19]+(1.959964*exp.est[i,20])#
#g1.lower<-exp.est[i,21]-(1.959964*exp.est[i,22])#
#g1.upper<-exp.est[i,21]+(1.959964*exp.est[i,22])#
#g2.lower<-exp.est[i,23]-(1.959964*exp.est[i,24])#
#g2.upper<-exp.est[i,23]+(1.959964*exp.est[i,24])#
#store coverage parameters#
exp.cp[i,8]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,9]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,10]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,11]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,12]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
################################################################################
########################Bayesian Zombie Weibull Model###########################
################################################################################
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZWeibull = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Weibull")#
output.BayesZWeibull = list(par = c(summary(mcmc(BayesZWeibull$beta))[[1]][,1], summary(mcmc(BayesZWeibull$gamma))[[1]][,1], #
                                    summary(mcmc(BayesZWeibull$lambda))[[1]][1]), #
                            se = c(summary(mcmc(BayesZWeibull$beta))[[1]][,4], summary(mcmc(BayesZWeibull$gamma))[[1]][,4], #
                                   summary(mcmc(BayesZWeibull$lambda))[[1]][4]),#
                            CI = rbind(summary(mcmc(BayesZWeibull$beta))[[2]], summary(mcmc(BayesZWeibull$gamma))[[2]], #
                                       summary(mcmc(BayesZWeibull$lambda))[[2]]))#
weib.est[i,19]<-output.BayesZWeibull$par[1]#
weib.est[i,20]<-output.BayesZWeibull$se[1]#
weib.est[i,21]<-output.BayesZWeibull$par[2]#
weib.est[i,22]<-output.BayesZWeibull$se[2]#
weib.est[i,23]<-output.BayesZWeibull$par[3]#
weib.est[i,24]<-output.BayesZWeibull$se[3]#
weib.est[i,25]<-output.BayesZWeibull$par[4]#
weib.est[i,26]<-output.BayesZWeibull$se[4]#
weib.est[i,27]<-output.BayesZWeibull$par[5]#
weib.est[i,28]<-output.BayesZWeibull$se[5]#
weib.est[i,29]<-output.BayesZWeibull$par[6]#
weib.est[i,30]<-output.BayesZWeibull$se[6]#
#
#store rmse#
weib.rmse[i,10]<-sqrt((tru.est[i,1]-weib.est[i,19])^2)#
weib.rmse[i,11]<-sqrt((tru.est[i,2]-weib.est[i,21])^2)#
weib.rmse[i,12]<-sqrt((tru.est[i,3]-weib.est[i,23])^2)#
weib.rmse[i,13]<-sqrt((tru.est[i,4]-weib.est[i,25])^2)#
weib.rmse[i,14]<-sqrt((tru.est[i,5]-weib.est[i,27])^2)#
weib.rmse[i,15]<-sqrt((tru.est[i,6]-weib.est[i,29])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-output.BayesZWeibull$CI[1,1]#
b0.upper<-output.BayesZWeibull$CI[1,5]#
b1.lower<-output.BayesZWeibull$CI[2,1]#
b1.upper<-output.BayesZWeibull$CI[2,5]#
g0.lower<-output.BayesZWeibull$CI[3,1]#
g0.upper<-output.BayesZWeibull$CI[3,5]#
g1.lower<-output.BayesZWeibull$CI[4,1]#
g1.upper<-output.BayesZWeibull$CI[4,5]#
g2.lower<-output.BayesZWeibull$CI[5,1]#
g2.upper<-output.BayesZWeibull$CI[5,5]#
p.lower<-output.BayesZWeibull$CI[6,1]#
p.upper<-output.BayesZWeibull$CI[6,2]#
# g0.lower<-weib.est[i,19]-(1.959964*weib.est[i,20])#
# g0.upper<-weib.est[i,19]+(1.959964*weib.est[i,20])#
# g1.lower<-weib.est[i,21]-(1.959964*weib.est[i,22])#
# g1.upper<-weib.est[i,21]+(1.959964*weib.est[i,22])#
# g2.lower<-weib.est[i,23]-(1.959964*weib.est[i,24])#
# g2.upper<-weib.est[i,23]+(1.959964*weib.est[i,24])#
# b0.lower<-weib.est[i,25]-(1.959964*weib.est[i,26])#
# b0.upper<-weib.est[i,25]+(1.959964*weib.est[i,26])#
# b1.lower<-weib.est[i,27]-(1.959964*weib.est[i,28])#
# b1.upper<-weib.est[i,27]+(1.959964*weib.est[i,28])#
# p.lower<-weib.est[i,29]-(1.959964*weib.est[i,30])#
# p.upper<-weib.est[i,29]+(1.959964*weib.est[i,30])#
#
#store coverage parameters#
weib.cp[i,10]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,11]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,12]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,13]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,14]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,15]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
#combine matrices and label variables#
main.data[i, ]<-c(tru.est[i, ],cox.est[i, ],exp.est[i, ],weib.est[i, ],cox.rmse[i, ],exp.rmse[i, ],weib.rmse[i, ],#
                  cox.cp[i, ],exp.cp[i, ],weib.cp[i, ])#
#
}
head(main.data)
rm( list=ls() )#
#
#load necessary libraries 						                                 #
library(foreign)#
library(Zelig)#
library(car)#
library(MASS)#
library(VGAM)#
library(plotrix)#
library(pscl)#
library(survival)#
library(msm)#
library(verification)#
library(corpcor)#
library(Design)#
library(coda)#
library(mcmcse)#
#library(devtools)#
#install_github('bomin8319/BayesOFsurv/pkg')#
library(BayesOFsurv)#
#set working directory
mcmcOF2
#clear memory#
rm( list=ls() )#
#
#load necessary libraries 						                                 #
library(foreign)#
library(Zelig)#
library(car)#
library(MASS)#
library(VGAM)#
library(plotrix)#
library(pscl)#
library(survival)#
library(msm)#
library(verification)#
library(corpcor)#
library(Design)#
library(coda)#
library(mcmcse)#
#library(devtools)#
#install_github('bomin8319/BayesOFsurv/pkg')#
library(BayesOFsurv)#
#set working directory#
setwd("/Users/bomin8319/Desktop/BayesOFsurv/coding material/Monte Carlos/Mixture DGP/")#
#
###########################################################################
###########################################################################
############################Monte Carlo####################################
###########################################################################
#
#set seed#
set.seed(100)   #
#
#set the number of observations#
n<-1000#
#
#set the number of simulations, and create matrices to store the results#
nsims<-100#
#history matrix for true estimates#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
#history matrix for cox estimates#
cox.est<-matrix(NA,nrow=nsims,ncol=2)#
#history matrix for exp estimates#
exp.est<-matrix(NA,nrow=nsims,ncol=24)#
#history matrix for weibull estimates#
weib.est<-matrix(NA,nrow=nsims,ncol=30)#
#history matrix for cox RMSE#
cox.rmse<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp RMSE#
exp.rmse<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp RMSE#
weib.rmse<-matrix(NA,nrow=nsims,ncol=15)#
#history matrix for cox CP#
cox.cp<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp CP#
exp.cp<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp CP#
weib.cp<-matrix(NA,nrow=nsims,ncol=15)#
main.data<-cbind(tru.est,cox.est,exp.est,weib.est,cox.rmse,exp.rmse,weib.rmse,cox.cp,exp.cp,weib.cp)#
colnames(main.data)<-c("true.x0","true.x1","true.z0","true.z1","true.z2","true.p","cen.lat","cen.obs",#
                       "cox.x1","cox.x1.se",#
                       "exp.x0","exp.x0.se","exp.x1","exp.x1.se",#
                       "zexp.z0","zexp.z0.se","zexp.z1","zexp.z1.se","zexp.z2","zexp.z2.se","zexp.x0","zexp.x0.se","zexp.x1","zexp.x1.se",#
                       "bzexp.x0","zexp.x0.se","bzexp.x1","bzexp.x1.se","bzexp.z0","bzexp.z0.se","bzexp.z1","bzexp.z1.se","bzexp.z2","bzexp.z2.se",#
                       "wei.x0","wei.x0.se","wei.x1","wei.x1.se","wei.p","wei.p.se",#
                       "zwei.z0","zwei.z0.se","zwei.z1","zwei.z1.se","zwei.z2","zwei.z2.se","zwei.x0","zwei.x0.se","zwei.x1","zwei.x1.se","zwei.p","zwei.p.se",#
                       "bzwei.x0","bzwei.x0.se","bzwei.x1","bzwei.x1.se","bzwei.z0","bzwei.z0.se","bzwei.z1","bzwei.z1.se","bzwei.z2","bzwei.z2.se","bzwei.p","bzwei.p.se",#
                       "cox.x1.rmse",#
                       "exp.x0.rmse","exp.x1.rmse","zexp.z0.rmse","zexp.z1.rmse","zexp.z2.rmse","zexp.x0.rmse","zexp.x1.rmse","bzexp.x0.rmse","bzexp.x1.rmse","bzexp.z0.rmse","bzexp.z1.rmse","bzexp.z2.rmse",#
                       "wei.x0.rmse","wei.x1.rmse","wei.p.rmse","zwei.z0.rmse","zwei.z1.rmse","zwei.z2.rmse",#
                       "zwei.x0.rmse","zwei.x1.rmse","zwei.p.rmse", "bzwei.x0.rmse","bzwei.x1.rmse","bzwei.z0.rmse","bzwei.z1.rmse","bzwei.z2.rmse","bzwei.p.rmse",#
                       "cox.x1.cp","exp.x0.cp","exp.x1.cp","zexp.z0.cp","zexp.z1.cp","zexp.z2.cp","zexp.x0.cp","zexp.x1.cp","bzexp.x0.cp","bzexp.x1.cp","bzexp.z0.cp","bzexp.z1.cp","bzexp.z2.cp",#
                       "wei.x0.cp","wei.x1.cp","wei.p.cp",#
                       "zwei.z0.cp","zwei.z1.cp","zwei.z2.cp","zwei.x0.cp","zwei.x1.cp","zwei.p.cp", "bzwei.x0.cp","bzwei.x1.cp","bzwei.z0.cp","bzwei.z1.cp","bzwei.z2.cp","bzwei.p.cp")#
#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
#create a dependent variable, begin the simmulations#
for(i in 1:nsims){#
  print(i)#
#Assign parameter values#
tru.est[i,1]<--1#
tru.est[i,2]<-3.5#
tru.est[i,3]<--2#
tru.est[i,4]<-2#
tru.est[i,5]<-3#
tru.est[i,6]<-1#
#
myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
y <- rexp(n, rate = myrates) # generates the r.v.#
cen <- rexp(n, rate = 1 )#
ycen <- pmin(y, cen)#
di <- as.numeric(y <= cen)#
tru.est[i,7]<-table(di)[1]#
#
#create parameters for ZG#
phi<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
print(mean(phi))#
yzero<-matrix(1,n,1)#
error<--1*rlogis(n)#
flag<-error<qlogis(phi)#
yzero[flag]<-error[flag]#
flag<-yzero==1#
di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
tru.est[i,8]<-table(di)[1]#
#
data<-cbind(ycen,di,x,z)#
######################################################################################
###################################COX Model##########################################
######################################################################################
#
#store estimate and se#
cox.est[i,1]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[1]#
cox.est[i,2]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[3]#
#
#store rmse#
cox.rmse[i,1]<-sqrt((tru.est[i,2]-cox.est[i,1])^2)#
#
#calculate upper and lower 95% CI's#
b1.lower<-cox.est[i,1]-(1.959964*cox.est[i,2])#
b1.upper<-cox.est[i,1]+(1.959964*cox.est[i,2])#
#
#store coverage parameters#
cox.cp[i,1]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
##############################################################################
########################Simple Exponential Model##############################
##############################################################################
Exponential<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)]#
	XB<-X%*%beta#
	llik<-C*(XB-exp(XB)*Y)+(1-C)*(-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Exponential<-try(optim(f=Exponential,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Exponential)=="list"){#
	ifelse(is.positive.definite(output.Exponential$hessian)==TRUE,vcv<-solve(output.Exponential$hessian),vcv<-matrix(data=NA,nrow=2,ncol=2))#
#
#store betas and ses#
exp.est[i,1]<-output.Exponential$par[1]#
exp.est[i,2]<-sqrt(vcv[1,1])#
exp.est[i,3]<-output.Exponential$par[2]#
exp.est[i,4]<-sqrt(vcv[2,2])#
#
#store rmse#
exp.rmse[i,1]<-sqrt((tru.est[i,1]-exp.est[i,1])^2)#
exp.rmse[i,2]<-sqrt((tru.est[i,2]-exp.est[i,3])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-exp.est[i,1]-(1.959964*exp.est[i,2])#
b0.upper<-exp.est[i,1]+(1.959964*exp.est[i,2])#
b1.lower<-exp.est[i,3]-(1.959964*exp.est[i,4])#
b1.upper<-exp.est[i,3]+(1.959964*exp.est[i,4])#
#store coverage parameters#
exp.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
#################################################################################
#########################Simple Weibull Model ###################################
#################################################################################
#
#Note this estiamtes the model via hazard rates, a la Stata#
#
test<-survreg(Surv(ycen, di)~x, dist="weibull")#
summary(test)#
Weibull<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)-1]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	llik<-C*(log(exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*log(exp(-(exp(XB+1/p)*Y)^p))#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(exp.est[i,1],exp.est[i,3],.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Weibull<-try(optim(f=Weibull,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Weibull)=="list"){#
	ifelse(is.positive.definite(output.Weibull$hessian)==TRUE,vcv<-solve(output.Weibull$hessian),vcv<-matrix(data=NA,nrow=3,ncol=3))#
#
#store betas and ses#
weib.est[i,1]<-output.Weibull$par[1]+1/exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,1],output.Weibull$par[3])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,3]#
varcov[2,1]<-vcv[3,1]#
varcov[2,2]<-vcv[3,3]#
weib.est[i,2]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,3]<-output.Weibull$par[2]#
weib.est[i,4]<-sqrt(vcv[2,2])#
weib.est[i,5]<-exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,5])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[3,3]#
weib.est[i,6]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,1]<-sqrt((tru.est[i,1]-weib.est[i,1])^2)#
weib.rmse[i,2]<-sqrt((tru.est[i,2]-weib.est[i,3])^2)#
weib.rmse[i,3]<-sqrt((tru.est[i,6]-weib.est[i,5])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-weib.est[i,1]-(1.959964*weib.est[i,2])#
b0.upper<-weib.est[i,1]+(1.959964*weib.est[i,2])#
b1.lower<-weib.est[i,3]-(1.959964*weib.est[i,4])#
b1.upper<-weib.est[i,3]+(1.959964*weib.est[i,4])#
p.lower<-weib.est[i,5]-(1.959964*weib.est[i,6])#
p.upper<-weib.est[i,5]+(1.959964*weib.est[i,6])#
#
#store coverage parameters#
weib.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,3]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
}#
#
###logit estimates####
dataset<-as.data.frame(data)#
logitcoef1<-glm(di~ z+x, data = dataset, family = "binomial")$coef[1]#
logitcoef2<-glm(di~ z+x, data = dataset, family = "binomial")$coef[2]#
logitcoef3<-glm(di~ z+x, data = dataset, family = "binomial")$coef[3]#
#
################################################################################
##########################Zombie Exponential Model##############################
################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZExponential<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):length(est)]#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-ZG))#
	llik<-C*(log((1-phi)+phi*exp(XB)*exp(-exp(XB)*Y)))+(1-C)*(log(phi)+-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,exp.est[i,1],exp.est[i,3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZExponential<-try(optim(f=ZExponential,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZExponential)=="list"){#
	ifelse(is.positive.definite(output.ZExponential$hessian)==TRUE,vcv<-solve(output.ZExponential$hessian),vcv<-matrix(data=NA,nrow=5,ncol=5))#
#
#store betas and ses#
exp.est[i,5]<-output.ZExponential$par[1]#
exp.est[i,6]<-sqrt(vcv[1,1])#
exp.est[i,7]<-output.ZExponential$par[2]#
exp.est[i,8]<-sqrt(vcv[2,2])#
exp.est[i,9]<-output.ZExponential$par[3]#
exp.est[i,10]<-sqrt(vcv[3,3])#
exp.est[i,11]<-output.ZExponential$par[4]#
exp.est[i,12]<-sqrt(vcv[4,4])#
exp.est[i,13]<-output.ZExponential$par[5]#
exp.est[i,14]<-sqrt(vcv[5,5])#
#
#store rmse#
exp.rmse[i,3]<-sqrt((tru.est[i,3]-exp.est[i,5])^2)#
exp.rmse[i,4]<-sqrt((tru.est[i,4]-exp.est[i,7])^2)#
exp.rmse[i,5]<-sqrt((tru.est[i,5]-exp.est[i,9])^2)#
exp.rmse[i,6]<-sqrt((tru.est[i,1]-exp.est[i,11])^2)#
exp.rmse[i,7]<-sqrt((tru.est[i,2]-exp.est[i,13])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-exp.est[i,5]-(1.959964*exp.est[i,6])#
g0.upper<-exp.est[i,5]+(1.959964*exp.est[i,6])#
g1.lower<-exp.est[i,7]-(1.959964*exp.est[i,8])#
g1.upper<-exp.est[i,7]+(1.959964*exp.est[i,8])#
g2.lower<-exp.est[i,9]-(1.959964*exp.est[i,10])#
g2.upper<-exp.est[i,9]+(1.959964*exp.est[i,10])#
b0.lower<-exp.est[i,11]-(1.959964*exp.est[i,12])#
b0.upper<-exp.est[i,11]+(1.959964*exp.est[i,12])#
b1.lower<-exp.est[i,13]-(1.959964*exp.est[i,14])#
b1.upper<-exp.est[i,13]+(1.959964*exp.est[i,14])#
#store coverage parameters#
exp.cp[i,3]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,4]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,5]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,6]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,7]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
######################################################################################
##########################Zombie Weibull Model #######################################
######################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZWeibull<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):(length(est)-1)]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-(ZG+1/p)))#
	llik<-C*(log((1-phi)+phi*exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*(log(phi)+-(exp(XB+1/p)*Y)^p)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,output.Weibull$par[1],output.Weibull$par[2],output.Weibull$par[3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZWeibull<-try(optim(f=ZWeibull,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZWeibull)=="list"){#
	ifelse(is.positive.definite(output.ZWeibull$hessian)==TRUE,vcv<-solve(output.ZWeibull$hessian),vcv<-matrix(data=NA,nrow=6,ncol=6))#
#
#store betas and ses#
weib.est[i,7]<-output.ZWeibull$par[1]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,7],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,6]#
varcov[2,1]<-vcv[6,1]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,8]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,9]<-output.ZWeibull$par[2]#
weib.est[i,10]<-sqrt(vcv[2,2])#
weib.est[i,11]<-output.ZWeibull$par[3]#
weib.est[i,12]<-sqrt(vcv[3,3])#
weib.est[i,13]<-output.ZWeibull$par[4]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,13],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[4,4]#
varcov[1,2]<-vcv[4,6]#
varcov[2,1]<-vcv[6,4]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,14]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,15]<-output.ZWeibull$par[5]#
weib.est[i,16]<-sqrt(vcv[5,5])#
weib.est[i,17]<-exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,17])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[6,6]#
weib.est[i,18]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,4]<-sqrt((tru.est[i,3]-weib.est[i,7])^2)#
weib.rmse[i,5]<-sqrt((tru.est[i,4]-weib.est[i,9])^2)#
weib.rmse[i,6]<-sqrt((tru.est[i,5]-weib.est[i,11])^2)#
weib.rmse[i,7]<-sqrt((tru.est[i,1]-weib.est[i,13])^2)#
weib.rmse[i,8]<-sqrt((tru.est[i,2]-weib.est[i,15])^2)#
weib.rmse[i,9]<-sqrt((tru.est[i,6]-weib.est[i,17])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-weib.est[i,7]-(1.959964*weib.est[i,8])#
g0.upper<-weib.est[i,7]+(1.959964*weib.est[i,8])#
g1.lower<-weib.est[i,9]-(1.959964*weib.est[i,10])#
g1.upper<-weib.est[i,9]+(1.959964*weib.est[i,10])#
g2.lower<-weib.est[i,11]-(1.959964*weib.est[i,12])#
g2.upper<-weib.est[i,11]+(1.959964*weib.est[i,12])#
b0.lower<-weib.est[i,13]-(1.959964*weib.est[i,14])#
b0.upper<-weib.est[i,13]+(1.959964*weib.est[i,14])#
b1.lower<-weib.est[i,15]-(1.959964*weib.est[i,16])#
b1.upper<-weib.est[i,15]+(1.959964*weib.est[i,16])#
p.lower<-weib.est[i,17]-(1.959964*weib.est[i,18])#
p.upper<-weib.est[i,17]+(1.959964*weib.est[i,18])#
#
#store coverage parameters#
weib.cp[i,4]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,5]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,6]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,7]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,8]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,9]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
}#
################################################################################
######################Bayesian Zombie Exponential Model#########################
################################################################################
##set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZExponential = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Exponential")#
output.BayesZExponential = list(par = c(summary(mcmc(BayesZExponential$beta))[[1]][,1], summary(mcmc(BayesZExponential$gamma))[[1]][,1]), #
                                se = c(summary(mcmc(BayesZExponential$beta))[[1]][,4], summary(mcmc(BayesZExponential$gamma))[[1]][,4]),#
                                CI = rbind(summary(mcmc(BayesZExponential$beta))[[2]], summary(mcmc(BayesZExponential$gamma))[[2]]))#
exp.est[i,15]<-output.BayesZExponential$par[1]#
exp.est[i,16]<-output.BayesZExponential$se[1]#
exp.est[i,17]<-output.BayesZExponential$par[2]#
exp.est[i,18]<-output.BayesZExponential$se[2]#
exp.est[i,19]<-output.BayesZExponential$par[3]#
exp.est[i,20]<-output.BayesZExponential$se[3]#
exp.est[i,21]<-output.BayesZExponential$par[4]#
exp.est[i,22]<-output.BayesZExponential$se[4]#
exp.est[i,23]<-output.BayesZExponential$par[5]#
exp.est[i,24]<-output.BayesZExponential$se[5]#
#
##store rmse#
exp.rmse[i,8]<-sqrt((tru.est[i,1]-exp.est[i,15])^2)#
exp.rmse[i,9]<-sqrt((tru.est[i,2]-exp.est[i,17])^2)#
exp.rmse[i,10]<-sqrt((tru.est[i,3]-exp.est[i,19])^2)#
exp.rmse[i,11]<-sqrt((tru.est[i,4]-exp.est[i,21])^2)#
exp.rmse[i,12]<-sqrt((tru.est[i,5]-exp.est[i,23])^2)#
##calculate upper and lower 95% CI's#
b0.lower<-output.BayesZExponential$CI[1,1]#
b0.upper<-output.BayesZExponential$CI[1,5]#
b1.lower<-output.BayesZExponential$CI[2,1]#
b1.upper<-output.BayesZExponential$CI[2,5]#
g0.lower<-output.BayesZExponential$CI[3,1]#
g0.upper<-output.BayesZExponential$CI[3,5]#
g1.lower<-output.BayesZExponential$CI[4,1]#
g1.upper<-output.BayesZExponential$CI[4,5]#
g2.lower<-output.BayesZExponential$CI[5,1]#
g2.upper<-output.BayesZExponential$CI[5,5]#
#b0.lower<-exp.est[i,15]-(1.959964*exp.est[i,16])#
#b0.upper<-exp.est[i,15]+(1.959964*exp.est[i,16])#
#b1.lower<-exp.est[i,17]-(1.959964*exp.est[i,18])#
#b1.upper<-exp.est[i,17]+(1.959964*exp.est[i,18])#
#g0.lower<-exp.est[i,19]-(1.959964*exp.est[i,20])#
#g0.upper<-exp.est[i,19]+(1.959964*exp.est[i,20])#
#g1.lower<-exp.est[i,21]-(1.959964*exp.est[i,22])#
#g1.upper<-exp.est[i,21]+(1.959964*exp.est[i,22])#
#g2.lower<-exp.est[i,23]-(1.959964*exp.est[i,24])#
#g2.upper<-exp.est[i,23]+(1.959964*exp.est[i,24])#
#store coverage parameters#
exp.cp[i,8]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,9]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,10]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,11]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,12]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
################################################################################
########################Bayesian Zombie Weibull Model###########################
################################################################################
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZWeibull = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Weibull")#
output.BayesZWeibull = list(par = c(summary(mcmc(BayesZWeibull$beta))[[1]][,1], summary(mcmc(BayesZWeibull$gamma))[[1]][,1], #
                                    summary(mcmc(BayesZWeibull$lambda))[[1]][1]), #
                            se = c(summary(mcmc(BayesZWeibull$beta))[[1]][,4], summary(mcmc(BayesZWeibull$gamma))[[1]][,4], #
                                   summary(mcmc(BayesZWeibull$lambda))[[1]][4]),#
                            CI = rbind(summary(mcmc(BayesZWeibull$beta))[[2]], summary(mcmc(BayesZWeibull$gamma))[[2]], #
                                       summary(mcmc(BayesZWeibull$lambda))[[2]]))#
weib.est[i,19]<-output.BayesZWeibull$par[1]#
weib.est[i,20]<-output.BayesZWeibull$se[1]#
weib.est[i,21]<-output.BayesZWeibull$par[2]#
weib.est[i,22]<-output.BayesZWeibull$se[2]#
weib.est[i,23]<-output.BayesZWeibull$par[3]#
weib.est[i,24]<-output.BayesZWeibull$se[3]#
weib.est[i,25]<-output.BayesZWeibull$par[4]#
weib.est[i,26]<-output.BayesZWeibull$se[4]#
weib.est[i,27]<-output.BayesZWeibull$par[5]#
weib.est[i,28]<-output.BayesZWeibull$se[5]#
weib.est[i,29]<-output.BayesZWeibull$par[6]#
weib.est[i,30]<-output.BayesZWeibull$se[6]#
#
#store rmse#
weib.rmse[i,10]<-sqrt((tru.est[i,1]-weib.est[i,19])^2)#
weib.rmse[i,11]<-sqrt((tru.est[i,2]-weib.est[i,21])^2)#
weib.rmse[i,12]<-sqrt((tru.est[i,3]-weib.est[i,23])^2)#
weib.rmse[i,13]<-sqrt((tru.est[i,4]-weib.est[i,25])^2)#
weib.rmse[i,14]<-sqrt((tru.est[i,5]-weib.est[i,27])^2)#
weib.rmse[i,15]<-sqrt((tru.est[i,6]-weib.est[i,29])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-output.BayesZWeibull$CI[1,1]#
b0.upper<-output.BayesZWeibull$CI[1,5]#
b1.lower<-output.BayesZWeibull$CI[2,1]#
b1.upper<-output.BayesZWeibull$CI[2,5]#
g0.lower<-output.BayesZWeibull$CI[3,1]#
g0.upper<-output.BayesZWeibull$CI[3,5]#
g1.lower<-output.BayesZWeibull$CI[4,1]#
g1.upper<-output.BayesZWeibull$CI[4,5]#
g2.lower<-output.BayesZWeibull$CI[5,1]#
g2.upper<-output.BayesZWeibull$CI[5,5]#
p.lower<-output.BayesZWeibull$CI[6,1]#
p.upper<-output.BayesZWeibull$CI[6,2]#
# g0.lower<-weib.est[i,19]-(1.959964*weib.est[i,20])#
# g0.upper<-weib.est[i,19]+(1.959964*weib.est[i,20])#
# g1.lower<-weib.est[i,21]-(1.959964*weib.est[i,22])#
# g1.upper<-weib.est[i,21]+(1.959964*weib.est[i,22])#
# g2.lower<-weib.est[i,23]-(1.959964*weib.est[i,24])#
# g2.upper<-weib.est[i,23]+(1.959964*weib.est[i,24])#
# b0.lower<-weib.est[i,25]-(1.959964*weib.est[i,26])#
# b0.upper<-weib.est[i,25]+(1.959964*weib.est[i,26])#
# b1.lower<-weib.est[i,27]-(1.959964*weib.est[i,28])#
# b1.upper<-weib.est[i,27]+(1.959964*weib.est[i,28])#
# p.lower<-weib.est[i,29]-(1.959964*weib.est[i,30])#
# p.upper<-weib.est[i,29]+(1.959964*weib.est[i,30])#
#
#store coverage parameters#
weib.cp[i,10]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,11]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,12]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,13]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,14]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,15]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
#combine matrices and label variables#
main.data[i, ]<-c(tru.est[i, ],cox.est[i, ],exp.est[i, ],weib.est[i, ],cox.rmse[i, ],exp.rmse[i, ],weib.rmse[i, ],#
                  cox.cp[i, ],exp.cp[i, ],weib.cp[i, ])#
#
}
main.data
main.data[1:50,]
colMeans(main.data[1:50,])
mcmcOF2
betas.slice.sampling2
univ.betas.slice.sampling2
betas.post2
library(devtools)
document()
setwd('/Users/bomin8319/Desktop/BayesOFsurv/pkg/R')
document()
check()
install()
document()
install()
#set seed#
set.seed(100)   #
#
#set the number of observations#
n<-1000#
#
#set the number of simulations, and create matrices to store the results#
nsims<-1000#
#history matrix for true estimates#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
#history matrix for cox estimates#
cox.est<-matrix(NA,nrow=nsims,ncol=2)#
#history matrix for exp estimates#
exp.est<-matrix(NA,nrow=nsims,ncol=24)#
#history matrix for weibull estimates#
weib.est<-matrix(NA,nrow=nsims,ncol=30)#
#history matrix for cox RMSE#
cox.rmse<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp RMSE#
exp.rmse<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp RMSE#
weib.rmse<-matrix(NA,nrow=nsims,ncol=15)#
#history matrix for cox CP#
cox.cp<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp CP#
exp.cp<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp CP#
weib.cp<-matrix(NA,nrow=nsims,ncol=15)#
main.data<-cbind(tru.est,cox.est,exp.est,weib.est,cox.rmse,exp.rmse,weib.rmse,cox.cp,exp.cp,weib.cp)#
colnames(main.data)<-c("true.x0","true.x1","true.z0","true.z1","true.z2","true.p","cen.lat","cen.obs",#
                       "cox.x1","cox.x1.se",#
                       "exp.x0","exp.x0.se","exp.x1","exp.x1.se",#
                       "zexp.z0","zexp.z0.se","zexp.z1","zexp.z1.se","zexp.z2","zexp.z2.se","zexp.x0","zexp.x0.se","zexp.x1","zexp.x1.se",#
                       "bzexp.x0","zexp.x0.se","bzexp.x1","bzexp.x1.se","bzexp.z0","bzexp.z0.se","bzexp.z1","bzexp.z1.se","bzexp.z2","bzexp.z2.se",#
                       "wei.x0","wei.x0.se","wei.x1","wei.x1.se","wei.p","wei.p.se",#
                       "zwei.z0","zwei.z0.se","zwei.z1","zwei.z1.se","zwei.z2","zwei.z2.se","zwei.x0","zwei.x0.se","zwei.x1","zwei.x1.se","zwei.p","zwei.p.se",#
                       "bzwei.x0","bzwei.x0.se","bzwei.x1","bzwei.x1.se","bzwei.z0","bzwei.z0.se","bzwei.z1","bzwei.z1.se","bzwei.z2","bzwei.z2.se","bzwei.p","bzwei.p.se",#
                       "cox.x1.rmse",#
                       "exp.x0.rmse","exp.x1.rmse","zexp.z0.rmse","zexp.z1.rmse","zexp.z2.rmse","zexp.x0.rmse","zexp.x1.rmse","bzexp.x0.rmse","bzexp.x1.rmse","bzexp.z0.rmse","bzexp.z1.rmse","bzexp.z2.rmse",#
                       "wei.x0.rmse","wei.x1.rmse","wei.p.rmse","zwei.z0.rmse","zwei.z1.rmse","zwei.z2.rmse",#
                       "zwei.x0.rmse","zwei.x1.rmse","zwei.p.rmse", "bzwei.x0.rmse","bzwei.x1.rmse","bzwei.z0.rmse","bzwei.z1.rmse","bzwei.z2.rmse","bzwei.p.rmse",#
                       "cox.x1.cp","exp.x0.cp","exp.x1.cp","zexp.z0.cp","zexp.z1.cp","zexp.z2.cp","zexp.x0.cp","zexp.x1.cp","bzexp.x0.cp","bzexp.x1.cp","bzexp.z0.cp","bzexp.z1.cp","bzexp.z2.cp",#
                       "wei.x0.cp","wei.x1.cp","wei.p.cp",#
                       "zwei.z0.cp","zwei.z1.cp","zwei.z2.cp","zwei.x0.cp","zwei.x1.cp","zwei.p.cp", "bzwei.x0.cp","bzwei.x1.cp","bzwei.z0.cp","bzwei.z1.cp","bzwei.z2.cp","bzwei.p.cp")#
#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
#create a dependent variable, begin the simmulations#
for(i in 1:nsims){#
  print(i)#
#Assign parameter values#
tru.est[i,1]<-1#
tru.est[i,2]<-3.5#
tru.est[i,3]<--2#
tru.est[i,4]<-2#
tru.est[i,5]<-3#
tru.est[i,6]<-1#
#
myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
y <- rexp(n, rate = myrates) # generates the r.v.#
cen <- rexp(n, rate = 1 )#
ycen <- pmin(y, cen)#
di <- as.numeric(y <= cen)#
tru.est[i,7]<-table(di)[1]#
#
#create parameters for ZG#
phi<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
print(mean(phi))#
yzero<-matrix(1,n,1)#
error<--1*rlogis(n)#
flag<-error<qlogis(phi)#
yzero[flag]<-error[flag]#
flag<-yzero==1#
di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
tru.est[i,8]<-table(di)[1]#
#
data<-cbind(ycen,di,x,z)#
######################################################################################
###################################COX Model##########################################
######################################################################################
#
#store estimate and se#
cox.est[i,1]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[1]#
cox.est[i,2]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[3]#
#
#store rmse#
cox.rmse[i,1]<-sqrt((tru.est[i,2]-cox.est[i,1])^2)#
#
#calculate upper and lower 95% CI's#
b1.lower<-cox.est[i,1]-(1.959964*cox.est[i,2])#
b1.upper<-cox.est[i,1]+(1.959964*cox.est[i,2])#
#
#store coverage parameters#
cox.cp[i,1]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
##############################################################################
########################Simple Exponential Model##############################
##############################################################################
Exponential<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)]#
	XB<-X%*%beta#
	llik<-C*(XB-exp(XB)*Y)+(1-C)*(-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Exponential<-try(optim(f=Exponential,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Exponential)=="list"){#
	ifelse(is.positive.definite(output.Exponential$hessian)==TRUE,vcv<-solve(output.Exponential$hessian),vcv<-matrix(data=NA,nrow=2,ncol=2))#
#
#store betas and ses#
exp.est[i,1]<-output.Exponential$par[1]#
exp.est[i,2]<-sqrt(vcv[1,1])#
exp.est[i,3]<-output.Exponential$par[2]#
exp.est[i,4]<-sqrt(vcv[2,2])#
#
#store rmse#
exp.rmse[i,1]<-sqrt((tru.est[i,1]-exp.est[i,1])^2)#
exp.rmse[i,2]<-sqrt((tru.est[i,2]-exp.est[i,3])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-exp.est[i,1]-(1.959964*exp.est[i,2])#
b0.upper<-exp.est[i,1]+(1.959964*exp.est[i,2])#
b1.lower<-exp.est[i,3]-(1.959964*exp.est[i,4])#
b1.upper<-exp.est[i,3]+(1.959964*exp.est[i,4])#
#store coverage parameters#
exp.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
#################################################################################
#########################Simple Weibull Model ###################################
#################################################################################
#
#Note this estiamtes the model via hazard rates, a la Stata#
#
test<-survreg(Surv(ycen, di)~x, dist="weibull")#
summary(test)#
Weibull<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)-1]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	llik<-C*(log(exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*log(exp(-(exp(XB+1/p)*Y)^p))#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(exp.est[i,1],exp.est[i,3],.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Weibull<-try(optim(f=Weibull,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Weibull)=="list"){#
	ifelse(is.positive.definite(output.Weibull$hessian)==TRUE,vcv<-solve(output.Weibull$hessian),vcv<-matrix(data=NA,nrow=3,ncol=3))#
#
#store betas and ses#
weib.est[i,1]<-output.Weibull$par[1]+1/exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,1],output.Weibull$par[3])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,3]#
varcov[2,1]<-vcv[3,1]#
varcov[2,2]<-vcv[3,3]#
weib.est[i,2]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,3]<-output.Weibull$par[2]#
weib.est[i,4]<-sqrt(vcv[2,2])#
weib.est[i,5]<-exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,5])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[3,3]#
weib.est[i,6]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,1]<-sqrt((tru.est[i,1]-weib.est[i,1])^2)#
weib.rmse[i,2]<-sqrt((tru.est[i,2]-weib.est[i,3])^2)#
weib.rmse[i,3]<-sqrt((tru.est[i,6]-weib.est[i,5])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-weib.est[i,1]-(1.959964*weib.est[i,2])#
b0.upper<-weib.est[i,1]+(1.959964*weib.est[i,2])#
b1.lower<-weib.est[i,3]-(1.959964*weib.est[i,4])#
b1.upper<-weib.est[i,3]+(1.959964*weib.est[i,4])#
p.lower<-weib.est[i,5]-(1.959964*weib.est[i,6])#
p.upper<-weib.est[i,5]+(1.959964*weib.est[i,6])#
#
#store coverage parameters#
weib.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,3]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
}#
#
###logit estimates####
dataset<-as.data.frame(data)#
logitcoef1<-glm(di~ z+x, data = dataset, family = "binomial")$coef[1]#
logitcoef2<-glm(di~ z+x, data = dataset, family = "binomial")$coef[2]#
logitcoef3<-glm(di~ z+x, data = dataset, family = "binomial")$coef[3]#
#
################################################################################
##########################Zombie Exponential Model##############################
################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZExponential<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):length(est)]#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-ZG))#
	llik<-C*(log((1-phi)+phi*exp(XB)*exp(-exp(XB)*Y)))+(1-C)*(log(phi)+-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,exp.est[i,1],exp.est[i,3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZExponential<-try(optim(f=ZExponential,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZExponential)=="list"){#
	ifelse(is.positive.definite(output.ZExponential$hessian)==TRUE,vcv<-solve(output.ZExponential$hessian),vcv<-matrix(data=NA,nrow=5,ncol=5))#
#
#store betas and ses#
exp.est[i,5]<-output.ZExponential$par[1]#
exp.est[i,6]<-sqrt(vcv[1,1])#
exp.est[i,7]<-output.ZExponential$par[2]#
exp.est[i,8]<-sqrt(vcv[2,2])#
exp.est[i,9]<-output.ZExponential$par[3]#
exp.est[i,10]<-sqrt(vcv[3,3])#
exp.est[i,11]<-output.ZExponential$par[4]#
exp.est[i,12]<-sqrt(vcv[4,4])#
exp.est[i,13]<-output.ZExponential$par[5]#
exp.est[i,14]<-sqrt(vcv[5,5])#
#
#store rmse#
exp.rmse[i,3]<-sqrt((tru.est[i,3]-exp.est[i,5])^2)#
exp.rmse[i,4]<-sqrt((tru.est[i,4]-exp.est[i,7])^2)#
exp.rmse[i,5]<-sqrt((tru.est[i,5]-exp.est[i,9])^2)#
exp.rmse[i,6]<-sqrt((tru.est[i,1]-exp.est[i,11])^2)#
exp.rmse[i,7]<-sqrt((tru.est[i,2]-exp.est[i,13])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-exp.est[i,5]-(1.959964*exp.est[i,6])#
g0.upper<-exp.est[i,5]+(1.959964*exp.est[i,6])#
g1.lower<-exp.est[i,7]-(1.959964*exp.est[i,8])#
g1.upper<-exp.est[i,7]+(1.959964*exp.est[i,8])#
g2.lower<-exp.est[i,9]-(1.959964*exp.est[i,10])#
g2.upper<-exp.est[i,9]+(1.959964*exp.est[i,10])#
b0.lower<-exp.est[i,11]-(1.959964*exp.est[i,12])#
b0.upper<-exp.est[i,11]+(1.959964*exp.est[i,12])#
b1.lower<-exp.est[i,13]-(1.959964*exp.est[i,14])#
b1.upper<-exp.est[i,13]+(1.959964*exp.est[i,14])#
#store coverage parameters#
exp.cp[i,3]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,4]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,5]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,6]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,7]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
######################################################################################
##########################Zombie Weibull Model #######################################
######################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZWeibull<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):(length(est)-1)]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-(ZG+1/p)))#
	llik<-C*(log((1-phi)+phi*exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*(log(phi)+-(exp(XB+1/p)*Y)^p)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,output.Weibull$par[1],output.Weibull$par[2],output.Weibull$par[3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZWeibull<-try(optim(f=ZWeibull,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZWeibull)=="list"){#
	ifelse(is.positive.definite(output.ZWeibull$hessian)==TRUE,vcv<-solve(output.ZWeibull$hessian),vcv<-matrix(data=NA,nrow=6,ncol=6))#
#
#store betas and ses#
weib.est[i,7]<-output.ZWeibull$par[1]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,7],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,6]#
varcov[2,1]<-vcv[6,1]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,8]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,9]<-output.ZWeibull$par[2]#
weib.est[i,10]<-sqrt(vcv[2,2])#
weib.est[i,11]<-output.ZWeibull$par[3]#
weib.est[i,12]<-sqrt(vcv[3,3])#
weib.est[i,13]<-output.ZWeibull$par[4]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,13],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[4,4]#
varcov[1,2]<-vcv[4,6]#
varcov[2,1]<-vcv[6,4]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,14]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,15]<-output.ZWeibull$par[5]#
weib.est[i,16]<-sqrt(vcv[5,5])#
weib.est[i,17]<-exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,17])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[6,6]#
weib.est[i,18]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,4]<-sqrt((tru.est[i,3]-weib.est[i,7])^2)#
weib.rmse[i,5]<-sqrt((tru.est[i,4]-weib.est[i,9])^2)#
weib.rmse[i,6]<-sqrt((tru.est[i,5]-weib.est[i,11])^2)#
weib.rmse[i,7]<-sqrt((tru.est[i,1]-weib.est[i,13])^2)#
weib.rmse[i,8]<-sqrt((tru.est[i,2]-weib.est[i,15])^2)#
weib.rmse[i,9]<-sqrt((tru.est[i,6]-weib.est[i,17])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-weib.est[i,7]-(1.959964*weib.est[i,8])#
g0.upper<-weib.est[i,7]+(1.959964*weib.est[i,8])#
g1.lower<-weib.est[i,9]-(1.959964*weib.est[i,10])#
g1.upper<-weib.est[i,9]+(1.959964*weib.est[i,10])#
g2.lower<-weib.est[i,11]-(1.959964*weib.est[i,12])#
g2.upper<-weib.est[i,11]+(1.959964*weib.est[i,12])#
b0.lower<-weib.est[i,13]-(1.959964*weib.est[i,14])#
b0.upper<-weib.est[i,13]+(1.959964*weib.est[i,14])#
b1.lower<-weib.est[i,15]-(1.959964*weib.est[i,16])#
b1.upper<-weib.est[i,15]+(1.959964*weib.est[i,16])#
p.lower<-weib.est[i,17]-(1.959964*weib.est[i,18])#
p.upper<-weib.est[i,17]+(1.959964*weib.est[i,18])#
#
#store coverage parameters#
weib.cp[i,4]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,5]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,6]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,7]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,8]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,9]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
}#
################################################################################
######################Bayesian Zombie Exponential Model#########################
################################################################################
##set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZExponential = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Exponential")#
output.BayesZExponential = list(par = c(summary(mcmc(BayesZExponential$beta))[[1]][,1], summary(mcmc(BayesZExponential$gamma))[[1]][,1]), #
                                se = c(summary(mcmc(BayesZExponential$beta))[[1]][,4], summary(mcmc(BayesZExponential$gamma))[[1]][,4]),#
                                CI = rbind(summary(mcmc(BayesZExponential$beta))[[2]], summary(mcmc(BayesZExponential$gamma))[[2]]))#
exp.est[i,15]<-output.BayesZExponential$par[1]#
exp.est[i,16]<-output.BayesZExponential$se[1]#
exp.est[i,17]<-output.BayesZExponential$par[2]#
exp.est[i,18]<-output.BayesZExponential$se[2]#
exp.est[i,19]<-output.BayesZExponential$par[3]#
exp.est[i,20]<-output.BayesZExponential$se[3]#
exp.est[i,21]<-output.BayesZExponential$par[4]#
exp.est[i,22]<-output.BayesZExponential$se[4]#
exp.est[i,23]<-output.BayesZExponential$par[5]#
exp.est[i,24]<-output.BayesZExponential$se[5]#
#
##store rmse#
exp.rmse[i,8]<-sqrt((tru.est[i,1]-exp.est[i,15])^2)#
exp.rmse[i,9]<-sqrt((tru.est[i,2]-exp.est[i,17])^2)#
exp.rmse[i,10]<-sqrt((tru.est[i,3]-exp.est[i,19])^2)#
exp.rmse[i,11]<-sqrt((tru.est[i,4]-exp.est[i,21])^2)#
exp.rmse[i,12]<-sqrt((tru.est[i,5]-exp.est[i,23])^2)#
##calculate upper and lower 95% CI's#
b0.lower<-output.BayesZExponential$CI[1,1]#
b0.upper<-output.BayesZExponential$CI[1,5]#
b1.lower<-output.BayesZExponential$CI[2,1]#
b1.upper<-output.BayesZExponential$CI[2,5]#
g0.lower<-output.BayesZExponential$CI[3,1]#
g0.upper<-output.BayesZExponential$CI[3,5]#
g1.lower<-output.BayesZExponential$CI[4,1]#
g1.upper<-output.BayesZExponential$CI[4,5]#
g2.lower<-output.BayesZExponential$CI[5,1]#
g2.upper<-output.BayesZExponential$CI[5,5]#
#b0.lower<-exp.est[i,15]-(1.959964*exp.est[i,16])#
#b0.upper<-exp.est[i,15]+(1.959964*exp.est[i,16])#
#b1.lower<-exp.est[i,17]-(1.959964*exp.est[i,18])#
#b1.upper<-exp.est[i,17]+(1.959964*exp.est[i,18])#
#g0.lower<-exp.est[i,19]-(1.959964*exp.est[i,20])#
#g0.upper<-exp.est[i,19]+(1.959964*exp.est[i,20])#
#g1.lower<-exp.est[i,21]-(1.959964*exp.est[i,22])#
#g1.upper<-exp.est[i,21]+(1.959964*exp.est[i,22])#
#g2.lower<-exp.est[i,23]-(1.959964*exp.est[i,24])#
#g2.upper<-exp.est[i,23]+(1.959964*exp.est[i,24])#
#store coverage parameters#
exp.cp[i,8]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,9]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,10]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,11]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,12]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
################################################################################
########################Bayesian Zombie Weibull Model###########################
################################################################################
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZWeibull = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Weibull")#
output.BayesZWeibull = list(par = c(summary(mcmc(BayesZWeibull$beta))[[1]][,1], summary(mcmc(BayesZWeibull$gamma))[[1]][,1], #
                                    summary(mcmc(BayesZWeibull$lambda))[[1]][1]), #
                            se = c(summary(mcmc(BayesZWeibull$beta))[[1]][,4], summary(mcmc(BayesZWeibull$gamma))[[1]][,4], #
                                   summary(mcmc(BayesZWeibull$lambda))[[1]][4]),#
                            CI = rbind(summary(mcmc(BayesZWeibull$beta))[[2]], summary(mcmc(BayesZWeibull$gamma))[[2]], #
                                       summary(mcmc(BayesZWeibull$lambda))[[2]]))#
weib.est[i,19]<-output.BayesZWeibull$par[1]#
weib.est[i,20]<-output.BayesZWeibull$se[1]#
weib.est[i,21]<-output.BayesZWeibull$par[2]#
weib.est[i,22]<-output.BayesZWeibull$se[2]#
weib.est[i,23]<-output.BayesZWeibull$par[3]#
weib.est[i,24]<-output.BayesZWeibull$se[3]#
weib.est[i,25]<-output.BayesZWeibull$par[4]#
weib.est[i,26]<-output.BayesZWeibull$se[4]#
weib.est[i,27]<-output.BayesZWeibull$par[5]#
weib.est[i,28]<-output.BayesZWeibull$se[5]#
weib.est[i,29]<-output.BayesZWeibull$par[6]#
weib.est[i,30]<-output.BayesZWeibull$se[6]#
#
#store rmse#
weib.rmse[i,10]<-sqrt((tru.est[i,1]-weib.est[i,19])^2)#
weib.rmse[i,11]<-sqrt((tru.est[i,2]-weib.est[i,21])^2)#
weib.rmse[i,12]<-sqrt((tru.est[i,3]-weib.est[i,23])^2)#
weib.rmse[i,13]<-sqrt((tru.est[i,4]-weib.est[i,25])^2)#
weib.rmse[i,14]<-sqrt((tru.est[i,5]-weib.est[i,27])^2)#
weib.rmse[i,15]<-sqrt((tru.est[i,6]-weib.est[i,29])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-output.BayesZWeibull$CI[1,1]#
b0.upper<-output.BayesZWeibull$CI[1,5]#
b1.lower<-output.BayesZWeibull$CI[2,1]#
b1.upper<-output.BayesZWeibull$CI[2,5]#
g0.lower<-output.BayesZWeibull$CI[3,1]#
g0.upper<-output.BayesZWeibull$CI[3,5]#
g1.lower<-output.BayesZWeibull$CI[4,1]#
g1.upper<-output.BayesZWeibull$CI[4,5]#
g2.lower<-output.BayesZWeibull$CI[5,1]#
g2.upper<-output.BayesZWeibull$CI[5,5]#
p.lower<-output.BayesZWeibull$CI[6,1]#
p.upper<-output.BayesZWeibull$CI[6,2]#
# g0.lower<-weib.est[i,19]-(1.959964*weib.est[i,20])#
# g0.upper<-weib.est[i,19]+(1.959964*weib.est[i,20])#
# g1.lower<-weib.est[i,21]-(1.959964*weib.est[i,22])#
# g1.upper<-weib.est[i,21]+(1.959964*weib.est[i,22])#
# g2.lower<-weib.est[i,23]-(1.959964*weib.est[i,24])#
# g2.upper<-weib.est[i,23]+(1.959964*weib.est[i,24])#
# b0.lower<-weib.est[i,25]-(1.959964*weib.est[i,26])#
# b0.upper<-weib.est[i,25]+(1.959964*weib.est[i,26])#
# b1.lower<-weib.est[i,27]-(1.959964*weib.est[i,28])#
# b1.upper<-weib.est[i,27]+(1.959964*weib.est[i,28])#
# p.lower<-weib.est[i,29]-(1.959964*weib.est[i,30])#
# p.upper<-weib.est[i,29]+(1.959964*weib.est[i,30])#
#
#store coverage parameters#
weib.cp[i,10]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,11]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,12]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,13]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,14]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,15]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
#combine matrices and label variables#
main.data[i, ]<-c(tru.est[i, ],cox.est[i, ],exp.est[i, ],weib.est[i, ],cox.rmse[i, ],exp.rmse[i, ],weib.rmse[i, ],#
                  cox.cp[i, ],exp.cp[i, ],weib.cp[i, ])#
#
}
colMeans(main.data[1:18,])
colMeans(main.data[1:17,])
#set seed#
set.seed(100)   #
#
#set the number of observations#
n<-1000#
#
#set the number of simulations, and create matrices to store the results#
nsims<-1000#
#history matrix for true estimates#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
#history matrix for cox estimates#
cox.est<-matrix(NA,nrow=nsims,ncol=2)#
#history matrix for exp estimates#
exp.est<-matrix(NA,nrow=nsims,ncol=24)#
#history matrix for weibull estimates#
weib.est<-matrix(NA,nrow=nsims,ncol=30)#
#history matrix for cox RMSE#
cox.rmse<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp RMSE#
exp.rmse<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp RMSE#
weib.rmse<-matrix(NA,nrow=nsims,ncol=15)#
#history matrix for cox CP#
cox.cp<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp CP#
exp.cp<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp CP#
weib.cp<-matrix(NA,nrow=nsims,ncol=15)#
main.data<-cbind(tru.est,cox.est,exp.est,weib.est,cox.rmse,exp.rmse,weib.rmse,cox.cp,exp.cp,weib.cp)#
colnames(main.data)<-c("true.x0","true.x1","true.z0","true.z1","true.z2","true.p","cen.lat","cen.obs",#
                       "cox.x1","cox.x1.se",#
                       "exp.x0","exp.x0.se","exp.x1","exp.x1.se",#
                       "zexp.z0","zexp.z0.se","zexp.z1","zexp.z1.se","zexp.z2","zexp.z2.se","zexp.x0","zexp.x0.se","zexp.x1","zexp.x1.se",#
                       "bzexp.x0","zexp.x0.se","bzexp.x1","bzexp.x1.se","bzexp.z0","bzexp.z0.se","bzexp.z1","bzexp.z1.se","bzexp.z2","bzexp.z2.se",#
                       "wei.x0","wei.x0.se","wei.x1","wei.x1.se","wei.p","wei.p.se",#
                       "zwei.z0","zwei.z0.se","zwei.z1","zwei.z1.se","zwei.z2","zwei.z2.se","zwei.x0","zwei.x0.se","zwei.x1","zwei.x1.se","zwei.p","zwei.p.se",#
                       "bzwei.x0","bzwei.x0.se","bzwei.x1","bzwei.x1.se","bzwei.z0","bzwei.z0.se","bzwei.z1","bzwei.z1.se","bzwei.z2","bzwei.z2.se","bzwei.p","bzwei.p.se",#
                       "cox.x1.rmse",#
                       "exp.x0.rmse","exp.x1.rmse","zexp.z0.rmse","zexp.z1.rmse","zexp.z2.rmse","zexp.x0.rmse","zexp.x1.rmse","bzexp.x0.rmse","bzexp.x1.rmse","bzexp.z0.rmse","bzexp.z1.rmse","bzexp.z2.rmse",#
                       "wei.x0.rmse","wei.x1.rmse","wei.p.rmse","zwei.z0.rmse","zwei.z1.rmse","zwei.z2.rmse",#
                       "zwei.x0.rmse","zwei.x1.rmse","zwei.p.rmse", "bzwei.x0.rmse","bzwei.x1.rmse","bzwei.z0.rmse","bzwei.z1.rmse","bzwei.z2.rmse","bzwei.p.rmse",#
                       "cox.x1.cp","exp.x0.cp","exp.x1.cp","zexp.z0.cp","zexp.z1.cp","zexp.z2.cp","zexp.x0.cp","zexp.x1.cp","bzexp.x0.cp","bzexp.x1.cp","bzexp.z0.cp","bzexp.z1.cp","bzexp.z2.cp",#
                       "wei.x0.cp","wei.x1.cp","wei.p.cp",#
                       "zwei.z0.cp","zwei.z1.cp","zwei.z2.cp","zwei.x0.cp","zwei.x1.cp","zwei.p.cp", "bzwei.x0.cp","bzwei.x1.cp","bzwei.z0.cp","bzwei.z1.cp","bzwei.z2.cp","bzwei.p.cp")#
#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
#create a dependent variable, begin the simmulations#
for(i in 1:nsims){#
  print(i)#
#Assign parameter values#
tru.est[i,1]<--1#
tru.est[i,2]<-3.5#
tru.est[i,3]<--2#
tru.est[i,4]<-2#
tru.est[i,5]<-3#
tru.est[i,6]<-1#
#
myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
y <- rexp(n, rate = myrates) # generates the r.v.#
cen <- rexp(n, rate = 1 )#
ycen <- pmin(y, cen)#
di <- as.numeric(y <= cen)#
tru.est[i,7]<-table(di)[1]#
#
#create parameters for ZG#
phi<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
print(mean(phi))#
yzero<-matrix(1,n,1)#
error<--1*rlogis(n)#
flag<-error<qlogis(phi)#
yzero[flag]<-error[flag]#
flag<-yzero==1#
di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
tru.est[i,8]<-table(di)[1]#
#
data<-cbind(ycen,di,x,z)#
######################################################################################
###################################COX Model##########################################
######################################################################################
#
#store estimate and se#
cox.est[i,1]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[1]#
cox.est[i,2]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[3]#
#
#store rmse#
cox.rmse[i,1]<-sqrt((tru.est[i,2]-cox.est[i,1])^2)#
#
#calculate upper and lower 95% CI's#
b1.lower<-cox.est[i,1]-(1.959964*cox.est[i,2])#
b1.upper<-cox.est[i,1]+(1.959964*cox.est[i,2])#
#
#store coverage parameters#
cox.cp[i,1]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
##############################################################################
########################Simple Exponential Model##############################
##############################################################################
Exponential<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)]#
	XB<-X%*%beta#
	llik<-C*(XB-exp(XB)*Y)+(1-C)*(-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Exponential<-try(optim(f=Exponential,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Exponential)=="list"){#
	ifelse(is.positive.definite(output.Exponential$hessian)==TRUE,vcv<-solve(output.Exponential$hessian),vcv<-matrix(data=NA,nrow=2,ncol=2))#
#
#store betas and ses#
exp.est[i,1]<-output.Exponential$par[1]#
exp.est[i,2]<-sqrt(vcv[1,1])#
exp.est[i,3]<-output.Exponential$par[2]#
exp.est[i,4]<-sqrt(vcv[2,2])#
#
#store rmse#
exp.rmse[i,1]<-sqrt((tru.est[i,1]-exp.est[i,1])^2)#
exp.rmse[i,2]<-sqrt((tru.est[i,2]-exp.est[i,3])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-exp.est[i,1]-(1.959964*exp.est[i,2])#
b0.upper<-exp.est[i,1]+(1.959964*exp.est[i,2])#
b1.lower<-exp.est[i,3]-(1.959964*exp.est[i,4])#
b1.upper<-exp.est[i,3]+(1.959964*exp.est[i,4])#
#store coverage parameters#
exp.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
#################################################################################
#########################Simple Weibull Model ###################################
#################################################################################
#
#Note this estiamtes the model via hazard rates, a la Stata#
#
test<-survreg(Surv(ycen, di)~x, dist="weibull")#
summary(test)#
Weibull<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)-1]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	llik<-C*(log(exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*log(exp(-(exp(XB+1/p)*Y)^p))#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(exp.est[i,1],exp.est[i,3],.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Weibull<-try(optim(f=Weibull,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Weibull)=="list"){#
	ifelse(is.positive.definite(output.Weibull$hessian)==TRUE,vcv<-solve(output.Weibull$hessian),vcv<-matrix(data=NA,nrow=3,ncol=3))#
#
#store betas and ses#
weib.est[i,1]<-output.Weibull$par[1]+1/exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,1],output.Weibull$par[3])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,3]#
varcov[2,1]<-vcv[3,1]#
varcov[2,2]<-vcv[3,3]#
weib.est[i,2]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,3]<-output.Weibull$par[2]#
weib.est[i,4]<-sqrt(vcv[2,2])#
weib.est[i,5]<-exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,5])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[3,3]#
weib.est[i,6]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,1]<-sqrt((tru.est[i,1]-weib.est[i,1])^2)#
weib.rmse[i,2]<-sqrt((tru.est[i,2]-weib.est[i,3])^2)#
weib.rmse[i,3]<-sqrt((tru.est[i,6]-weib.est[i,5])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-weib.est[i,1]-(1.959964*weib.est[i,2])#
b0.upper<-weib.est[i,1]+(1.959964*weib.est[i,2])#
b1.lower<-weib.est[i,3]-(1.959964*weib.est[i,4])#
b1.upper<-weib.est[i,3]+(1.959964*weib.est[i,4])#
p.lower<-weib.est[i,5]-(1.959964*weib.est[i,6])#
p.upper<-weib.est[i,5]+(1.959964*weib.est[i,6])#
#
#store coverage parameters#
weib.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,3]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
}#
#
###logit estimates####
dataset<-as.data.frame(data)#
logitcoef1<-glm(di~ z+x, data = dataset, family = "binomial")$coef[1]#
logitcoef2<-glm(di~ z+x, data = dataset, family = "binomial")$coef[2]#
logitcoef3<-glm(di~ z+x, data = dataset, family = "binomial")$coef[3]#
#
################################################################################
##########################Zombie Exponential Model##############################
################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZExponential<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):length(est)]#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-ZG))#
	llik<-C*(log((1-phi)+phi*exp(XB)*exp(-exp(XB)*Y)))+(1-C)*(log(phi)+-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,exp.est[i,1],exp.est[i,3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZExponential<-try(optim(f=ZExponential,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZExponential)=="list"){#
	ifelse(is.positive.definite(output.ZExponential$hessian)==TRUE,vcv<-solve(output.ZExponential$hessian),vcv<-matrix(data=NA,nrow=5,ncol=5))#
#
#store betas and ses#
exp.est[i,5]<-output.ZExponential$par[1]#
exp.est[i,6]<-sqrt(vcv[1,1])#
exp.est[i,7]<-output.ZExponential$par[2]#
exp.est[i,8]<-sqrt(vcv[2,2])#
exp.est[i,9]<-output.ZExponential$par[3]#
exp.est[i,10]<-sqrt(vcv[3,3])#
exp.est[i,11]<-output.ZExponential$par[4]#
exp.est[i,12]<-sqrt(vcv[4,4])#
exp.est[i,13]<-output.ZExponential$par[5]#
exp.est[i,14]<-sqrt(vcv[5,5])#
#
#store rmse#
exp.rmse[i,3]<-sqrt((tru.est[i,3]-exp.est[i,5])^2)#
exp.rmse[i,4]<-sqrt((tru.est[i,4]-exp.est[i,7])^2)#
exp.rmse[i,5]<-sqrt((tru.est[i,5]-exp.est[i,9])^2)#
exp.rmse[i,6]<-sqrt((tru.est[i,1]-exp.est[i,11])^2)#
exp.rmse[i,7]<-sqrt((tru.est[i,2]-exp.est[i,13])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-exp.est[i,5]-(1.959964*exp.est[i,6])#
g0.upper<-exp.est[i,5]+(1.959964*exp.est[i,6])#
g1.lower<-exp.est[i,7]-(1.959964*exp.est[i,8])#
g1.upper<-exp.est[i,7]+(1.959964*exp.est[i,8])#
g2.lower<-exp.est[i,9]-(1.959964*exp.est[i,10])#
g2.upper<-exp.est[i,9]+(1.959964*exp.est[i,10])#
b0.lower<-exp.est[i,11]-(1.959964*exp.est[i,12])#
b0.upper<-exp.est[i,11]+(1.959964*exp.est[i,12])#
b1.lower<-exp.est[i,13]-(1.959964*exp.est[i,14])#
b1.upper<-exp.est[i,13]+(1.959964*exp.est[i,14])#
#store coverage parameters#
exp.cp[i,3]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,4]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,5]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,6]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,7]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
######################################################################################
##########################Zombie Weibull Model #######################################
######################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZWeibull<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):(length(est)-1)]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-(ZG+1/p)))#
	llik<-C*(log((1-phi)+phi*exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*(log(phi)+-(exp(XB+1/p)*Y)^p)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,output.Weibull$par[1],output.Weibull$par[2],output.Weibull$par[3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZWeibull<-try(optim(f=ZWeibull,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZWeibull)=="list"){#
	ifelse(is.positive.definite(output.ZWeibull$hessian)==TRUE,vcv<-solve(output.ZWeibull$hessian),vcv<-matrix(data=NA,nrow=6,ncol=6))#
#
#store betas and ses#
weib.est[i,7]<-output.ZWeibull$par[1]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,7],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,6]#
varcov[2,1]<-vcv[6,1]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,8]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,9]<-output.ZWeibull$par[2]#
weib.est[i,10]<-sqrt(vcv[2,2])#
weib.est[i,11]<-output.ZWeibull$par[3]#
weib.est[i,12]<-sqrt(vcv[3,3])#
weib.est[i,13]<-output.ZWeibull$par[4]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,13],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[4,4]#
varcov[1,2]<-vcv[4,6]#
varcov[2,1]<-vcv[6,4]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,14]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,15]<-output.ZWeibull$par[5]#
weib.est[i,16]<-sqrt(vcv[5,5])#
weib.est[i,17]<-exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,17])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[6,6]#
weib.est[i,18]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,4]<-sqrt((tru.est[i,3]-weib.est[i,7])^2)#
weib.rmse[i,5]<-sqrt((tru.est[i,4]-weib.est[i,9])^2)#
weib.rmse[i,6]<-sqrt((tru.est[i,5]-weib.est[i,11])^2)#
weib.rmse[i,7]<-sqrt((tru.est[i,1]-weib.est[i,13])^2)#
weib.rmse[i,8]<-sqrt((tru.est[i,2]-weib.est[i,15])^2)#
weib.rmse[i,9]<-sqrt((tru.est[i,6]-weib.est[i,17])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-weib.est[i,7]-(1.959964*weib.est[i,8])#
g0.upper<-weib.est[i,7]+(1.959964*weib.est[i,8])#
g1.lower<-weib.est[i,9]-(1.959964*weib.est[i,10])#
g1.upper<-weib.est[i,9]+(1.959964*weib.est[i,10])#
g2.lower<-weib.est[i,11]-(1.959964*weib.est[i,12])#
g2.upper<-weib.est[i,11]+(1.959964*weib.est[i,12])#
b0.lower<-weib.est[i,13]-(1.959964*weib.est[i,14])#
b0.upper<-weib.est[i,13]+(1.959964*weib.est[i,14])#
b1.lower<-weib.est[i,15]-(1.959964*weib.est[i,16])#
b1.upper<-weib.est[i,15]+(1.959964*weib.est[i,16])#
p.lower<-weib.est[i,17]-(1.959964*weib.est[i,18])#
p.upper<-weib.est[i,17]+(1.959964*weib.est[i,18])#
#
#store coverage parameters#
weib.cp[i,4]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,5]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,6]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,7]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,8]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,9]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
}#
################################################################################
######################Bayesian Zombie Exponential Model#########################
################################################################################
##set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZExponential = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Exponential")#
output.BayesZExponential = list(par = c(summary(mcmc(BayesZExponential$beta))[[1]][,1], summary(mcmc(BayesZExponential$gamma))[[1]][,1]), #
                                se = c(summary(mcmc(BayesZExponential$beta))[[1]][,4], summary(mcmc(BayesZExponential$gamma))[[1]][,4]),#
                                CI = rbind(summary(mcmc(BayesZExponential$beta))[[2]], summary(mcmc(BayesZExponential$gamma))[[2]]))#
exp.est[i,15]<-output.BayesZExponential$par[1]#
exp.est[i,16]<-output.BayesZExponential$se[1]#
exp.est[i,17]<-output.BayesZExponential$par[2]#
exp.est[i,18]<-output.BayesZExponential$se[2]#
exp.est[i,19]<-output.BayesZExponential$par[3]#
exp.est[i,20]<-output.BayesZExponential$se[3]#
exp.est[i,21]<-output.BayesZExponential$par[4]#
exp.est[i,22]<-output.BayesZExponential$se[4]#
exp.est[i,23]<-output.BayesZExponential$par[5]#
exp.est[i,24]<-output.BayesZExponential$se[5]#
#
##store rmse#
exp.rmse[i,8]<-sqrt((tru.est[i,1]-exp.est[i,15])^2)#
exp.rmse[i,9]<-sqrt((tru.est[i,2]-exp.est[i,17])^2)#
exp.rmse[i,10]<-sqrt((tru.est[i,3]-exp.est[i,19])^2)#
exp.rmse[i,11]<-sqrt((tru.est[i,4]-exp.est[i,21])^2)#
exp.rmse[i,12]<-sqrt((tru.est[i,5]-exp.est[i,23])^2)#
##calculate upper and lower 95% CI's#
b0.lower<-output.BayesZExponential$CI[1,1]#
b0.upper<-output.BayesZExponential$CI[1,5]#
b1.lower<-output.BayesZExponential$CI[2,1]#
b1.upper<-output.BayesZExponential$CI[2,5]#
g0.lower<-output.BayesZExponential$CI[3,1]#
g0.upper<-output.BayesZExponential$CI[3,5]#
g1.lower<-output.BayesZExponential$CI[4,1]#
g1.upper<-output.BayesZExponential$CI[4,5]#
g2.lower<-output.BayesZExponential$CI[5,1]#
g2.upper<-output.BayesZExponential$CI[5,5]#
#b0.lower<-exp.est[i,15]-(1.959964*exp.est[i,16])#
#b0.upper<-exp.est[i,15]+(1.959964*exp.est[i,16])#
#b1.lower<-exp.est[i,17]-(1.959964*exp.est[i,18])#
#b1.upper<-exp.est[i,17]+(1.959964*exp.est[i,18])#
#g0.lower<-exp.est[i,19]-(1.959964*exp.est[i,20])#
#g0.upper<-exp.est[i,19]+(1.959964*exp.est[i,20])#
#g1.lower<-exp.est[i,21]-(1.959964*exp.est[i,22])#
#g1.upper<-exp.est[i,21]+(1.959964*exp.est[i,22])#
#g2.lower<-exp.est[i,23]-(1.959964*exp.est[i,24])#
#g2.upper<-exp.est[i,23]+(1.959964*exp.est[i,24])#
#store coverage parameters#
exp.cp[i,8]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,9]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,10]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,11]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,12]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
################################################################################
########################Bayesian Zombie Weibull Model###########################
################################################################################
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZWeibull = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Weibull")#
output.BayesZWeibull = list(par = c(summary(mcmc(BayesZWeibull$beta))[[1]][,1], summary(mcmc(BayesZWeibull$gamma))[[1]][,1], #
                                    summary(mcmc(BayesZWeibull$lambda))[[1]][1]), #
                            se = c(summary(mcmc(BayesZWeibull$beta))[[1]][,4], summary(mcmc(BayesZWeibull$gamma))[[1]][,4], #
                                   summary(mcmc(BayesZWeibull$lambda))[[1]][4]),#
                            CI = rbind(summary(mcmc(BayesZWeibull$beta))[[2]], summary(mcmc(BayesZWeibull$gamma))[[2]], #
                                       summary(mcmc(BayesZWeibull$lambda))[[2]]))#
weib.est[i,19]<-output.BayesZWeibull$par[1]#
weib.est[i,20]<-output.BayesZWeibull$se[1]#
weib.est[i,21]<-output.BayesZWeibull$par[2]#
weib.est[i,22]<-output.BayesZWeibull$se[2]#
weib.est[i,23]<-output.BayesZWeibull$par[3]#
weib.est[i,24]<-output.BayesZWeibull$se[3]#
weib.est[i,25]<-output.BayesZWeibull$par[4]#
weib.est[i,26]<-output.BayesZWeibull$se[4]#
weib.est[i,27]<-output.BayesZWeibull$par[5]#
weib.est[i,28]<-output.BayesZWeibull$se[5]#
weib.est[i,29]<-output.BayesZWeibull$par[6]#
weib.est[i,30]<-output.BayesZWeibull$se[6]#
#
#store rmse#
weib.rmse[i,10]<-sqrt((tru.est[i,1]-weib.est[i,19])^2)#
weib.rmse[i,11]<-sqrt((tru.est[i,2]-weib.est[i,21])^2)#
weib.rmse[i,12]<-sqrt((tru.est[i,3]-weib.est[i,23])^2)#
weib.rmse[i,13]<-sqrt((tru.est[i,4]-weib.est[i,25])^2)#
weib.rmse[i,14]<-sqrt((tru.est[i,5]-weib.est[i,27])^2)#
weib.rmse[i,15]<-sqrt((tru.est[i,6]-weib.est[i,29])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-output.BayesZWeibull$CI[1,1]#
b0.upper<-output.BayesZWeibull$CI[1,5]#
b1.lower<-output.BayesZWeibull$CI[2,1]#
b1.upper<-output.BayesZWeibull$CI[2,5]#
g0.lower<-output.BayesZWeibull$CI[3,1]#
g0.upper<-output.BayesZWeibull$CI[3,5]#
g1.lower<-output.BayesZWeibull$CI[4,1]#
g1.upper<-output.BayesZWeibull$CI[4,5]#
g2.lower<-output.BayesZWeibull$CI[5,1]#
g2.upper<-output.BayesZWeibull$CI[5,5]#
p.lower<-output.BayesZWeibull$CI[6,1]#
p.upper<-output.BayesZWeibull$CI[6,2]#
# g0.lower<-weib.est[i,19]-(1.959964*weib.est[i,20])#
# g0.upper<-weib.est[i,19]+(1.959964*weib.est[i,20])#
# g1.lower<-weib.est[i,21]-(1.959964*weib.est[i,22])#
# g1.upper<-weib.est[i,21]+(1.959964*weib.est[i,22])#
# g2.lower<-weib.est[i,23]-(1.959964*weib.est[i,24])#
# g2.upper<-weib.est[i,23]+(1.959964*weib.est[i,24])#
# b0.lower<-weib.est[i,25]-(1.959964*weib.est[i,26])#
# b0.upper<-weib.est[i,25]+(1.959964*weib.est[i,26])#
# b1.lower<-weib.est[i,27]-(1.959964*weib.est[i,28])#
# b1.upper<-weib.est[i,27]+(1.959964*weib.est[i,28])#
# p.lower<-weib.est[i,29]-(1.959964*weib.est[i,30])#
# p.upper<-weib.est[i,29]+(1.959964*weib.est[i,30])#
#
#store coverage parameters#
weib.cp[i,10]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,11]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,12]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,13]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,14]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,15]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
#combine matrices and label variables#
main.data[i, ]<-c(tru.est[i, ],cox.est[i, ],exp.est[i, ],weib.est[i, ],cox.rmse[i, ],exp.rmse[i, ],weib.rmse[i, ],#
                  cox.cp[i, ],exp.cp[i, ],weib.cp[i, ])#
#
}
colMeans(main.data[1:9,])
colMeans(main.data[1:8,])
document()
install()
#set seed#
set.seed(100)   #
#
#set the number of observations#
n<-1000#
#
#set the number of simulations, and create matrices to store the results#
nsims<-1000#
#history matrix for true estimates#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
#history matrix for cox estimates#
cox.est<-matrix(NA,nrow=nsims,ncol=2)#
#history matrix for exp estimates#
exp.est<-matrix(NA,nrow=nsims,ncol=24)#
#history matrix for weibull estimates#
weib.est<-matrix(NA,nrow=nsims,ncol=30)#
#history matrix for cox RMSE#
cox.rmse<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp RMSE#
exp.rmse<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp RMSE#
weib.rmse<-matrix(NA,nrow=nsims,ncol=15)#
#history matrix for cox CP#
cox.cp<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp CP#
exp.cp<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp CP#
weib.cp<-matrix(NA,nrow=nsims,ncol=15)#
main.data<-cbind(tru.est,cox.est,exp.est,weib.est,cox.rmse,exp.rmse,weib.rmse,cox.cp,exp.cp,weib.cp)#
colnames(main.data)<-c("true.x0","true.x1","true.z0","true.z1","true.z2","true.p","cen.lat","cen.obs",#
                       "cox.x1","cox.x1.se",#
                       "exp.x0","exp.x0.se","exp.x1","exp.x1.se",#
                       "zexp.z0","zexp.z0.se","zexp.z1","zexp.z1.se","zexp.z2","zexp.z2.se","zexp.x0","zexp.x0.se","zexp.x1","zexp.x1.se",#
                       "bzexp.x0","zexp.x0.se","bzexp.x1","bzexp.x1.se","bzexp.z0","bzexp.z0.se","bzexp.z1","bzexp.z1.se","bzexp.z2","bzexp.z2.se",#
                       "wei.x0","wei.x0.se","wei.x1","wei.x1.se","wei.p","wei.p.se",#
                       "zwei.z0","zwei.z0.se","zwei.z1","zwei.z1.se","zwei.z2","zwei.z2.se","zwei.x0","zwei.x0.se","zwei.x1","zwei.x1.se","zwei.p","zwei.p.se",#
                       "bzwei.x0","bzwei.x0.se","bzwei.x1","bzwei.x1.se","bzwei.z0","bzwei.z0.se","bzwei.z1","bzwei.z1.se","bzwei.z2","bzwei.z2.se","bzwei.p","bzwei.p.se",#
                       "cox.x1.rmse",#
                       "exp.x0.rmse","exp.x1.rmse","zexp.z0.rmse","zexp.z1.rmse","zexp.z2.rmse","zexp.x0.rmse","zexp.x1.rmse","bzexp.x0.rmse","bzexp.x1.rmse","bzexp.z0.rmse","bzexp.z1.rmse","bzexp.z2.rmse",#
                       "wei.x0.rmse","wei.x1.rmse","wei.p.rmse","zwei.z0.rmse","zwei.z1.rmse","zwei.z2.rmse",#
                       "zwei.x0.rmse","zwei.x1.rmse","zwei.p.rmse", "bzwei.x0.rmse","bzwei.x1.rmse","bzwei.z0.rmse","bzwei.z1.rmse","bzwei.z2.rmse","bzwei.p.rmse",#
                       "cox.x1.cp","exp.x0.cp","exp.x1.cp","zexp.z0.cp","zexp.z1.cp","zexp.z2.cp","zexp.x0.cp","zexp.x1.cp","bzexp.x0.cp","bzexp.x1.cp","bzexp.z0.cp","bzexp.z1.cp","bzexp.z2.cp",#
                       "wei.x0.cp","wei.x1.cp","wei.p.cp",#
                       "zwei.z0.cp","zwei.z1.cp","zwei.z2.cp","zwei.x0.cp","zwei.x1.cp","zwei.p.cp", "bzwei.x0.cp","bzwei.x1.cp","bzwei.z0.cp","bzwei.z1.cp","bzwei.z2.cp","bzwei.p.cp")#
#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
#create a dependent variable, begin the simmulations#
for(i in 1:nsims){#
  print(i)#
#Assign parameter values#
tru.est[i,1]<--1#
tru.est[i,2]<-3.5#
tru.est[i,3]<--2#
tru.est[i,4]<-2#
tru.est[i,5]<-3#
tru.est[i,6]<-1#
#
myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
y <- rexp(n, rate = myrates) # generates the r.v.#
cen <- rexp(n, rate = 1 )#
ycen <- pmin(y, cen)#
di <- as.numeric(y <= cen)#
tru.est[i,7]<-table(di)[1]#
#
#create parameters for ZG#
phi<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
print(mean(phi))#
yzero<-matrix(1,n,1)#
error<--1*rlogis(n)#
flag<-error<qlogis(phi)#
yzero[flag]<-error[flag]#
flag<-yzero==1#
di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
tru.est[i,8]<-table(di)[1]#
#
data<-cbind(ycen,di,x,z)#
######################################################################################
###################################COX Model##########################################
######################################################################################
#
#store estimate and se#
cox.est[i,1]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[1]#
cox.est[i,2]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[3]#
#
#store rmse#
cox.rmse[i,1]<-sqrt((tru.est[i,2]-cox.est[i,1])^2)#
#
#calculate upper and lower 95% CI's#
b1.lower<-cox.est[i,1]-(1.959964*cox.est[i,2])#
b1.upper<-cox.est[i,1]+(1.959964*cox.est[i,2])#
#
#store coverage parameters#
cox.cp[i,1]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
##############################################################################
########################Simple Exponential Model##############################
##############################################################################
Exponential<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)]#
	XB<-X%*%beta#
	llik<-C*(XB-exp(XB)*Y)+(1-C)*(-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Exponential<-try(optim(f=Exponential,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Exponential)=="list"){#
	ifelse(is.positive.definite(output.Exponential$hessian)==TRUE,vcv<-solve(output.Exponential$hessian),vcv<-matrix(data=NA,nrow=2,ncol=2))#
#
#store betas and ses#
exp.est[i,1]<-output.Exponential$par[1]#
exp.est[i,2]<-sqrt(vcv[1,1])#
exp.est[i,3]<-output.Exponential$par[2]#
exp.est[i,4]<-sqrt(vcv[2,2])#
#
#store rmse#
exp.rmse[i,1]<-sqrt((tru.est[i,1]-exp.est[i,1])^2)#
exp.rmse[i,2]<-sqrt((tru.est[i,2]-exp.est[i,3])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-exp.est[i,1]-(1.959964*exp.est[i,2])#
b0.upper<-exp.est[i,1]+(1.959964*exp.est[i,2])#
b1.lower<-exp.est[i,3]-(1.959964*exp.est[i,4])#
b1.upper<-exp.est[i,3]+(1.959964*exp.est[i,4])#
#store coverage parameters#
exp.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
#################################################################################
#########################Simple Weibull Model ###################################
#################################################################################
#
#Note this estiamtes the model via hazard rates, a la Stata#
#
test<-survreg(Surv(ycen, di)~x, dist="weibull")#
summary(test)#
Weibull<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)-1]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	llik<-C*(log(exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*log(exp(-(exp(XB+1/p)*Y)^p))#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(exp.est[i,1],exp.est[i,3],.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Weibull<-try(optim(f=Weibull,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Weibull)=="list"){#
	ifelse(is.positive.definite(output.Weibull$hessian)==TRUE,vcv<-solve(output.Weibull$hessian),vcv<-matrix(data=NA,nrow=3,ncol=3))#
#
#store betas and ses#
weib.est[i,1]<-output.Weibull$par[1]+1/exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,1],output.Weibull$par[3])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,3]#
varcov[2,1]<-vcv[3,1]#
varcov[2,2]<-vcv[3,3]#
weib.est[i,2]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,3]<-output.Weibull$par[2]#
weib.est[i,4]<-sqrt(vcv[2,2])#
weib.est[i,5]<-exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,5])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[3,3]#
weib.est[i,6]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,1]<-sqrt((tru.est[i,1]-weib.est[i,1])^2)#
weib.rmse[i,2]<-sqrt((tru.est[i,2]-weib.est[i,3])^2)#
weib.rmse[i,3]<-sqrt((tru.est[i,6]-weib.est[i,5])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-weib.est[i,1]-(1.959964*weib.est[i,2])#
b0.upper<-weib.est[i,1]+(1.959964*weib.est[i,2])#
b1.lower<-weib.est[i,3]-(1.959964*weib.est[i,4])#
b1.upper<-weib.est[i,3]+(1.959964*weib.est[i,4])#
p.lower<-weib.est[i,5]-(1.959964*weib.est[i,6])#
p.upper<-weib.est[i,5]+(1.959964*weib.est[i,6])#
#
#store coverage parameters#
weib.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,3]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
}#
#
###logit estimates####
dataset<-as.data.frame(data)#
logitcoef1<-glm(di~ z+x, data = dataset, family = "binomial")$coef[1]#
logitcoef2<-glm(di~ z+x, data = dataset, family = "binomial")$coef[2]#
logitcoef3<-glm(di~ z+x, data = dataset, family = "binomial")$coef[3]#
#
################################################################################
##########################Zombie Exponential Model##############################
################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZExponential<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):length(est)]#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-ZG))#
	llik<-C*(log((1-phi)+phi*exp(XB)*exp(-exp(XB)*Y)))+(1-C)*(log(phi)+-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,exp.est[i,1],exp.est[i,3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZExponential<-try(optim(f=ZExponential,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZExponential)=="list"){#
	ifelse(is.positive.definite(output.ZExponential$hessian)==TRUE,vcv<-solve(output.ZExponential$hessian),vcv<-matrix(data=NA,nrow=5,ncol=5))#
#
#store betas and ses#
exp.est[i,5]<-output.ZExponential$par[1]#
exp.est[i,6]<-sqrt(vcv[1,1])#
exp.est[i,7]<-output.ZExponential$par[2]#
exp.est[i,8]<-sqrt(vcv[2,2])#
exp.est[i,9]<-output.ZExponential$par[3]#
exp.est[i,10]<-sqrt(vcv[3,3])#
exp.est[i,11]<-output.ZExponential$par[4]#
exp.est[i,12]<-sqrt(vcv[4,4])#
exp.est[i,13]<-output.ZExponential$par[5]#
exp.est[i,14]<-sqrt(vcv[5,5])#
#
#store rmse#
exp.rmse[i,3]<-sqrt((tru.est[i,3]-exp.est[i,5])^2)#
exp.rmse[i,4]<-sqrt((tru.est[i,4]-exp.est[i,7])^2)#
exp.rmse[i,5]<-sqrt((tru.est[i,5]-exp.est[i,9])^2)#
exp.rmse[i,6]<-sqrt((tru.est[i,1]-exp.est[i,11])^2)#
exp.rmse[i,7]<-sqrt((tru.est[i,2]-exp.est[i,13])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-exp.est[i,5]-(1.959964*exp.est[i,6])#
g0.upper<-exp.est[i,5]+(1.959964*exp.est[i,6])#
g1.lower<-exp.est[i,7]-(1.959964*exp.est[i,8])#
g1.upper<-exp.est[i,7]+(1.959964*exp.est[i,8])#
g2.lower<-exp.est[i,9]-(1.959964*exp.est[i,10])#
g2.upper<-exp.est[i,9]+(1.959964*exp.est[i,10])#
b0.lower<-exp.est[i,11]-(1.959964*exp.est[i,12])#
b0.upper<-exp.est[i,11]+(1.959964*exp.est[i,12])#
b1.lower<-exp.est[i,13]-(1.959964*exp.est[i,14])#
b1.upper<-exp.est[i,13]+(1.959964*exp.est[i,14])#
#store coverage parameters#
exp.cp[i,3]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,4]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,5]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,6]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,7]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
######################################################################################
##########################Zombie Weibull Model #######################################
######################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZWeibull<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):(length(est)-1)]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-(ZG+1/p)))#
	llik<-C*(log((1-phi)+phi*exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*(log(phi)+-(exp(XB+1/p)*Y)^p)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,output.Weibull$par[1],output.Weibull$par[2],output.Weibull$par[3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZWeibull<-try(optim(f=ZWeibull,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZWeibull)=="list"){#
	ifelse(is.positive.definite(output.ZWeibull$hessian)==TRUE,vcv<-solve(output.ZWeibull$hessian),vcv<-matrix(data=NA,nrow=6,ncol=6))#
#
#store betas and ses#
weib.est[i,7]<-output.ZWeibull$par[1]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,7],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,6]#
varcov[2,1]<-vcv[6,1]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,8]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,9]<-output.ZWeibull$par[2]#
weib.est[i,10]<-sqrt(vcv[2,2])#
weib.est[i,11]<-output.ZWeibull$par[3]#
weib.est[i,12]<-sqrt(vcv[3,3])#
weib.est[i,13]<-output.ZWeibull$par[4]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,13],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[4,4]#
varcov[1,2]<-vcv[4,6]#
varcov[2,1]<-vcv[6,4]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,14]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,15]<-output.ZWeibull$par[5]#
weib.est[i,16]<-sqrt(vcv[5,5])#
weib.est[i,17]<-exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,17])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[6,6]#
weib.est[i,18]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,4]<-sqrt((tru.est[i,3]-weib.est[i,7])^2)#
weib.rmse[i,5]<-sqrt((tru.est[i,4]-weib.est[i,9])^2)#
weib.rmse[i,6]<-sqrt((tru.est[i,5]-weib.est[i,11])^2)#
weib.rmse[i,7]<-sqrt((tru.est[i,1]-weib.est[i,13])^2)#
weib.rmse[i,8]<-sqrt((tru.est[i,2]-weib.est[i,15])^2)#
weib.rmse[i,9]<-sqrt((tru.est[i,6]-weib.est[i,17])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-weib.est[i,7]-(1.959964*weib.est[i,8])#
g0.upper<-weib.est[i,7]+(1.959964*weib.est[i,8])#
g1.lower<-weib.est[i,9]-(1.959964*weib.est[i,10])#
g1.upper<-weib.est[i,9]+(1.959964*weib.est[i,10])#
g2.lower<-weib.est[i,11]-(1.959964*weib.est[i,12])#
g2.upper<-weib.est[i,11]+(1.959964*weib.est[i,12])#
b0.lower<-weib.est[i,13]-(1.959964*weib.est[i,14])#
b0.upper<-weib.est[i,13]+(1.959964*weib.est[i,14])#
b1.lower<-weib.est[i,15]-(1.959964*weib.est[i,16])#
b1.upper<-weib.est[i,15]+(1.959964*weib.est[i,16])#
p.lower<-weib.est[i,17]-(1.959964*weib.est[i,18])#
p.upper<-weib.est[i,17]+(1.959964*weib.est[i,18])#
#
#store coverage parameters#
weib.cp[i,4]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,5]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,6]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,7]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,8]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,9]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
}#
################################################################################
######################Bayesian Zombie Exponential Model#########################
################################################################################
##set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZExponential = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Exponential")#
output.BayesZExponential = list(par = c(summary(mcmc(BayesZExponential$beta))[[1]][,1], summary(mcmc(BayesZExponential$gamma))[[1]][,1]), #
                                se = c(summary(mcmc(BayesZExponential$beta))[[1]][,4], summary(mcmc(BayesZExponential$gamma))[[1]][,4]),#
                                CI = rbind(summary(mcmc(BayesZExponential$beta))[[2]], summary(mcmc(BayesZExponential$gamma))[[2]]))#
exp.est[i,15]<-output.BayesZExponential$par[1]#
exp.est[i,16]<-output.BayesZExponential$se[1]#
exp.est[i,17]<-output.BayesZExponential$par[2]#
exp.est[i,18]<-output.BayesZExponential$se[2]#
exp.est[i,19]<-output.BayesZExponential$par[3]#
exp.est[i,20]<-output.BayesZExponential$se[3]#
exp.est[i,21]<-output.BayesZExponential$par[4]#
exp.est[i,22]<-output.BayesZExponential$se[4]#
exp.est[i,23]<-output.BayesZExponential$par[5]#
exp.est[i,24]<-output.BayesZExponential$se[5]#
#
##store rmse#
exp.rmse[i,8]<-sqrt((tru.est[i,1]-exp.est[i,15])^2)#
exp.rmse[i,9]<-sqrt((tru.est[i,2]-exp.est[i,17])^2)#
exp.rmse[i,10]<-sqrt((tru.est[i,3]-exp.est[i,19])^2)#
exp.rmse[i,11]<-sqrt((tru.est[i,4]-exp.est[i,21])^2)#
exp.rmse[i,12]<-sqrt((tru.est[i,5]-exp.est[i,23])^2)#
##calculate upper and lower 95% CI's#
b0.lower<-output.BayesZExponential$CI[1,1]#
b0.upper<-output.BayesZExponential$CI[1,5]#
b1.lower<-output.BayesZExponential$CI[2,1]#
b1.upper<-output.BayesZExponential$CI[2,5]#
g0.lower<-output.BayesZExponential$CI[3,1]#
g0.upper<-output.BayesZExponential$CI[3,5]#
g1.lower<-output.BayesZExponential$CI[4,1]#
g1.upper<-output.BayesZExponential$CI[4,5]#
g2.lower<-output.BayesZExponential$CI[5,1]#
g2.upper<-output.BayesZExponential$CI[5,5]#
#b0.lower<-exp.est[i,15]-(1.959964*exp.est[i,16])#
#b0.upper<-exp.est[i,15]+(1.959964*exp.est[i,16])#
#b1.lower<-exp.est[i,17]-(1.959964*exp.est[i,18])#
#b1.upper<-exp.est[i,17]+(1.959964*exp.est[i,18])#
#g0.lower<-exp.est[i,19]-(1.959964*exp.est[i,20])#
#g0.upper<-exp.est[i,19]+(1.959964*exp.est[i,20])#
#g1.lower<-exp.est[i,21]-(1.959964*exp.est[i,22])#
#g1.upper<-exp.est[i,21]+(1.959964*exp.est[i,22])#
#g2.lower<-exp.est[i,23]-(1.959964*exp.est[i,24])#
#g2.upper<-exp.est[i,23]+(1.959964*exp.est[i,24])#
#store coverage parameters#
exp.cp[i,8]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,9]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,10]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,11]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,12]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
################################################################################
########################Bayesian Zombie Weibull Model###########################
################################################################################
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZWeibull = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Weibull")#
output.BayesZWeibull = list(par = c(summary(mcmc(BayesZWeibull$beta))[[1]][,1], summary(mcmc(BayesZWeibull$gamma))[[1]][,1], #
                                    summary(mcmc(BayesZWeibull$lambda))[[1]][1]), #
                            se = c(summary(mcmc(BayesZWeibull$beta))[[1]][,4], summary(mcmc(BayesZWeibull$gamma))[[1]][,4], #
                                   summary(mcmc(BayesZWeibull$lambda))[[1]][4]),#
                            CI = rbind(summary(mcmc(BayesZWeibull$beta))[[2]], summary(mcmc(BayesZWeibull$gamma))[[2]], #
                                       summary(mcmc(BayesZWeibull$lambda))[[2]]))#
weib.est[i,19]<-output.BayesZWeibull$par[1]#
weib.est[i,20]<-output.BayesZWeibull$se[1]#
weib.est[i,21]<-output.BayesZWeibull$par[2]#
weib.est[i,22]<-output.BayesZWeibull$se[2]#
weib.est[i,23]<-output.BayesZWeibull$par[3]#
weib.est[i,24]<-output.BayesZWeibull$se[3]#
weib.est[i,25]<-output.BayesZWeibull$par[4]#
weib.est[i,26]<-output.BayesZWeibull$se[4]#
weib.est[i,27]<-output.BayesZWeibull$par[5]#
weib.est[i,28]<-output.BayesZWeibull$se[5]#
weib.est[i,29]<-output.BayesZWeibull$par[6]#
weib.est[i,30]<-output.BayesZWeibull$se[6]#
#
#store rmse#
weib.rmse[i,10]<-sqrt((tru.est[i,1]-weib.est[i,19])^2)#
weib.rmse[i,11]<-sqrt((tru.est[i,2]-weib.est[i,21])^2)#
weib.rmse[i,12]<-sqrt((tru.est[i,3]-weib.est[i,23])^2)#
weib.rmse[i,13]<-sqrt((tru.est[i,4]-weib.est[i,25])^2)#
weib.rmse[i,14]<-sqrt((tru.est[i,5]-weib.est[i,27])^2)#
weib.rmse[i,15]<-sqrt((tru.est[i,6]-weib.est[i,29])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-output.BayesZWeibull$CI[1,1]#
b0.upper<-output.BayesZWeibull$CI[1,5]#
b1.lower<-output.BayesZWeibull$CI[2,1]#
b1.upper<-output.BayesZWeibull$CI[2,5]#
g0.lower<-output.BayesZWeibull$CI[3,1]#
g0.upper<-output.BayesZWeibull$CI[3,5]#
g1.lower<-output.BayesZWeibull$CI[4,1]#
g1.upper<-output.BayesZWeibull$CI[4,5]#
g2.lower<-output.BayesZWeibull$CI[5,1]#
g2.upper<-output.BayesZWeibull$CI[5,5]#
p.lower<-output.BayesZWeibull$CI[6,1]#
p.upper<-output.BayesZWeibull$CI[6,2]#
# g0.lower<-weib.est[i,19]-(1.959964*weib.est[i,20])#
# g0.upper<-weib.est[i,19]+(1.959964*weib.est[i,20])#
# g1.lower<-weib.est[i,21]-(1.959964*weib.est[i,22])#
# g1.upper<-weib.est[i,21]+(1.959964*weib.est[i,22])#
# g2.lower<-weib.est[i,23]-(1.959964*weib.est[i,24])#
# g2.upper<-weib.est[i,23]+(1.959964*weib.est[i,24])#
# b0.lower<-weib.est[i,25]-(1.959964*weib.est[i,26])#
# b0.upper<-weib.est[i,25]+(1.959964*weib.est[i,26])#
# b1.lower<-weib.est[i,27]-(1.959964*weib.est[i,28])#
# b1.upper<-weib.est[i,27]+(1.959964*weib.est[i,28])#
# p.lower<-weib.est[i,29]-(1.959964*weib.est[i,30])#
# p.upper<-weib.est[i,29]+(1.959964*weib.est[i,30])#
#
#store coverage parameters#
weib.cp[i,10]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,11]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,12]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,13]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,14]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,15]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
#combine matrices and label variables#
main.data[i, ]<-c(tru.est[i, ],cox.est[i, ],exp.est[i, ],weib.est[i, ],cox.rmse[i, ],exp.rmse[i, ],weib.rmse[i, ],#
                  cox.cp[i, ],exp.cp[i, ],weib.cp[i, ])#
#
}
colMeans(main.data[1:17,])
colMeans(main.data[1:8,])
2.184820e+00  2.639578e-01  1.795462e+00  1.508232e-01  3.021899e+00  1.666281e-01
#set seed#
set.seed(100)   #
#
#set the number of observations#
n<-1000#
#
#set the number of simulations, and create matrices to store the results#
nsims<-1000#
#history matrix for true estimates#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
#history matrix for cox estimates#
cox.est<-matrix(NA,nrow=nsims,ncol=2)#
#history matrix for exp estimates#
exp.est<-matrix(NA,nrow=nsims,ncol=24)#
#history matrix for weibull estimates#
weib.est<-matrix(NA,nrow=nsims,ncol=30)#
#history matrix for cox RMSE#
cox.rmse<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp RMSE#
exp.rmse<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp RMSE#
weib.rmse<-matrix(NA,nrow=nsims,ncol=15)#
#history matrix for cox CP#
cox.cp<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp CP#
exp.cp<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp CP#
weib.cp<-matrix(NA,nrow=nsims,ncol=15)#
main.data<-cbind(tru.est,cox.est,exp.est,weib.est,cox.rmse,exp.rmse,weib.rmse,cox.cp,exp.cp,weib.cp)#
colnames(main.data)<-c("true.x0","true.x1","true.z0","true.z1","true.z2","true.p","cen.lat","cen.obs",#
                       "cox.x1","cox.x1.se",#
                       "exp.x0","exp.x0.se","exp.x1","exp.x1.se",#
                       "zexp.z0","zexp.z0.se","zexp.z1","zexp.z1.se","zexp.z2","zexp.z2.se","zexp.x0","zexp.x0.se","zexp.x1","zexp.x1.se",#
                       "bzexp.x0","zexp.x0.se","bzexp.x1","bzexp.x1.se","bzexp.z0","bzexp.z0.se","bzexp.z1","bzexp.z1.se","bzexp.z2","bzexp.z2.se",#
                       "wei.x0","wei.x0.se","wei.x1","wei.x1.se","wei.p","wei.p.se",#
                       "zwei.z0","zwei.z0.se","zwei.z1","zwei.z1.se","zwei.z2","zwei.z2.se","zwei.x0","zwei.x0.se","zwei.x1","zwei.x1.se","zwei.p","zwei.p.se",#
                       "bzwei.x0","bzwei.x0.se","bzwei.x1","bzwei.x1.se","bzwei.z0","bzwei.z0.se","bzwei.z1","bzwei.z1.se","bzwei.z2","bzwei.z2.se","bzwei.p","bzwei.p.se",#
                       "cox.x1.rmse",#
                       "exp.x0.rmse","exp.x1.rmse","zexp.z0.rmse","zexp.z1.rmse","zexp.z2.rmse","zexp.x0.rmse","zexp.x1.rmse","bzexp.x0.rmse","bzexp.x1.rmse","bzexp.z0.rmse","bzexp.z1.rmse","bzexp.z2.rmse",#
                       "wei.x0.rmse","wei.x1.rmse","wei.p.rmse","zwei.z0.rmse","zwei.z1.rmse","zwei.z2.rmse",#
                       "zwei.x0.rmse","zwei.x1.rmse","zwei.p.rmse", "bzwei.x0.rmse","bzwei.x1.rmse","bzwei.z0.rmse","bzwei.z1.rmse","bzwei.z2.rmse","bzwei.p.rmse",#
                       "cox.x1.cp","exp.x0.cp","exp.x1.cp","zexp.z0.cp","zexp.z1.cp","zexp.z2.cp","zexp.x0.cp","zexp.x1.cp","bzexp.x0.cp","bzexp.x1.cp","bzexp.z0.cp","bzexp.z1.cp","bzexp.z2.cp",#
                       "wei.x0.cp","wei.x1.cp","wei.p.cp",#
                       "zwei.z0.cp","zwei.z1.cp","zwei.z2.cp","zwei.x0.cp","zwei.x1.cp","zwei.p.cp", "bzwei.x0.cp","bzwei.x1.cp","bzwei.z0.cp","bzwei.z1.cp","bzwei.z2.cp","bzwei.p.cp")#
#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
#create a dependent variable, begin the simmulations#
for(i in 1:nsims){#
  print(i)#
#Assign parameter values#
tru.est[i,1]<--1#
tru.est[i,2]<-3.5#
tru.est[i,3]<--2#
tru.est[i,4]<-2#
tru.est[i,5]<-3#
tru.est[i,6]<-1#
#
myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
y <- rexp(n, rate = myrates) # generates the r.v.#
cen <- rexp(n, rate = 1 )#
ycen <- pmin(y, cen)#
di <- as.numeric(y <= cen)#
tru.est[i,7]<-table(di)[1]#
#
#create parameters for ZG#
phi<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
print(mean(phi))#
yzero<-matrix(1,n,1)#
error<--1*rlogis(n)#
flag<-error<qlogis(phi)#
yzero[flag]<-error[flag]#
flag<-yzero==1#
di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
tru.est[i,8]<-table(di)[1]#
#
data<-cbind(ycen,di,x,z)#
######################################################################################
###################################COX Model##########################################
######################################################################################
#
#store estimate and se#
cox.est[i,1]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[1]#
cox.est[i,2]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[3]#
#
#store rmse#
cox.rmse[i,1]<-sqrt((tru.est[i,2]-cox.est[i,1])^2)#
#
#calculate upper and lower 95% CI's#
b1.lower<-cox.est[i,1]-(1.959964*cox.est[i,2])#
b1.upper<-cox.est[i,1]+(1.959964*cox.est[i,2])#
#
#store coverage parameters#
cox.cp[i,1]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
##############################################################################
########################Simple Exponential Model##############################
##############################################################################
Exponential<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)]#
	XB<-X%*%beta#
	llik<-C*(XB-exp(XB)*Y)+(1-C)*(-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Exponential<-try(optim(f=Exponential,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Exponential)=="list"){#
	ifelse(is.positive.definite(output.Exponential$hessian)==TRUE,vcv<-solve(output.Exponential$hessian),vcv<-matrix(data=NA,nrow=2,ncol=2))#
#
#store betas and ses#
exp.est[i,1]<-output.Exponential$par[1]#
exp.est[i,2]<-sqrt(vcv[1,1])#
exp.est[i,3]<-output.Exponential$par[2]#
exp.est[i,4]<-sqrt(vcv[2,2])#
#
#store rmse#
exp.rmse[i,1]<-sqrt((tru.est[i,1]-exp.est[i,1])^2)#
exp.rmse[i,2]<-sqrt((tru.est[i,2]-exp.est[i,3])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-exp.est[i,1]-(1.959964*exp.est[i,2])#
b0.upper<-exp.est[i,1]+(1.959964*exp.est[i,2])#
b1.lower<-exp.est[i,3]-(1.959964*exp.est[i,4])#
b1.upper<-exp.est[i,3]+(1.959964*exp.est[i,4])#
#store coverage parameters#
exp.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
#################################################################################
#########################Simple Weibull Model ###################################
#################################################################################
#
#Note this estiamtes the model via hazard rates, a la Stata#
#
test<-survreg(Surv(ycen, di)~x, dist="weibull")#
summary(test)#
Weibull<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)-1]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	llik<-C*(log(exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*log(exp(-(exp(XB+1/p)*Y)^p))#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(exp.est[i,1],exp.est[i,3],.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Weibull<-try(optim(f=Weibull,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Weibull)=="list"){#
	ifelse(is.positive.definite(output.Weibull$hessian)==TRUE,vcv<-solve(output.Weibull$hessian),vcv<-matrix(data=NA,nrow=3,ncol=3))#
#
#store betas and ses#
weib.est[i,1]<-output.Weibull$par[1]+1/exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,1],output.Weibull$par[3])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,3]#
varcov[2,1]<-vcv[3,1]#
varcov[2,2]<-vcv[3,3]#
weib.est[i,2]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,3]<-output.Weibull$par[2]#
weib.est[i,4]<-sqrt(vcv[2,2])#
weib.est[i,5]<-exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,5])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[3,3]#
weib.est[i,6]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,1]<-sqrt((tru.est[i,1]-weib.est[i,1])^2)#
weib.rmse[i,2]<-sqrt((tru.est[i,2]-weib.est[i,3])^2)#
weib.rmse[i,3]<-sqrt((tru.est[i,6]-weib.est[i,5])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-weib.est[i,1]-(1.959964*weib.est[i,2])#
b0.upper<-weib.est[i,1]+(1.959964*weib.est[i,2])#
b1.lower<-weib.est[i,3]-(1.959964*weib.est[i,4])#
b1.upper<-weib.est[i,3]+(1.959964*weib.est[i,4])#
p.lower<-weib.est[i,5]-(1.959964*weib.est[i,6])#
p.upper<-weib.est[i,5]+(1.959964*weib.est[i,6])#
#
#store coverage parameters#
weib.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,3]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
}#
#
###logit estimates####
dataset<-as.data.frame(data)#
logitcoef1<-glm(di~ z+x, data = dataset, family = "binomial")$coef[1]#
logitcoef2<-glm(di~ z+x, data = dataset, family = "binomial")$coef[2]#
logitcoef3<-glm(di~ z+x, data = dataset, family = "binomial")$coef[3]#
#
################################################################################
##########################Zombie Exponential Model##############################
################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZExponential<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):length(est)]#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-ZG))#
	llik<-C*(log((1-phi)+phi*exp(XB)*exp(-exp(XB)*Y)))+(1-C)*(log(phi)+-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,exp.est[i,1],exp.est[i,3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZExponential<-try(optim(f=ZExponential,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZExponential)=="list"){#
	ifelse(is.positive.definite(output.ZExponential$hessian)==TRUE,vcv<-solve(output.ZExponential$hessian),vcv<-matrix(data=NA,nrow=5,ncol=5))#
#
#store betas and ses#
exp.est[i,5]<-output.ZExponential$par[1]#
exp.est[i,6]<-sqrt(vcv[1,1])#
exp.est[i,7]<-output.ZExponential$par[2]#
exp.est[i,8]<-sqrt(vcv[2,2])#
exp.est[i,9]<-output.ZExponential$par[3]#
exp.est[i,10]<-sqrt(vcv[3,3])#
exp.est[i,11]<-output.ZExponential$par[4]#
exp.est[i,12]<-sqrt(vcv[4,4])#
exp.est[i,13]<-output.ZExponential$par[5]#
exp.est[i,14]<-sqrt(vcv[5,5])#
#
#store rmse#
exp.rmse[i,3]<-sqrt((tru.est[i,3]-exp.est[i,5])^2)#
exp.rmse[i,4]<-sqrt((tru.est[i,4]-exp.est[i,7])^2)#
exp.rmse[i,5]<-sqrt((tru.est[i,5]-exp.est[i,9])^2)#
exp.rmse[i,6]<-sqrt((tru.est[i,1]-exp.est[i,11])^2)#
exp.rmse[i,7]<-sqrt((tru.est[i,2]-exp.est[i,13])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-exp.est[i,5]-(1.959964*exp.est[i,6])#
g0.upper<-exp.est[i,5]+(1.959964*exp.est[i,6])#
g1.lower<-exp.est[i,7]-(1.959964*exp.est[i,8])#
g1.upper<-exp.est[i,7]+(1.959964*exp.est[i,8])#
g2.lower<-exp.est[i,9]-(1.959964*exp.est[i,10])#
g2.upper<-exp.est[i,9]+(1.959964*exp.est[i,10])#
b0.lower<-exp.est[i,11]-(1.959964*exp.est[i,12])#
b0.upper<-exp.est[i,11]+(1.959964*exp.est[i,12])#
b1.lower<-exp.est[i,13]-(1.959964*exp.est[i,14])#
b1.upper<-exp.est[i,13]+(1.959964*exp.est[i,14])#
#store coverage parameters#
exp.cp[i,3]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,4]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,5]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,6]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,7]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
######################################################################################
##########################Zombie Weibull Model #######################################
######################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZWeibull<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):(length(est)-1)]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-(ZG+1/p)))#
	llik<-C*(log((1-phi)+phi*exp(XB)*p*((exp(XB)*Y)^(p-1))*exp(-(exp(XB)*Y)^p)))+(1-C)*(log(phi)+-(exp(XB)*Y)^p)#
#	llik<-C*(log((1-phi)+phi*exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*(log(phi)+-(exp(XB+1/p)*Y)^p)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,output.Weibull$par[1],output.Weibull$par[2],output.Weibull$par[3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZWeibull<-try(optim(f=ZWeibull,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZWeibull)=="list"){#
	ifelse(is.positive.definite(output.ZWeibull$hessian)==TRUE,vcv<-solve(output.ZWeibull$hessian),vcv<-matrix(data=NA,nrow=6,ncol=6))#
#
#store betas and ses#
weib.est[i,7]<-output.ZWeibull$par[1]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,7],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,6]#
varcov[2,1]<-vcv[6,1]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,8]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,9]<-output.ZWeibull$par[2]#
weib.est[i,10]<-sqrt(vcv[2,2])#
weib.est[i,11]<-output.ZWeibull$par[3]#
weib.est[i,12]<-sqrt(vcv[3,3])#
weib.est[i,13]<-output.ZWeibull$par[4]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,13],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[4,4]#
varcov[1,2]<-vcv[4,6]#
varcov[2,1]<-vcv[6,4]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,14]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,15]<-output.ZWeibull$par[5]#
weib.est[i,16]<-sqrt(vcv[5,5])#
weib.est[i,17]<-exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,17])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[6,6]#
weib.est[i,18]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,4]<-sqrt((tru.est[i,3]-weib.est[i,7])^2)#
weib.rmse[i,5]<-sqrt((tru.est[i,4]-weib.est[i,9])^2)#
weib.rmse[i,6]<-sqrt((tru.est[i,5]-weib.est[i,11])^2)#
weib.rmse[i,7]<-sqrt((tru.est[i,1]-weib.est[i,13])^2)#
weib.rmse[i,8]<-sqrt((tru.est[i,2]-weib.est[i,15])^2)#
weib.rmse[i,9]<-sqrt((tru.est[i,6]-weib.est[i,17])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-weib.est[i,7]-(1.959964*weib.est[i,8])#
g0.upper<-weib.est[i,7]+(1.959964*weib.est[i,8])#
g1.lower<-weib.est[i,9]-(1.959964*weib.est[i,10])#
g1.upper<-weib.est[i,9]+(1.959964*weib.est[i,10])#
g2.lower<-weib.est[i,11]-(1.959964*weib.est[i,12])#
g2.upper<-weib.est[i,11]+(1.959964*weib.est[i,12])#
b0.lower<-weib.est[i,13]-(1.959964*weib.est[i,14])#
b0.upper<-weib.est[i,13]+(1.959964*weib.est[i,14])#
b1.lower<-weib.est[i,15]-(1.959964*weib.est[i,16])#
b1.upper<-weib.est[i,15]+(1.959964*weib.est[i,16])#
p.lower<-weib.est[i,17]-(1.959964*weib.est[i,18])#
p.upper<-weib.est[i,17]+(1.959964*weib.est[i,18])#
#
#store coverage parameters#
weib.cp[i,4]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,5]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,6]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,7]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,8]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,9]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
}#
################################################################################
######################Bayesian Zombie Exponential Model#########################
################################################################################
##set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZExponential = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Exponential")#
output.BayesZExponential = list(par = c(summary(mcmc(BayesZExponential$beta))[[1]][,1], summary(mcmc(BayesZExponential$gamma))[[1]][,1]), #
                                se = c(summary(mcmc(BayesZExponential$beta))[[1]][,4], summary(mcmc(BayesZExponential$gamma))[[1]][,4]),#
                                CI = rbind(summary(mcmc(BayesZExponential$beta))[[2]], summary(mcmc(BayesZExponential$gamma))[[2]]))#
exp.est[i,15]<-output.BayesZExponential$par[1]#
exp.est[i,16]<-output.BayesZExponential$se[1]#
exp.est[i,17]<-output.BayesZExponential$par[2]#
exp.est[i,18]<-output.BayesZExponential$se[2]#
exp.est[i,19]<-output.BayesZExponential$par[3]#
exp.est[i,20]<-output.BayesZExponential$se[3]#
exp.est[i,21]<-output.BayesZExponential$par[4]#
exp.est[i,22]<-output.BayesZExponential$se[4]#
exp.est[i,23]<-output.BayesZExponential$par[5]#
exp.est[i,24]<-output.BayesZExponential$se[5]#
#
##store rmse#
exp.rmse[i,8]<-sqrt((tru.est[i,1]-exp.est[i,15])^2)#
exp.rmse[i,9]<-sqrt((tru.est[i,2]-exp.est[i,17])^2)#
exp.rmse[i,10]<-sqrt((tru.est[i,3]-exp.est[i,19])^2)#
exp.rmse[i,11]<-sqrt((tru.est[i,4]-exp.est[i,21])^2)#
exp.rmse[i,12]<-sqrt((tru.est[i,5]-exp.est[i,23])^2)#
##calculate upper and lower 95% CI's#
b0.lower<-output.BayesZExponential$CI[1,1]#
b0.upper<-output.BayesZExponential$CI[1,5]#
b1.lower<-output.BayesZExponential$CI[2,1]#
b1.upper<-output.BayesZExponential$CI[2,5]#
g0.lower<-output.BayesZExponential$CI[3,1]#
g0.upper<-output.BayesZExponential$CI[3,5]#
g1.lower<-output.BayesZExponential$CI[4,1]#
g1.upper<-output.BayesZExponential$CI[4,5]#
g2.lower<-output.BayesZExponential$CI[5,1]#
g2.upper<-output.BayesZExponential$CI[5,5]#
#b0.lower<-exp.est[i,15]-(1.959964*exp.est[i,16])#
#b0.upper<-exp.est[i,15]+(1.959964*exp.est[i,16])#
#b1.lower<-exp.est[i,17]-(1.959964*exp.est[i,18])#
#b1.upper<-exp.est[i,17]+(1.959964*exp.est[i,18])#
#g0.lower<-exp.est[i,19]-(1.959964*exp.est[i,20])#
#g0.upper<-exp.est[i,19]+(1.959964*exp.est[i,20])#
#g1.lower<-exp.est[i,21]-(1.959964*exp.est[i,22])#
#g1.upper<-exp.est[i,21]+(1.959964*exp.est[i,22])#
#g2.lower<-exp.est[i,23]-(1.959964*exp.est[i,24])#
#g2.upper<-exp.est[i,23]+(1.959964*exp.est[i,24])#
#store coverage parameters#
exp.cp[i,8]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,9]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,10]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,11]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,12]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
################################################################################
########################Bayesian Zombie Weibull Model###########################
################################################################################
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZWeibull = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Weibull")#
output.BayesZWeibull = list(par = c(summary(mcmc(BayesZWeibull$beta))[[1]][,1], summary(mcmc(BayesZWeibull$gamma))[[1]][,1], #
                                    summary(mcmc(BayesZWeibull$lambda))[[1]][1]), #
                            se = c(summary(mcmc(BayesZWeibull$beta))[[1]][,4], summary(mcmc(BayesZWeibull$gamma))[[1]][,4], #
                                   summary(mcmc(BayesZWeibull$lambda))[[1]][4]),#
                            CI = rbind(summary(mcmc(BayesZWeibull$beta))[[2]], summary(mcmc(BayesZWeibull$gamma))[[2]], #
                                       summary(mcmc(BayesZWeibull$lambda))[[2]]))#
weib.est[i,19]<-output.BayesZWeibull$par[1]#
weib.est[i,20]<-output.BayesZWeibull$se[1]#
weib.est[i,21]<-output.BayesZWeibull$par[2]#
weib.est[i,22]<-output.BayesZWeibull$se[2]#
weib.est[i,23]<-output.BayesZWeibull$par[3]#
weib.est[i,24]<-output.BayesZWeibull$se[3]#
weib.est[i,25]<-output.BayesZWeibull$par[4]#
weib.est[i,26]<-output.BayesZWeibull$se[4]#
weib.est[i,27]<-output.BayesZWeibull$par[5]#
weib.est[i,28]<-output.BayesZWeibull$se[5]#
weib.est[i,29]<-output.BayesZWeibull$par[6]#
weib.est[i,30]<-output.BayesZWeibull$se[6]#
#
#store rmse#
weib.rmse[i,10]<-sqrt((tru.est[i,1]-weib.est[i,19])^2)#
weib.rmse[i,11]<-sqrt((tru.est[i,2]-weib.est[i,21])^2)#
weib.rmse[i,12]<-sqrt((tru.est[i,3]-weib.est[i,23])^2)#
weib.rmse[i,13]<-sqrt((tru.est[i,4]-weib.est[i,25])^2)#
weib.rmse[i,14]<-sqrt((tru.est[i,5]-weib.est[i,27])^2)#
weib.rmse[i,15]<-sqrt((tru.est[i,6]-weib.est[i,29])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-output.BayesZWeibull$CI[1,1]#
b0.upper<-output.BayesZWeibull$CI[1,5]#
b1.lower<-output.BayesZWeibull$CI[2,1]#
b1.upper<-output.BayesZWeibull$CI[2,5]#
g0.lower<-output.BayesZWeibull$CI[3,1]#
g0.upper<-output.BayesZWeibull$CI[3,5]#
g1.lower<-output.BayesZWeibull$CI[4,1]#
g1.upper<-output.BayesZWeibull$CI[4,5]#
g2.lower<-output.BayesZWeibull$CI[5,1]#
g2.upper<-output.BayesZWeibull$CI[5,5]#
p.lower<-output.BayesZWeibull$CI[6,1]#
p.upper<-output.BayesZWeibull$CI[6,2]#
# g0.lower<-weib.est[i,19]-(1.959964*weib.est[i,20])#
# g0.upper<-weib.est[i,19]+(1.959964*weib.est[i,20])#
# g1.lower<-weib.est[i,21]-(1.959964*weib.est[i,22])#
# g1.upper<-weib.est[i,21]+(1.959964*weib.est[i,22])#
# g2.lower<-weib.est[i,23]-(1.959964*weib.est[i,24])#
# g2.upper<-weib.est[i,23]+(1.959964*weib.est[i,24])#
# b0.lower<-weib.est[i,25]-(1.959964*weib.est[i,26])#
# b0.upper<-weib.est[i,25]+(1.959964*weib.est[i,26])#
# b1.lower<-weib.est[i,27]-(1.959964*weib.est[i,28])#
# b1.upper<-weib.est[i,27]+(1.959964*weib.est[i,28])#
# p.lower<-weib.est[i,29]-(1.959964*weib.est[i,30])#
# p.upper<-weib.est[i,29]+(1.959964*weib.est[i,30])#
#
#store coverage parameters#
weib.cp[i,10]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,11]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,12]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,13]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,14]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,15]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
#combine matrices and label variables#
main.data[i, ]<-c(tru.est[i, ],cox.est[i, ],exp.est[i, ],weib.est[i, ],cox.rmse[i, ],exp.rmse[i, ],weib.rmse[i, ],#
                  cox.cp[i, ],exp.cp[i, ],weib.cp[i, ])#
#
}
colMeans(main.data[1:8,])
9.087052e-01  3.676077e-01  5.204417e-01
1.020279e+00  6.987041e-01  1.145986e+00
#set seed#
set.seed(100)   #
#
#set the number of observations#
n<-1000#
#
#set the number of simulations, and create matrices to store the results#
nsims<-1000#
#history matrix for true estimates#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
#history matrix for cox estimates#
cox.est<-matrix(NA,nrow=nsims,ncol=2)#
#history matrix for exp estimates#
exp.est<-matrix(NA,nrow=nsims,ncol=24)#
#history matrix for weibull estimates#
weib.est<-matrix(NA,nrow=nsims,ncol=30)#
#history matrix for cox RMSE#
cox.rmse<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp RMSE#
exp.rmse<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp RMSE#
weib.rmse<-matrix(NA,nrow=nsims,ncol=15)#
#history matrix for cox CP#
cox.cp<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp CP#
exp.cp<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp CP#
weib.cp<-matrix(NA,nrow=nsims,ncol=15)#
main.data<-cbind(tru.est,cox.est,exp.est,weib.est,cox.rmse,exp.rmse,weib.rmse,cox.cp,exp.cp,weib.cp)#
colnames(main.data)<-c("true.x0","true.x1","true.z0","true.z1","true.z2","true.p","cen.lat","cen.obs",#
                       "cox.x1","cox.x1.se",#
                       "exp.x0","exp.x0.se","exp.x1","exp.x1.se",#
                       "zexp.z0","zexp.z0.se","zexp.z1","zexp.z1.se","zexp.z2","zexp.z2.se","zexp.x0","zexp.x0.se","zexp.x1","zexp.x1.se",#
                       "bzexp.x0","zexp.x0.se","bzexp.x1","bzexp.x1.se","bzexp.z0","bzexp.z0.se","bzexp.z1","bzexp.z1.se","bzexp.z2","bzexp.z2.se",#
                       "wei.x0","wei.x0.se","wei.x1","wei.x1.se","wei.p","wei.p.se",#
                       "zwei.z0","zwei.z0.se","zwei.z1","zwei.z1.se","zwei.z2","zwei.z2.se","zwei.x0","zwei.x0.se","zwei.x1","zwei.x1.se","zwei.p","zwei.p.se",#
                       "bzwei.x0","bzwei.x0.se","bzwei.x1","bzwei.x1.se","bzwei.z0","bzwei.z0.se","bzwei.z1","bzwei.z1.se","bzwei.z2","bzwei.z2.se","bzwei.p","bzwei.p.se",#
                       "cox.x1.rmse",#
                       "exp.x0.rmse","exp.x1.rmse","zexp.z0.rmse","zexp.z1.rmse","zexp.z2.rmse","zexp.x0.rmse","zexp.x1.rmse","bzexp.x0.rmse","bzexp.x1.rmse","bzexp.z0.rmse","bzexp.z1.rmse","bzexp.z2.rmse",#
                       "wei.x0.rmse","wei.x1.rmse","wei.p.rmse","zwei.z0.rmse","zwei.z1.rmse","zwei.z2.rmse",#
                       "zwei.x0.rmse","zwei.x1.rmse","zwei.p.rmse", "bzwei.x0.rmse","bzwei.x1.rmse","bzwei.z0.rmse","bzwei.z1.rmse","bzwei.z2.rmse","bzwei.p.rmse",#
                       "cox.x1.cp","exp.x0.cp","exp.x1.cp","zexp.z0.cp","zexp.z1.cp","zexp.z2.cp","zexp.x0.cp","zexp.x1.cp","bzexp.x0.cp","bzexp.x1.cp","bzexp.z0.cp","bzexp.z1.cp","bzexp.z2.cp",#
                       "wei.x0.cp","wei.x1.cp","wei.p.cp",#
                       "zwei.z0.cp","zwei.z1.cp","zwei.z2.cp","zwei.x0.cp","zwei.x1.cp","zwei.p.cp", "bzwei.x0.cp","bzwei.x1.cp","bzwei.z0.cp","bzwei.z1.cp","bzwei.z2.cp","bzwei.p.cp")#
#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
#create a dependent variable, begin the simmulations#
for(i in 1:nsims){#
  print(i)#
#Assign parameter values#
tru.est[i,1]<--1#
tru.est[i,2]<-3.5#
tru.est[i,3]<--2#
tru.est[i,4]<-2#
tru.est[i,5]<-3#
tru.est[i,6]<-1#
#
myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
y <- rexp(n, rate = myrates) # generates the r.v.#
cen <- rexp(n, rate = 1 )#
ycen <- pmin(y, cen)#
di <- as.numeric(y <= cen)#
tru.est[i,7]<-table(di)[1]#
#
#create parameters for ZG#
phi<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
print(mean(phi))#
yzero<-matrix(1,n,1)#
error<--1*rlogis(n)#
flag<-error<qlogis(phi)#
yzero[flag]<-error[flag]#
flag<-yzero==1#
di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
tru.est[i,8]<-table(di)[1]#
#
data<-cbind(ycen,di,x,z)#
######################################################################################
###################################COX Model##########################################
######################################################################################
#
#store estimate and se#
cox.est[i,1]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[1]#
cox.est[i,2]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[3]#
#
#store rmse#
cox.rmse[i,1]<-sqrt((tru.est[i,2]-cox.est[i,1])^2)#
#
#calculate upper and lower 95% CI's#
b1.lower<-cox.est[i,1]-(1.959964*cox.est[i,2])#
b1.upper<-cox.est[i,1]+(1.959964*cox.est[i,2])#
#
#store coverage parameters#
cox.cp[i,1]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
##############################################################################
########################Simple Exponential Model##############################
##############################################################################
Exponential<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)]#
	XB<-X%*%beta#
	llik<-C*(XB-exp(XB)*Y)+(1-C)*(-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Exponential<-try(optim(f=Exponential,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Exponential)=="list"){#
	ifelse(is.positive.definite(output.Exponential$hessian)==TRUE,vcv<-solve(output.Exponential$hessian),vcv<-matrix(data=NA,nrow=2,ncol=2))#
#
#store betas and ses#
exp.est[i,1]<-output.Exponential$par[1]#
exp.est[i,2]<-sqrt(vcv[1,1])#
exp.est[i,3]<-output.Exponential$par[2]#
exp.est[i,4]<-sqrt(vcv[2,2])#
#
#store rmse#
exp.rmse[i,1]<-sqrt((tru.est[i,1]-exp.est[i,1])^2)#
exp.rmse[i,2]<-sqrt((tru.est[i,2]-exp.est[i,3])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-exp.est[i,1]-(1.959964*exp.est[i,2])#
b0.upper<-exp.est[i,1]+(1.959964*exp.est[i,2])#
b1.lower<-exp.est[i,3]-(1.959964*exp.est[i,4])#
b1.upper<-exp.est[i,3]+(1.959964*exp.est[i,4])#
#store coverage parameters#
exp.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
#################################################################################
#########################Simple Weibull Model ###################################
#################################################################################
#
#Note this estiamtes the model via hazard rates, a la Stata#
#
test<-survreg(Surv(ycen, di)~x, dist="weibull")#
summary(test)#
Weibull<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)-1]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	llik<-C*(log(exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*log(exp(-(exp(XB+1/p)*Y)^p))#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(exp.est[i,1],exp.est[i,3],.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Weibull<-try(optim(f=Weibull,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Weibull)=="list"){#
	ifelse(is.positive.definite(output.Weibull$hessian)==TRUE,vcv<-solve(output.Weibull$hessian),vcv<-matrix(data=NA,nrow=3,ncol=3))#
#
#store betas and ses#
weib.est[i,1]<-output.Weibull$par[1]+1/exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,1],output.Weibull$par[3])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,3]#
varcov[2,1]<-vcv[3,1]#
varcov[2,2]<-vcv[3,3]#
weib.est[i,2]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,3]<-output.Weibull$par[2]#
weib.est[i,4]<-sqrt(vcv[2,2])#
weib.est[i,5]<-exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,5])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[3,3]#
weib.est[i,6]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,1]<-sqrt((tru.est[i,1]-weib.est[i,1])^2)#
weib.rmse[i,2]<-sqrt((tru.est[i,2]-weib.est[i,3])^2)#
weib.rmse[i,3]<-sqrt((tru.est[i,6]-weib.est[i,5])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-weib.est[i,1]-(1.959964*weib.est[i,2])#
b0.upper<-weib.est[i,1]+(1.959964*weib.est[i,2])#
b1.lower<-weib.est[i,3]-(1.959964*weib.est[i,4])#
b1.upper<-weib.est[i,3]+(1.959964*weib.est[i,4])#
p.lower<-weib.est[i,5]-(1.959964*weib.est[i,6])#
p.upper<-weib.est[i,5]+(1.959964*weib.est[i,6])#
#
#store coverage parameters#
weib.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,3]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
}#
#
###logit estimates####
dataset<-as.data.frame(data)#
logitcoef1<-glm(di~ z+x, data = dataset, family = "binomial")$coef[1]#
logitcoef2<-glm(di~ z+x, data = dataset, family = "binomial")$coef[2]#
logitcoef3<-glm(di~ z+x, data = dataset, family = "binomial")$coef[3]#
#
################################################################################
##########################Zombie Exponential Model##############################
################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZExponential<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):length(est)]#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-ZG))#
	llik<-C*(log((1-phi)+phi*exp(XB)*exp(-exp(XB)*Y)))+(1-C)*(log(phi)+-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,exp.est[i,1],exp.est[i,3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZExponential<-try(optim(f=ZExponential,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZExponential)=="list"){#
	ifelse(is.positive.definite(output.ZExponential$hessian)==TRUE,vcv<-solve(output.ZExponential$hessian),vcv<-matrix(data=NA,nrow=5,ncol=5))#
#
#store betas and ses#
exp.est[i,5]<-output.ZExponential$par[1]#
exp.est[i,6]<-sqrt(vcv[1,1])#
exp.est[i,7]<-output.ZExponential$par[2]#
exp.est[i,8]<-sqrt(vcv[2,2])#
exp.est[i,9]<-output.ZExponential$par[3]#
exp.est[i,10]<-sqrt(vcv[3,3])#
exp.est[i,11]<-output.ZExponential$par[4]#
exp.est[i,12]<-sqrt(vcv[4,4])#
exp.est[i,13]<-output.ZExponential$par[5]#
exp.est[i,14]<-sqrt(vcv[5,5])#
#
#store rmse#
exp.rmse[i,3]<-sqrt((tru.est[i,3]-exp.est[i,5])^2)#
exp.rmse[i,4]<-sqrt((tru.est[i,4]-exp.est[i,7])^2)#
exp.rmse[i,5]<-sqrt((tru.est[i,5]-exp.est[i,9])^2)#
exp.rmse[i,6]<-sqrt((tru.est[i,1]-exp.est[i,11])^2)#
exp.rmse[i,7]<-sqrt((tru.est[i,2]-exp.est[i,13])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-exp.est[i,5]-(1.959964*exp.est[i,6])#
g0.upper<-exp.est[i,5]+(1.959964*exp.est[i,6])#
g1.lower<-exp.est[i,7]-(1.959964*exp.est[i,8])#
g1.upper<-exp.est[i,7]+(1.959964*exp.est[i,8])#
g2.lower<-exp.est[i,9]-(1.959964*exp.est[i,10])#
g2.upper<-exp.est[i,9]+(1.959964*exp.est[i,10])#
b0.lower<-exp.est[i,11]-(1.959964*exp.est[i,12])#
b0.upper<-exp.est[i,11]+(1.959964*exp.est[i,12])#
b1.lower<-exp.est[i,13]-(1.959964*exp.est[i,14])#
b1.upper<-exp.est[i,13]+(1.959964*exp.est[i,14])#
#store coverage parameters#
exp.cp[i,3]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,4]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,5]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,6]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,7]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
######################################################################################
##########################Zombie Weibull Model #######################################
######################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZWeibull<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):(length(est)-1)]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-(ZG+1/p)))#
	llik<-C*(log((1-phi)+phi*exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*(log(phi)+-(exp(XB+1/p)*Y)^p)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,output.Weibull$par[1],output.Weibull$par[2],output.Weibull$par[3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZWeibull<-try(optim(f=ZWeibull,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZWeibull)=="list"){#
	ifelse(is.positive.definite(output.ZWeibull$hessian)==TRUE,vcv<-solve(output.ZWeibull$hessian),vcv<-matrix(data=NA,nrow=6,ncol=6))#
#
#store betas and ses#
weib.est[i,7]<-output.ZWeibull$par[1]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,7],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,6]#
varcov[2,1]<-vcv[6,1]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,8]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,9]<-output.ZWeibull$par[2]#
weib.est[i,10]<-sqrt(vcv[2,2])#
weib.est[i,11]<-output.ZWeibull$par[3]#
weib.est[i,12]<-sqrt(vcv[3,3])#
weib.est[i,13]<-output.ZWeibull$par[4]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,13],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[4,4]#
varcov[1,2]<-vcv[4,6]#
varcov[2,1]<-vcv[6,4]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,14]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,15]<-output.ZWeibull$par[5]#
weib.est[i,16]<-sqrt(vcv[5,5])#
weib.est[i,17]<-exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,17])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[6,6]#
weib.est[i,18]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,4]<-sqrt((tru.est[i,3]-weib.est[i,7])^2)#
weib.rmse[i,5]<-sqrt((tru.est[i,4]-weib.est[i,9])^2)#
weib.rmse[i,6]<-sqrt((tru.est[i,5]-weib.est[i,11])^2)#
weib.rmse[i,7]<-sqrt((tru.est[i,1]-weib.est[i,13])^2)#
weib.rmse[i,8]<-sqrt((tru.est[i,2]-weib.est[i,15])^2)#
weib.rmse[i,9]<-sqrt((tru.est[i,6]-weib.est[i,17])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-weib.est[i,7]-(1.959964*weib.est[i,8])#
g0.upper<-weib.est[i,7]+(1.959964*weib.est[i,8])#
g1.lower<-weib.est[i,9]-(1.959964*weib.est[i,10])#
g1.upper<-weib.est[i,9]+(1.959964*weib.est[i,10])#
g2.lower<-weib.est[i,11]-(1.959964*weib.est[i,12])#
g2.upper<-weib.est[i,11]+(1.959964*weib.est[i,12])#
b0.lower<-weib.est[i,13]-(1.959964*weib.est[i,14])#
b0.upper<-weib.est[i,13]+(1.959964*weib.est[i,14])#
b1.lower<-weib.est[i,15]-(1.959964*weib.est[i,16])#
b1.upper<-weib.est[i,15]+(1.959964*weib.est[i,16])#
p.lower<-weib.est[i,17]-(1.959964*weib.est[i,18])#
p.upper<-weib.est[i,17]+(1.959964*weib.est[i,18])#
#
#store coverage parameters#
weib.cp[i,4]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,5]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,6]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,7]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,8]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,9]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
}#
################################################################################
######################Bayesian Zombie Exponential Model#########################
################################################################################
##set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZExponential = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Exponential")#
output.BayesZExponential = list(par = c(summary(mcmc(BayesZExponential$beta))[[1]][,1], summary(mcmc(BayesZExponential$gamma))[[1]][,1]), #
                                se = c(summary(mcmc(BayesZExponential$beta))[[1]][,4], summary(mcmc(BayesZExponential$gamma))[[1]][,4]),#
                                CI = rbind(summary(mcmc(BayesZExponential$beta))[[2]], summary(mcmc(BayesZExponential$gamma))[[2]]))#
exp.est[i,15]<-output.BayesZExponential$par[1]#
exp.est[i,16]<-output.BayesZExponential$se[1]#
exp.est[i,17]<-output.BayesZExponential$par[2]#
exp.est[i,18]<-output.BayesZExponential$se[2]#
exp.est[i,19]<-output.BayesZExponential$par[3]#
exp.est[i,20]<-output.BayesZExponential$se[3]#
exp.est[i,21]<-output.BayesZExponential$par[4]#
exp.est[i,22]<-output.BayesZExponential$se[4]#
exp.est[i,23]<-output.BayesZExponential$par[5]#
exp.est[i,24]<-output.BayesZExponential$se[5]#
#
##store rmse#
exp.rmse[i,8]<-sqrt((tru.est[i,1]-exp.est[i,15])^2)#
exp.rmse[i,9]<-sqrt((tru.est[i,2]-exp.est[i,17])^2)#
exp.rmse[i,10]<-sqrt((tru.est[i,3]-exp.est[i,19])^2)#
exp.rmse[i,11]<-sqrt((tru.est[i,4]-exp.est[i,21])^2)#
exp.rmse[i,12]<-sqrt((tru.est[i,5]-exp.est[i,23])^2)#
##calculate upper and lower 95% CI's#
b0.lower<-output.BayesZExponential$CI[1,1]#
b0.upper<-output.BayesZExponential$CI[1,5]#
b1.lower<-output.BayesZExponential$CI[2,1]#
b1.upper<-output.BayesZExponential$CI[2,5]#
g0.lower<-output.BayesZExponential$CI[3,1]#
g0.upper<-output.BayesZExponential$CI[3,5]#
g1.lower<-output.BayesZExponential$CI[4,1]#
g1.upper<-output.BayesZExponential$CI[4,5]#
g2.lower<-output.BayesZExponential$CI[5,1]#
g2.upper<-output.BayesZExponential$CI[5,5]#
#b0.lower<-exp.est[i,15]-(1.959964*exp.est[i,16])#
#b0.upper<-exp.est[i,15]+(1.959964*exp.est[i,16])#
#b1.lower<-exp.est[i,17]-(1.959964*exp.est[i,18])#
#b1.upper<-exp.est[i,17]+(1.959964*exp.est[i,18])#
#g0.lower<-exp.est[i,19]-(1.959964*exp.est[i,20])#
#g0.upper<-exp.est[i,19]+(1.959964*exp.est[i,20])#
#g1.lower<-exp.est[i,21]-(1.959964*exp.est[i,22])#
#g1.upper<-exp.est[i,21]+(1.959964*exp.est[i,22])#
#g2.lower<-exp.est[i,23]-(1.959964*exp.est[i,24])#
#g2.upper<-exp.est[i,23]+(1.959964*exp.est[i,24])#
#store coverage parameters#
exp.cp[i,8]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,9]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,10]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,11]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,12]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
################################################################################
########################Bayesian Zombie Weibull Model###########################
################################################################################
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZWeibull = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Weibull")#
output.BayesZWeibull = list(par = c(summary(mcmc(BayesZWeibull$beta))[[1]][,1], summary(mcmc(BayesZWeibull$gamma))[[1]][,1], #
                                    summary(mcmc(BayesZWeibull$lambda))[[1]][1]), #
                            se = c(summary(mcmc(BayesZWeibull$beta))[[1]][,4], summary(mcmc(BayesZWeibull$gamma))[[1]][,4], #
                                   summary(mcmc(BayesZWeibull$lambda))[[1]][4]),#
                            CI = rbind(summary(mcmc(BayesZWeibull$beta))[[2]], summary(mcmc(BayesZWeibull$gamma))[[2]], #
                                       summary(mcmc(BayesZWeibull$lambda))[[2]]))#
weib.est[i,19]<-output.BayesZWeibull$par[1]#
weib.est[i,20]<-output.BayesZWeibull$se[1]#
weib.est[i,21]<-output.BayesZWeibull$par[2]#
weib.est[i,22]<-output.BayesZWeibull$se[2]#
weib.est[i,23]<-output.BayesZWeibull$par[3]#
weib.est[i,24]<-output.BayesZWeibull$se[3]#
weib.est[i,25]<-output.BayesZWeibull$par[4]#
weib.est[i,26]<-output.BayesZWeibull$se[4]#
weib.est[i,27]<-output.BayesZWeibull$par[5]#
weib.est[i,28]<-output.BayesZWeibull$se[5]#
weib.est[i,29]<-output.BayesZWeibull$par[6]#
weib.est[i,30]<-output.BayesZWeibull$se[6]#
#
#store rmse#
weib.rmse[i,10]<-sqrt((tru.est[i,1]-weib.est[i,19])^2)#
weib.rmse[i,11]<-sqrt((tru.est[i,2]-weib.est[i,21])^2)#
weib.rmse[i,12]<-sqrt((tru.est[i,3]-weib.est[i,23])^2)#
weib.rmse[i,13]<-sqrt((tru.est[i,4]-weib.est[i,25])^2)#
weib.rmse[i,14]<-sqrt((tru.est[i,5]-weib.est[i,27])^2)#
weib.rmse[i,15]<-sqrt((tru.est[i,6]-weib.est[i,29])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-output.BayesZWeibull$CI[1,1]#
b0.upper<-output.BayesZWeibull$CI[1,5]#
b1.lower<-output.BayesZWeibull$CI[2,1]#
b1.upper<-output.BayesZWeibull$CI[2,5]#
g0.lower<-output.BayesZWeibull$CI[3,1]#
g0.upper<-output.BayesZWeibull$CI[3,5]#
g1.lower<-output.BayesZWeibull$CI[4,1]#
g1.upper<-output.BayesZWeibull$CI[4,5]#
g2.lower<-output.BayesZWeibull$CI[5,1]#
g2.upper<-output.BayesZWeibull$CI[5,5]#
p.lower<-output.BayesZWeibull$CI[6,1]#
p.upper<-output.BayesZWeibull$CI[6,2]#
# g0.lower<-weib.est[i,19]-(1.959964*weib.est[i,20])#
# g0.upper<-weib.est[i,19]+(1.959964*weib.est[i,20])#
# g1.lower<-weib.est[i,21]-(1.959964*weib.est[i,22])#
# g1.upper<-weib.est[i,21]+(1.959964*weib.est[i,22])#
# g2.lower<-weib.est[i,23]-(1.959964*weib.est[i,24])#
# g2.upper<-weib.est[i,23]+(1.959964*weib.est[i,24])#
# b0.lower<-weib.est[i,25]-(1.959964*weib.est[i,26])#
# b0.upper<-weib.est[i,25]+(1.959964*weib.est[i,26])#
# b1.lower<-weib.est[i,27]-(1.959964*weib.est[i,28])#
# b1.upper<-weib.est[i,27]+(1.959964*weib.est[i,28])#
# p.lower<-weib.est[i,29]-(1.959964*weib.est[i,30])#
# p.upper<-weib.est[i,29]+(1.959964*weib.est[i,30])#
#
#store coverage parameters#
weib.cp[i,10]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,11]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,12]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,13]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,14]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,15]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
#combine matrices and label variables#
main.data[i, ]<-c(tru.est[i, ],cox.est[i, ],exp.est[i, ],weib.est[i, ],cox.rmse[i, ],exp.rmse[i, ],weib.rmse[i, ],#
                  cox.cp[i, ],exp.cp[i, ],weib.cp[i, ])#
#
}
colMeans(main.data[1:5,])
#clear memory#
rm( list=ls() )#
#
#load necessary libraries 						                                 #
library(foreign)#
library(Zelig)#
library(car)#
library(MASS)#
library(VGAM)#
library(plotrix)#
library(pscl)#
library(survival)#
library(msm)#
library(verification)#
library(corpcor)#
library(Design)#
library(coda)#
library(mcmcse)#
#library(devtools)#
#install_github('bomin8319/BayesOFsurv/pkg')#
library(BayesOFsurv)#
#set working directory#
setwd("/Users/bomin8319/Desktop/BayesOFsurv/coding material/Monte Carlos/Mixture DGP/")#
#
###########################################################################
###########################################################################
############################Monte Carlo####################################
###########################################################################
#
#set seed#
set.seed(100)   #
#
#set the number of observations#
n<-1000#
#
#set the number of simulations, and create matrices to store the results#
nsims<-1000#
#history matrix for true estimates#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
#history matrix for cox estimates#
cox.est<-matrix(NA,nrow=nsims,ncol=2)#
#history matrix for exp estimates#
exp.est<-matrix(NA,nrow=nsims,ncol=24)#
#history matrix for weibull estimates#
weib.est<-matrix(NA,nrow=nsims,ncol=30)#
#history matrix for cox RMSE#
cox.rmse<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp RMSE#
exp.rmse<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp RMSE#
weib.rmse<-matrix(NA,nrow=nsims,ncol=15)#
#history matrix for cox CP#
cox.cp<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp CP#
exp.cp<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp CP#
weib.cp<-matrix(NA,nrow=nsims,ncol=15)#
main.data<-cbind(tru.est,cox.est,exp.est,weib.est,cox.rmse,exp.rmse,weib.rmse,cox.cp,exp.cp,weib.cp)#
colnames(main.data)<-c("true.x0","true.x1","true.z0","true.z1","true.z2","true.p","cen.lat","cen.obs",#
                       "cox.x1","cox.x1.se",#
                       "exp.x0","exp.x0.se","exp.x1","exp.x1.se",#
                       "zexp.z0","zexp.z0.se","zexp.z1","zexp.z1.se","zexp.z2","zexp.z2.se","zexp.x0","zexp.x0.se","zexp.x1","zexp.x1.se",#
                       "bzexp.x0","zexp.x0.se","bzexp.x1","bzexp.x1.se","bzexp.z0","bzexp.z0.se","bzexp.z1","bzexp.z1.se","bzexp.z2","bzexp.z2.se",#
                       "wei.x0","wei.x0.se","wei.x1","wei.x1.se","wei.p","wei.p.se",#
                       "zwei.z0","zwei.z0.se","zwei.z1","zwei.z1.se","zwei.z2","zwei.z2.se","zwei.x0","zwei.x0.se","zwei.x1","zwei.x1.se","zwei.p","zwei.p.se",#
                       "bzwei.x0","bzwei.x0.se","bzwei.x1","bzwei.x1.se","bzwei.z0","bzwei.z0.se","bzwei.z1","bzwei.z1.se","bzwei.z2","bzwei.z2.se","bzwei.p","bzwei.p.se",#
                       "cox.x1.rmse",#
                       "exp.x0.rmse","exp.x1.rmse","zexp.z0.rmse","zexp.z1.rmse","zexp.z2.rmse","zexp.x0.rmse","zexp.x1.rmse","bzexp.x0.rmse","bzexp.x1.rmse","bzexp.z0.rmse","bzexp.z1.rmse","bzexp.z2.rmse",#
                       "wei.x0.rmse","wei.x1.rmse","wei.p.rmse","zwei.z0.rmse","zwei.z1.rmse","zwei.z2.rmse",#
                       "zwei.x0.rmse","zwei.x1.rmse","zwei.p.rmse", "bzwei.x0.rmse","bzwei.x1.rmse","bzwei.z0.rmse","bzwei.z1.rmse","bzwei.z2.rmse","bzwei.p.rmse",#
                       "cox.x1.cp","exp.x0.cp","exp.x1.cp","zexp.z0.cp","zexp.z1.cp","zexp.z2.cp","zexp.x0.cp","zexp.x1.cp","bzexp.x0.cp","bzexp.x1.cp","bzexp.z0.cp","bzexp.z1.cp","bzexp.z2.cp",#
                       "wei.x0.cp","wei.x1.cp","wei.p.cp",#
                       "zwei.z0.cp","zwei.z1.cp","zwei.z2.cp","zwei.x0.cp","zwei.x1.cp","zwei.p.cp", "bzwei.x0.cp","bzwei.x1.cp","bzwei.z0.cp","bzwei.z1.cp","bzwei.z2.cp","bzwei.p.cp")#
#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
#create a dependent variable, begin the simmulations#
for(i in 1:nsims){#
  print(i)#
#Assign parameter values#
tru.est[i,1]<-1#
tru.est[i,2]<-3.5#
tru.est[i,3]<--2#
tru.est[i,4]<-2#
tru.est[i,5]<-3#
tru.est[i,6]<-1#
#
myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
y <- rexp(n, rate = myrates) # generates the r.v.#
cen <- rexp(n, rate = 1 )#
ycen <- pmin(y, cen)#
di <- as.numeric(y <= cen)#
tru.est[i,7]<-table(di)[1]#
#
#create parameters for ZG#
phi<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
print(mean(phi))#
yzero<-matrix(1,n,1)#
error<--1*rlogis(n)#
flag<-error<qlogis(phi)#
yzero[flag]<-error[flag]#
flag<-yzero==1#
di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
tru.est[i,8]<-table(di)[1]#
#
data<-cbind(ycen,di,x,z)#
######################################################################################
###################################COX Model##########################################
######################################################################################
#
#store estimate and se#
cox.est[i,1]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[1]#
cox.est[i,2]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[3]#
#
#store rmse#
cox.rmse[i,1]<-sqrt((tru.est[i,2]-cox.est[i,1])^2)#
#
#calculate upper and lower 95% CI's#
b1.lower<-cox.est[i,1]-(1.959964*cox.est[i,2])#
b1.upper<-cox.est[i,1]+(1.959964*cox.est[i,2])#
#
#store coverage parameters#
cox.cp[i,1]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
##############################################################################
########################Simple Exponential Model##############################
##############################################################################
Exponential<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)]#
	XB<-X%*%beta#
	llik<-C*(XB-exp(XB)*Y)+(1-C)*(-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Exponential<-try(optim(f=Exponential,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Exponential)=="list"){#
	ifelse(is.positive.definite(output.Exponential$hessian)==TRUE,vcv<-solve(output.Exponential$hessian),vcv<-matrix(data=NA,nrow=2,ncol=2))#
#
#store betas and ses#
exp.est[i,1]<-output.Exponential$par[1]#
exp.est[i,2]<-sqrt(vcv[1,1])#
exp.est[i,3]<-output.Exponential$par[2]#
exp.est[i,4]<-sqrt(vcv[2,2])#
#
#store rmse#
exp.rmse[i,1]<-sqrt((tru.est[i,1]-exp.est[i,1])^2)#
exp.rmse[i,2]<-sqrt((tru.est[i,2]-exp.est[i,3])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-exp.est[i,1]-(1.959964*exp.est[i,2])#
b0.upper<-exp.est[i,1]+(1.959964*exp.est[i,2])#
b1.lower<-exp.est[i,3]-(1.959964*exp.est[i,4])#
b1.upper<-exp.est[i,3]+(1.959964*exp.est[i,4])#
#store coverage parameters#
exp.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
#################################################################################
#########################Simple Weibull Model ###################################
#################################################################################
#
#Note this estiamtes the model via hazard rates, a la Stata#
#
test<-survreg(Surv(ycen, di)~x, dist="weibull")#
summary(test)#
Weibull<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)-1]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	llik<-C*(log(exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*log(exp(-(exp(XB+1/p)*Y)^p))#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(exp.est[i,1],exp.est[i,3],.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Weibull<-try(optim(f=Weibull,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Weibull)=="list"){#
	ifelse(is.positive.definite(output.Weibull$hessian)==TRUE,vcv<-solve(output.Weibull$hessian),vcv<-matrix(data=NA,nrow=3,ncol=3))#
#
#store betas and ses#
weib.est[i,1]<-output.Weibull$par[1]+1/exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,1],output.Weibull$par[3])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,3]#
varcov[2,1]<-vcv[3,1]#
varcov[2,2]<-vcv[3,3]#
weib.est[i,2]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,3]<-output.Weibull$par[2]#
weib.est[i,4]<-sqrt(vcv[2,2])#
weib.est[i,5]<-exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,5])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[3,3]#
weib.est[i,6]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,1]<-sqrt((tru.est[i,1]-weib.est[i,1])^2)#
weib.rmse[i,2]<-sqrt((tru.est[i,2]-weib.est[i,3])^2)#
weib.rmse[i,3]<-sqrt((tru.est[i,6]-weib.est[i,5])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-weib.est[i,1]-(1.959964*weib.est[i,2])#
b0.upper<-weib.est[i,1]+(1.959964*weib.est[i,2])#
b1.lower<-weib.est[i,3]-(1.959964*weib.est[i,4])#
b1.upper<-weib.est[i,3]+(1.959964*weib.est[i,4])#
p.lower<-weib.est[i,5]-(1.959964*weib.est[i,6])#
p.upper<-weib.est[i,5]+(1.959964*weib.est[i,6])#
#
#store coverage parameters#
weib.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,3]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
}#
#
###logit estimates####
dataset<-as.data.frame(data)#
logitcoef1<-glm(di~ z+x, data = dataset, family = "binomial")$coef[1]#
logitcoef2<-glm(di~ z+x, data = dataset, family = "binomial")$coef[2]#
logitcoef3<-glm(di~ z+x, data = dataset, family = "binomial")$coef[3]#
#
################################################################################
##########################Zombie Exponential Model##############################
################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZExponential<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):length(est)]#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-ZG))#
	llik<-C*(log((1-phi)+phi*exp(XB)*exp(-exp(XB)*Y)))+(1-C)*(log(phi)+-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,exp.est[i,1],exp.est[i,3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZExponential<-try(optim(f=ZExponential,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZExponential)=="list"){#
	ifelse(is.positive.definite(output.ZExponential$hessian)==TRUE,vcv<-solve(output.ZExponential$hessian),vcv<-matrix(data=NA,nrow=5,ncol=5))#
#
#store betas and ses#
exp.est[i,5]<-output.ZExponential$par[1]#
exp.est[i,6]<-sqrt(vcv[1,1])#
exp.est[i,7]<-output.ZExponential$par[2]#
exp.est[i,8]<-sqrt(vcv[2,2])#
exp.est[i,9]<-output.ZExponential$par[3]#
exp.est[i,10]<-sqrt(vcv[3,3])#
exp.est[i,11]<-output.ZExponential$par[4]#
exp.est[i,12]<-sqrt(vcv[4,4])#
exp.est[i,13]<-output.ZExponential$par[5]#
exp.est[i,14]<-sqrt(vcv[5,5])#
#
#store rmse#
exp.rmse[i,3]<-sqrt((tru.est[i,3]-exp.est[i,5])^2)#
exp.rmse[i,4]<-sqrt((tru.est[i,4]-exp.est[i,7])^2)#
exp.rmse[i,5]<-sqrt((tru.est[i,5]-exp.est[i,9])^2)#
exp.rmse[i,6]<-sqrt((tru.est[i,1]-exp.est[i,11])^2)#
exp.rmse[i,7]<-sqrt((tru.est[i,2]-exp.est[i,13])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-exp.est[i,5]-(1.959964*exp.est[i,6])#
g0.upper<-exp.est[i,5]+(1.959964*exp.est[i,6])#
g1.lower<-exp.est[i,7]-(1.959964*exp.est[i,8])#
g1.upper<-exp.est[i,7]+(1.959964*exp.est[i,8])#
g2.lower<-exp.est[i,9]-(1.959964*exp.est[i,10])#
g2.upper<-exp.est[i,9]+(1.959964*exp.est[i,10])#
b0.lower<-exp.est[i,11]-(1.959964*exp.est[i,12])#
b0.upper<-exp.est[i,11]+(1.959964*exp.est[i,12])#
b1.lower<-exp.est[i,13]-(1.959964*exp.est[i,14])#
b1.upper<-exp.est[i,13]+(1.959964*exp.est[i,14])#
#store coverage parameters#
exp.cp[i,3]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,4]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,5]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,6]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,7]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
######################################################################################
##########################Zombie Weibull Model #######################################
######################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZWeibull<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):(length(est)-1)]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-(ZG+1/p)))#
	llik<-C*(log((1-phi)+phi*exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*(log(phi)+-(exp(XB+1/p)*Y)^p)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,output.Weibull$par[1],output.Weibull$par[2],output.Weibull$par[3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZWeibull<-try(optim(f=ZWeibull,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZWeibull)=="list"){#
	ifelse(is.positive.definite(output.ZWeibull$hessian)==TRUE,vcv<-solve(output.ZWeibull$hessian),vcv<-matrix(data=NA,nrow=6,ncol=6))#
#
#store betas and ses#
weib.est[i,7]<-output.ZWeibull$par[1]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,7],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,6]#
varcov[2,1]<-vcv[6,1]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,8]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,9]<-output.ZWeibull$par[2]#
weib.est[i,10]<-sqrt(vcv[2,2])#
weib.est[i,11]<-output.ZWeibull$par[3]#
weib.est[i,12]<-sqrt(vcv[3,3])#
weib.est[i,13]<-output.ZWeibull$par[4]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,13],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[4,4]#
varcov[1,2]<-vcv[4,6]#
varcov[2,1]<-vcv[6,4]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,14]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,15]<-output.ZWeibull$par[5]#
weib.est[i,16]<-sqrt(vcv[5,5])#
weib.est[i,17]<-exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,17])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[6,6]#
weib.est[i,18]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,4]<-sqrt((tru.est[i,3]-weib.est[i,7])^2)#
weib.rmse[i,5]<-sqrt((tru.est[i,4]-weib.est[i,9])^2)#
weib.rmse[i,6]<-sqrt((tru.est[i,5]-weib.est[i,11])^2)#
weib.rmse[i,7]<-sqrt((tru.est[i,1]-weib.est[i,13])^2)#
weib.rmse[i,8]<-sqrt((tru.est[i,2]-weib.est[i,15])^2)#
weib.rmse[i,9]<-sqrt((tru.est[i,6]-weib.est[i,17])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-weib.est[i,7]-(1.959964*weib.est[i,8])#
g0.upper<-weib.est[i,7]+(1.959964*weib.est[i,8])#
g1.lower<-weib.est[i,9]-(1.959964*weib.est[i,10])#
g1.upper<-weib.est[i,9]+(1.959964*weib.est[i,10])#
g2.lower<-weib.est[i,11]-(1.959964*weib.est[i,12])#
g2.upper<-weib.est[i,11]+(1.959964*weib.est[i,12])#
b0.lower<-weib.est[i,13]-(1.959964*weib.est[i,14])#
b0.upper<-weib.est[i,13]+(1.959964*weib.est[i,14])#
b1.lower<-weib.est[i,15]-(1.959964*weib.est[i,16])#
b1.upper<-weib.est[i,15]+(1.959964*weib.est[i,16])#
p.lower<-weib.est[i,17]-(1.959964*weib.est[i,18])#
p.upper<-weib.est[i,17]+(1.959964*weib.est[i,18])#
#
#store coverage parameters#
weib.cp[i,4]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,5]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,6]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,7]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,8]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,9]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
}#
################################################################################
######################Bayesian Zombie Exponential Model#########################
################################################################################
##set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZExponential = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Exponential")#
output.BayesZExponential = list(par = c(summary(mcmc(BayesZExponential$beta))[[1]][,1], summary(mcmc(BayesZExponential$gamma))[[1]][,1]), #
                                se = c(summary(mcmc(BayesZExponential$beta))[[1]][,4], summary(mcmc(BayesZExponential$gamma))[[1]][,4]),#
                                CI = rbind(summary(mcmc(BayesZExponential$beta))[[2]], summary(mcmc(BayesZExponential$gamma))[[2]]))#
exp.est[i,15]<-output.BayesZExponential$par[1]#
exp.est[i,16]<-output.BayesZExponential$se[1]#
exp.est[i,17]<-output.BayesZExponential$par[2]#
exp.est[i,18]<-output.BayesZExponential$se[2]#
exp.est[i,19]<-output.BayesZExponential$par[3]#
exp.est[i,20]<-output.BayesZExponential$se[3]#
exp.est[i,21]<-output.BayesZExponential$par[4]#
exp.est[i,22]<-output.BayesZExponential$se[4]#
exp.est[i,23]<-output.BayesZExponential$par[5]#
exp.est[i,24]<-output.BayesZExponential$se[5]#
#
##store rmse#
exp.rmse[i,8]<-sqrt((tru.est[i,1]-exp.est[i,15])^2)#
exp.rmse[i,9]<-sqrt((tru.est[i,2]-exp.est[i,17])^2)#
exp.rmse[i,10]<-sqrt((tru.est[i,3]-exp.est[i,19])^2)#
exp.rmse[i,11]<-sqrt((tru.est[i,4]-exp.est[i,21])^2)#
exp.rmse[i,12]<-sqrt((tru.est[i,5]-exp.est[i,23])^2)#
##calculate upper and lower 95% CI's#
b0.lower<-output.BayesZExponential$CI[1,1]#
b0.upper<-output.BayesZExponential$CI[1,5]#
b1.lower<-output.BayesZExponential$CI[2,1]#
b1.upper<-output.BayesZExponential$CI[2,5]#
g0.lower<-output.BayesZExponential$CI[3,1]#
g0.upper<-output.BayesZExponential$CI[3,5]#
g1.lower<-output.BayesZExponential$CI[4,1]#
g1.upper<-output.BayesZExponential$CI[4,5]#
g2.lower<-output.BayesZExponential$CI[5,1]#
g2.upper<-output.BayesZExponential$CI[5,5]#
#b0.lower<-exp.est[i,15]-(1.959964*exp.est[i,16])#
#b0.upper<-exp.est[i,15]+(1.959964*exp.est[i,16])#
#b1.lower<-exp.est[i,17]-(1.959964*exp.est[i,18])#
#b1.upper<-exp.est[i,17]+(1.959964*exp.est[i,18])#
#g0.lower<-exp.est[i,19]-(1.959964*exp.est[i,20])#
#g0.upper<-exp.est[i,19]+(1.959964*exp.est[i,20])#
#g1.lower<-exp.est[i,21]-(1.959964*exp.est[i,22])#
#g1.upper<-exp.est[i,21]+(1.959964*exp.est[i,22])#
#g2.lower<-exp.est[i,23]-(1.959964*exp.est[i,24])#
#g2.upper<-exp.est[i,23]+(1.959964*exp.est[i,24])#
#store coverage parameters#
exp.cp[i,8]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,9]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,10]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,11]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,12]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
################################################################################
########################Bayesian Zombie Weibull Model###########################
################################################################################
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZWeibull = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Weibull")#
output.BayesZWeibull = list(par = c(summary(mcmc(BayesZWeibull$beta))[[1]][,1], summary(mcmc(BayesZWeibull$gamma))[[1]][,1], #
                                    summary(mcmc(BayesZWeibull$lambda))[[1]][1]), #
                            se = c(summary(mcmc(BayesZWeibull$beta))[[1]][,4], summary(mcmc(BayesZWeibull$gamma))[[1]][,4], #
                                   summary(mcmc(BayesZWeibull$lambda))[[1]][4]),#
                            CI = rbind(summary(mcmc(BayesZWeibull$beta))[[2]], summary(mcmc(BayesZWeibull$gamma))[[2]], #
                                       summary(mcmc(BayesZWeibull$lambda))[[2]]))#
weib.est[i,19]<-output.BayesZWeibull$par[1]#
weib.est[i,20]<-output.BayesZWeibull$se[1]#
weib.est[i,21]<-output.BayesZWeibull$par[2]#
weib.est[i,22]<-output.BayesZWeibull$se[2]#
weib.est[i,23]<-output.BayesZWeibull$par[3]#
weib.est[i,24]<-output.BayesZWeibull$se[3]#
weib.est[i,25]<-output.BayesZWeibull$par[4]#
weib.est[i,26]<-output.BayesZWeibull$se[4]#
weib.est[i,27]<-output.BayesZWeibull$par[5]#
weib.est[i,28]<-output.BayesZWeibull$se[5]#
weib.est[i,29]<-output.BayesZWeibull$par[6]#
weib.est[i,30]<-output.BayesZWeibull$se[6]#
#
#store rmse#
weib.rmse[i,10]<-sqrt((tru.est[i,1]-weib.est[i,19])^2)#
weib.rmse[i,11]<-sqrt((tru.est[i,2]-weib.est[i,21])^2)#
weib.rmse[i,12]<-sqrt((tru.est[i,3]-weib.est[i,23])^2)#
weib.rmse[i,13]<-sqrt((tru.est[i,4]-weib.est[i,25])^2)#
weib.rmse[i,14]<-sqrt((tru.est[i,5]-weib.est[i,27])^2)#
weib.rmse[i,15]<-sqrt((tru.est[i,6]-weib.est[i,29])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-output.BayesZWeibull$CI[1,1]#
b0.upper<-output.BayesZWeibull$CI[1,5]#
b1.lower<-output.BayesZWeibull$CI[2,1]#
b1.upper<-output.BayesZWeibull$CI[2,5]#
g0.lower<-output.BayesZWeibull$CI[3,1]#
g0.upper<-output.BayesZWeibull$CI[3,5]#
g1.lower<-output.BayesZWeibull$CI[4,1]#
g1.upper<-output.BayesZWeibull$CI[4,5]#
g2.lower<-output.BayesZWeibull$CI[5,1]#
g2.upper<-output.BayesZWeibull$CI[5,5]#
p.lower<-output.BayesZWeibull$CI[6,1]#
p.upper<-output.BayesZWeibull$CI[6,2]#
# g0.lower<-weib.est[i,19]-(1.959964*weib.est[i,20])#
# g0.upper<-weib.est[i,19]+(1.959964*weib.est[i,20])#
# g1.lower<-weib.est[i,21]-(1.959964*weib.est[i,22])#
# g1.upper<-weib.est[i,21]+(1.959964*weib.est[i,22])#
# g2.lower<-weib.est[i,23]-(1.959964*weib.est[i,24])#
# g2.upper<-weib.est[i,23]+(1.959964*weib.est[i,24])#
# b0.lower<-weib.est[i,25]-(1.959964*weib.est[i,26])#
# b0.upper<-weib.est[i,25]+(1.959964*weib.est[i,26])#
# b1.lower<-weib.est[i,27]-(1.959964*weib.est[i,28])#
# b1.upper<-weib.est[i,27]+(1.959964*weib.est[i,28])#
# p.lower<-weib.est[i,29]-(1.959964*weib.est[i,30])#
# p.upper<-weib.est[i,29]+(1.959964*weib.est[i,30])#
#
#store coverage parameters#
weib.cp[i,10]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,11]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,12]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,13]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,14]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,15]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
#combine matrices and label variables#
main.data[i, ]<-c(tru.est[i, ],cox.est[i, ],exp.est[i, ],weib.est[i, ],cox.rmse[i, ],exp.rmse[i, ],weib.rmse[i, ],#
                  cox.cp[i, ],exp.cp[i, ],weib.cp[i, ])#
#
}
colMeans(main.data[1:10,])
document()
document()
library(devtools)
setwd('/Users/bomin8319/Desktop/BayesOFsurv/pkg')
document()
install()
library(BayesOFsurv)
#set seed#
set.seed(100)   #
#
#set the number of observations#
n<-1000#
#
#set the number of simulations, and create matrices to store the results#
nsims<-1000#
#history matrix for true estimates#
tru.est<-matrix(NA,nrow=nsims,ncol=8)#
#history matrix for cox estimates#
cox.est<-matrix(NA,nrow=nsims,ncol=2)#
#history matrix for exp estimates#
exp.est<-matrix(NA,nrow=nsims,ncol=24)#
#history matrix for weibull estimates#
weib.est<-matrix(NA,nrow=nsims,ncol=30)#
#history matrix for cox RMSE#
cox.rmse<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp RMSE#
exp.rmse<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp RMSE#
weib.rmse<-matrix(NA,nrow=nsims,ncol=15)#
#history matrix for cox CP#
cox.cp<-matrix(NA,nrow=nsims,ncol=1)#
#history matrix for exp CP#
exp.cp<-matrix(NA,nrow=nsims,ncol=12)#
#history matrix for exp CP#
weib.cp<-matrix(NA,nrow=nsims,ncol=15)#
main.data<-cbind(tru.est,cox.est,exp.est,weib.est,cox.rmse,exp.rmse,weib.rmse,cox.cp,exp.cp,weib.cp)#
colnames(main.data)<-c("true.x0","true.x1","true.z0","true.z1","true.z2","true.p","cen.lat","cen.obs",#
                       "cox.x1","cox.x1.se",#
                       "exp.x0","exp.x0.se","exp.x1","exp.x1.se",#
                       "zexp.z0","zexp.z0.se","zexp.z1","zexp.z1.se","zexp.z2","zexp.z2.se","zexp.x0","zexp.x0.se","zexp.x1","zexp.x1.se",#
                       "bzexp.x0","zexp.x0.se","bzexp.x1","bzexp.x1.se","bzexp.z0","bzexp.z0.se","bzexp.z1","bzexp.z1.se","bzexp.z2","bzexp.z2.se",#
                       "wei.x0","wei.x0.se","wei.x1","wei.x1.se","wei.p","wei.p.se",#
                       "zwei.z0","zwei.z0.se","zwei.z1","zwei.z1.se","zwei.z2","zwei.z2.se","zwei.x0","zwei.x0.se","zwei.x1","zwei.x1.se","zwei.p","zwei.p.se",#
                       "bzwei.x0","bzwei.x0.se","bzwei.x1","bzwei.x1.se","bzwei.z0","bzwei.z0.se","bzwei.z1","bzwei.z1.se","bzwei.z2","bzwei.z2.se","bzwei.p","bzwei.p.se",#
                       "cox.x1.rmse",#
                       "exp.x0.rmse","exp.x1.rmse","zexp.z0.rmse","zexp.z1.rmse","zexp.z2.rmse","zexp.x0.rmse","zexp.x1.rmse","bzexp.x0.rmse","bzexp.x1.rmse","bzexp.z0.rmse","bzexp.z1.rmse","bzexp.z2.rmse",#
                       "wei.x0.rmse","wei.x1.rmse","wei.p.rmse","zwei.z0.rmse","zwei.z1.rmse","zwei.z2.rmse",#
                       "zwei.x0.rmse","zwei.x1.rmse","zwei.p.rmse", "bzwei.x0.rmse","bzwei.x1.rmse","bzwei.z0.rmse","bzwei.z1.rmse","bzwei.z2.rmse","bzwei.p.rmse",#
                       "cox.x1.cp","exp.x0.cp","exp.x1.cp","zexp.z0.cp","zexp.z1.cp","zexp.z2.cp","zexp.x0.cp","zexp.x1.cp","bzexp.x0.cp","bzexp.x1.cp","bzexp.z0.cp","bzexp.z1.cp","bzexp.z2.cp",#
                       "wei.x0.cp","wei.x1.cp","wei.p.cp",#
                       "zwei.z0.cp","zwei.z1.cp","zwei.z2.cp","zwei.x0.cp","zwei.x1.cp","zwei.p.cp", "bzwei.x0.cp","bzwei.x1.cp","bzwei.z0.cp","bzwei.z1.cp","bzwei.z2.cp","bzwei.p.cp")#
#
#create covariates#
x<-runif(n, min=-2.5, max=12)#
z<-log(runif(n, min=1, max=100))#
#create a dependent variable, begin the simmulations#
for(i in 1:nsims){#
  print(i)#
#Assign parameter values#
tru.est[i,1]<-1#
tru.est[i,2]<-3.5#
tru.est[i,3]<--2#
tru.est[i,4]<-2#
tru.est[i,5]<-3#
tru.est[i,6]<-1#
#
myrates <- exp(tru.est[i,1]+(tru.est[i,2]*x)) #
y <- rexp(n, rate = myrates) # generates the r.v.#
cen <- rexp(n, rate = 1 )#
ycen <- pmin(y, cen)#
di <- as.numeric(y <= cen)#
tru.est[i,7]<-table(di)[1]#
#
#create parameters for ZG#
phi<-1/(1+exp(-(tru.est[i,3]+tru.est[i,4]*z+tru.est[i,5]*x)))#
print(mean(phi))#
yzero<-matrix(1,n,1)#
error<--1*rlogis(n)#
flag<-error<qlogis(phi)#
yzero[flag]<-error[flag]#
flag<-yzero==1#
di[flag]<-ifelse(di[flag]==0,yzero[flag],di[flag])#
tru.est[i,8]<-table(di)[1]#
#
data<-cbind(ycen,di,x,z)#
######################################################################################
###################################COX Model##########################################
######################################################################################
#
#store estimate and se#
cox.est[i,1]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[1]#
cox.est[i,2]<-summary(coxph(Surv(ycen, di)~x,coxph.control(iter.max = 10000)))$coef[3]#
#
#store rmse#
cox.rmse[i,1]<-sqrt((tru.est[i,2]-cox.est[i,1])^2)#
#
#calculate upper and lower 95% CI's#
b1.lower<-cox.est[i,1]-(1.959964*cox.est[i,2])#
b1.upper<-cox.est[i,1]+(1.959964*cox.est[i,2])#
#
#store coverage parameters#
cox.cp[i,1]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
##############################################################################
########################Simple Exponential Model##############################
##############################################################################
Exponential<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)]#
	XB<-X%*%beta#
	llik<-C*(XB-exp(XB)*Y)+(1-C)*(-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Exponential<-try(optim(f=Exponential,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Exponential)=="list"){#
	ifelse(is.positive.definite(output.Exponential$hessian)==TRUE,vcv<-solve(output.Exponential$hessian),vcv<-matrix(data=NA,nrow=2,ncol=2))#
#
#store betas and ses#
exp.est[i,1]<-output.Exponential$par[1]#
exp.est[i,2]<-sqrt(vcv[1,1])#
exp.est[i,3]<-output.Exponential$par[2]#
exp.est[i,4]<-sqrt(vcv[2,2])#
#
#store rmse#
exp.rmse[i,1]<-sqrt((tru.est[i,1]-exp.est[i,1])^2)#
exp.rmse[i,2]<-sqrt((tru.est[i,2]-exp.est[i,3])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-exp.est[i,1]-(1.959964*exp.est[i,2])#
b0.upper<-exp.est[i,1]+(1.959964*exp.est[i,2])#
b1.lower<-exp.est[i,3]-(1.959964*exp.est[i,4])#
b1.upper<-exp.est[i,3]+(1.959964*exp.est[i,4])#
#store coverage parameters#
exp.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
#################################################################################
#########################Simple Weibull Model ###################################
#################################################################################
#
#Note this estiamtes the model via hazard rates, a la Stata#
#
test<-survreg(Surv(ycen, di)~x, dist="weibull")#
summary(test)#
Weibull<- function(est,Y,C,X,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	beta<-est[1:length(est)-1]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	llik<-C*(log(exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*log(exp(-(exp(XB+1/p)*Y)^p))#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(exp.est[i,1],exp.est[i,3],.01)#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
#optimize#
output.Weibull<-try(optim(f=Weibull,  p=est, X=X,Y=Y,C=C, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.Weibull)=="list"){#
	ifelse(is.positive.definite(output.Weibull$hessian)==TRUE,vcv<-solve(output.Weibull$hessian),vcv<-matrix(data=NA,nrow=3,ncol=3))#
#
#store betas and ses#
weib.est[i,1]<-output.Weibull$par[1]+1/exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,1],output.Weibull$par[3])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,3]#
varcov[2,1]<-vcv[3,1]#
varcov[2,2]<-vcv[3,3]#
weib.est[i,2]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,3]<-output.Weibull$par[2]#
weib.est[i,4]<-sqrt(vcv[2,2])#
weib.est[i,5]<-exp(output.Weibull$par[3])#
coeff<-c(weib.est[i,5])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[3,3]#
weib.est[i,6]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,1]<-sqrt((tru.est[i,1]-weib.est[i,1])^2)#
weib.rmse[i,2]<-sqrt((tru.est[i,2]-weib.est[i,3])^2)#
weib.rmse[i,3]<-sqrt((tru.est[i,6]-weib.est[i,5])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-weib.est[i,1]-(1.959964*weib.est[i,2])#
b0.upper<-weib.est[i,1]+(1.959964*weib.est[i,2])#
b1.lower<-weib.est[i,3]-(1.959964*weib.est[i,4])#
b1.upper<-weib.est[i,3]+(1.959964*weib.est[i,4])#
p.lower<-weib.est[i,5]-(1.959964*weib.est[i,6])#
p.upper<-weib.est[i,5]+(1.959964*weib.est[i,6])#
#
#store coverage parameters#
weib.cp[i,1]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,2]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,3]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
}#
#
###logit estimates####
dataset<-as.data.frame(data)#
logitcoef1<-glm(di~ z+x, data = dataset, family = "binomial")$coef[1]#
logitcoef2<-glm(di~ z+x, data = dataset, family = "binomial")$coef[2]#
logitcoef3<-glm(di~ z+x, data = dataset, family = "binomial")$coef[3]#
#
################################################################################
##########################Zombie Exponential Model##############################
################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZExponential<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):length(est)]#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-ZG))#
	llik<-C*(log((1-phi)+phi*exp(XB)*exp(-exp(XB)*Y)))+(1-C)*(log(phi)+-exp(XB)*Y)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,exp.est[i,1],exp.est[i,3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZExponential<-try(optim(f=ZExponential,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZExponential)=="list"){#
	ifelse(is.positive.definite(output.ZExponential$hessian)==TRUE,vcv<-solve(output.ZExponential$hessian),vcv<-matrix(data=NA,nrow=5,ncol=5))#
#
#store betas and ses#
exp.est[i,5]<-output.ZExponential$par[1]#
exp.est[i,6]<-sqrt(vcv[1,1])#
exp.est[i,7]<-output.ZExponential$par[2]#
exp.est[i,8]<-sqrt(vcv[2,2])#
exp.est[i,9]<-output.ZExponential$par[3]#
exp.est[i,10]<-sqrt(vcv[3,3])#
exp.est[i,11]<-output.ZExponential$par[4]#
exp.est[i,12]<-sqrt(vcv[4,4])#
exp.est[i,13]<-output.ZExponential$par[5]#
exp.est[i,14]<-sqrt(vcv[5,5])#
#
#store rmse#
exp.rmse[i,3]<-sqrt((tru.est[i,3]-exp.est[i,5])^2)#
exp.rmse[i,4]<-sqrt((tru.est[i,4]-exp.est[i,7])^2)#
exp.rmse[i,5]<-sqrt((tru.est[i,5]-exp.est[i,9])^2)#
exp.rmse[i,6]<-sqrt((tru.est[i,1]-exp.est[i,11])^2)#
exp.rmse[i,7]<-sqrt((tru.est[i,2]-exp.est[i,13])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-exp.est[i,5]-(1.959964*exp.est[i,6])#
g0.upper<-exp.est[i,5]+(1.959964*exp.est[i,6])#
g1.lower<-exp.est[i,7]-(1.959964*exp.est[i,8])#
g1.upper<-exp.est[i,7]+(1.959964*exp.est[i,8])#
g2.lower<-exp.est[i,9]-(1.959964*exp.est[i,10])#
g2.upper<-exp.est[i,9]+(1.959964*exp.est[i,10])#
b0.lower<-exp.est[i,11]-(1.959964*exp.est[i,12])#
b0.upper<-exp.est[i,11]+(1.959964*exp.est[i,12])#
b1.lower<-exp.est[i,13]-(1.959964*exp.est[i,14])#
b1.upper<-exp.est[i,13]+(1.959964*exp.est[i,14])#
#store coverage parameters#
exp.cp[i,3]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,4]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,5]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,6]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,7]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
}#
#
######################################################################################
##########################Zombie Weibull Model #######################################
######################################################################################
#This program estimates the Exponential loglikelihood function returning hazard rate form coefficients#
#
ZWeibull<- function(est,Y,C,X,Z,data) {					      #
	n=nrow(data)							      					  #
	llik <- matrix(0, nrow=n, ncol = 1)#
	gamma<-est[1:ncol(Z)]#
	beta<-est[(ncol(Z)+1):(length(est)-1)]#
	p<-est[length(est)]#
	p<-exp(p)#
	XB<-X%*%beta#
	ZG<-Z%*%gamma#
	phi<-1/(1+exp(-(ZG+1/p)))#
	llik<-C*(log((1-phi)+phi*exp(XB+1/p)*p*((exp(XB+1/p)*Y)^(p-1))*exp(-(exp(XB+1/p)*Y)^p)))+(1-C)*(log(phi)+-(exp(XB+1/p)*Y)^p)#
	llik<--1*sum(llik)#
	return(llik)#
	}#
#set starting parameters#
est<-rbind(.01,.01,.01,output.Weibull$par[1],output.Weibull$par[2],output.Weibull$par[3])#
#
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
#optimize#
output.ZWeibull<-try(optim(f=ZWeibull,  p=est, X=X,Y=Y,C=C,Z=Z, method="BFGS", control=list(maxit=10000),  data=data, hessian=TRUE), TRUE)#
#
if(class(output.ZWeibull)=="list"){#
	ifelse(is.positive.definite(output.ZWeibull$hessian)==TRUE,vcv<-solve(output.ZWeibull$hessian),vcv<-matrix(data=NA,nrow=6,ncol=6))#
#
#store betas and ses#
weib.est[i,7]<-output.ZWeibull$par[1]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,7],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[1,1]#
varcov[1,2]<-vcv[1,6]#
varcov[2,1]<-vcv[6,1]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,8]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,9]<-output.ZWeibull$par[2]#
weib.est[i,10]<-sqrt(vcv[2,2])#
weib.est[i,11]<-output.ZWeibull$par[3]#
weib.est[i,12]<-sqrt(vcv[3,3])#
weib.est[i,13]<-output.ZWeibull$par[4]+1/exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,13],output.ZWeibull$par[6])#
varcov<-matrix(NA,2,2)#
varcov[1,1]<-vcv[4,4]#
varcov[1,2]<-vcv[4,6]#
varcov[2,1]<-vcv[6,4]#
varcov[2,2]<-vcv[6,6]#
weib.est[i,14]<-deltamethod(~(x1+1/exp(x2)), coeff, varcov, ses=TRUE)#
weib.est[i,15]<-output.ZWeibull$par[5]#
weib.est[i,16]<-sqrt(vcv[5,5])#
weib.est[i,17]<-exp(output.ZWeibull$par[6])#
coeff<-c(weib.est[i,17])#
varcov<-matrix(NA,1,1)#
varcov[1,1]<-vcv[6,6]#
weib.est[i,18]<-deltamethod(~(exp(x1)), coeff, varcov, ses=TRUE)#
#store rmse#
weib.rmse[i,4]<-sqrt((tru.est[i,3]-weib.est[i,7])^2)#
weib.rmse[i,5]<-sqrt((tru.est[i,4]-weib.est[i,9])^2)#
weib.rmse[i,6]<-sqrt((tru.est[i,5]-weib.est[i,11])^2)#
weib.rmse[i,7]<-sqrt((tru.est[i,1]-weib.est[i,13])^2)#
weib.rmse[i,8]<-sqrt((tru.est[i,2]-weib.est[i,15])^2)#
weib.rmse[i,9]<-sqrt((tru.est[i,6]-weib.est[i,17])^2)#
#
#calculate upper and lower 95% CI's#
g0.lower<-weib.est[i,7]-(1.959964*weib.est[i,8])#
g0.upper<-weib.est[i,7]+(1.959964*weib.est[i,8])#
g1.lower<-weib.est[i,9]-(1.959964*weib.est[i,10])#
g1.upper<-weib.est[i,9]+(1.959964*weib.est[i,10])#
g2.lower<-weib.est[i,11]-(1.959964*weib.est[i,12])#
g2.upper<-weib.est[i,11]+(1.959964*weib.est[i,12])#
b0.lower<-weib.est[i,13]-(1.959964*weib.est[i,14])#
b0.upper<-weib.est[i,13]+(1.959964*weib.est[i,14])#
b1.lower<-weib.est[i,15]-(1.959964*weib.est[i,16])#
b1.upper<-weib.est[i,15]+(1.959964*weib.est[i,16])#
p.lower<-weib.est[i,17]-(1.959964*weib.est[i,18])#
p.upper<-weib.est[i,17]+(1.959964*weib.est[i,18])#
#
#store coverage parameters#
weib.cp[i,4]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,5]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,6]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,7]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,8]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,9]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
}#
################################################################################
######################Bayesian Zombie Exponential Model#########################
################################################################################
##set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZExponential = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Exponential")#
output.BayesZExponential = list(par = c(summary(mcmc(BayesZExponential$beta))[[1]][,1], summary(mcmc(BayesZExponential$gamma))[[1]][,1]), #
                                se = c(summary(mcmc(BayesZExponential$beta))[[1]][,4], summary(mcmc(BayesZExponential$gamma))[[1]][,4]),#
                                CI = rbind(summary(mcmc(BayesZExponential$beta))[[2]], summary(mcmc(BayesZExponential$gamma))[[2]]))#
exp.est[i,15]<-output.BayesZExponential$par[1]#
exp.est[i,16]<-output.BayesZExponential$se[1]#
exp.est[i,17]<-output.BayesZExponential$par[2]#
exp.est[i,18]<-output.BayesZExponential$se[2]#
exp.est[i,19]<-output.BayesZExponential$par[3]#
exp.est[i,20]<-output.BayesZExponential$se[3]#
exp.est[i,21]<-output.BayesZExponential$par[4]#
exp.est[i,22]<-output.BayesZExponential$se[4]#
exp.est[i,23]<-output.BayesZExponential$par[5]#
exp.est[i,24]<-output.BayesZExponential$se[5]#
#
##store rmse#
exp.rmse[i,8]<-sqrt((tru.est[i,1]-exp.est[i,15])^2)#
exp.rmse[i,9]<-sqrt((tru.est[i,2]-exp.est[i,17])^2)#
exp.rmse[i,10]<-sqrt((tru.est[i,3]-exp.est[i,19])^2)#
exp.rmse[i,11]<-sqrt((tru.est[i,4]-exp.est[i,21])^2)#
exp.rmse[i,12]<-sqrt((tru.est[i,5]-exp.est[i,23])^2)#
##calculate upper and lower 95% CI's#
b0.lower<-output.BayesZExponential$CI[1,1]#
b0.upper<-output.BayesZExponential$CI[1,5]#
b1.lower<-output.BayesZExponential$CI[2,1]#
b1.upper<-output.BayesZExponential$CI[2,5]#
g0.lower<-output.BayesZExponential$CI[3,1]#
g0.upper<-output.BayesZExponential$CI[3,5]#
g1.lower<-output.BayesZExponential$CI[4,1]#
g1.upper<-output.BayesZExponential$CI[4,5]#
g2.lower<-output.BayesZExponential$CI[5,1]#
g2.upper<-output.BayesZExponential$CI[5,5]#
#b0.lower<-exp.est[i,15]-(1.959964*exp.est[i,16])#
#b0.upper<-exp.est[i,15]+(1.959964*exp.est[i,16])#
#b1.lower<-exp.est[i,17]-(1.959964*exp.est[i,18])#
#b1.upper<-exp.est[i,17]+(1.959964*exp.est[i,18])#
#g0.lower<-exp.est[i,19]-(1.959964*exp.est[i,20])#
#g0.upper<-exp.est[i,19]+(1.959964*exp.est[i,20])#
#g1.lower<-exp.est[i,21]-(1.959964*exp.est[i,22])#
#g1.upper<-exp.est[i,21]+(1.959964*exp.est[i,22])#
#g2.lower<-exp.est[i,23]-(1.959964*exp.est[i,24])#
#g2.upper<-exp.est[i,23]+(1.959964*exp.est[i,24])#
#store coverage parameters#
exp.cp[i,8]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
exp.cp[i,9]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
exp.cp[i,10]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
exp.cp[i,11]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
exp.cp[i,12]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
#
################################################################################
########################Bayesian Zombie Weibull Model###########################
################################################################################
#set data, Y and X#
data<-data#
Y<-ycen#
C<-di#
X<-cbind(1,x)#
Z<-cbind(1,z,x)#
BayesZWeibull = mcmcOF2(Y, C, X, Z, N = 400, burn = 100, thin = 1,  w = c(5, 5, 5), m = 100, form = "Weibull")#
output.BayesZWeibull = list(par = c(summary(mcmc(BayesZWeibull$beta))[[1]][,1], summary(mcmc(BayesZWeibull$gamma))[[1]][,1], #
                                    summary(mcmc(BayesZWeibull$lambda))[[1]][1]), #
                            se = c(summary(mcmc(BayesZWeibull$beta))[[1]][,4], summary(mcmc(BayesZWeibull$gamma))[[1]][,4], #
                                   summary(mcmc(BayesZWeibull$lambda))[[1]][4]),#
                            CI = rbind(summary(mcmc(BayesZWeibull$beta))[[2]], summary(mcmc(BayesZWeibull$gamma))[[2]], #
                                       summary(mcmc(BayesZWeibull$lambda))[[2]]))#
weib.est[i,19]<-output.BayesZWeibull$par[1]#
weib.est[i,20]<-output.BayesZWeibull$se[1]#
weib.est[i,21]<-output.BayesZWeibull$par[2]#
weib.est[i,22]<-output.BayesZWeibull$se[2]#
weib.est[i,23]<-output.BayesZWeibull$par[3]#
weib.est[i,24]<-output.BayesZWeibull$se[3]#
weib.est[i,25]<-output.BayesZWeibull$par[4]#
weib.est[i,26]<-output.BayesZWeibull$se[4]#
weib.est[i,27]<-output.BayesZWeibull$par[5]#
weib.est[i,28]<-output.BayesZWeibull$se[5]#
weib.est[i,29]<-output.BayesZWeibull$par[6]#
weib.est[i,30]<-output.BayesZWeibull$se[6]#
#
#store rmse#
weib.rmse[i,10]<-sqrt((tru.est[i,1]-weib.est[i,19])^2)#
weib.rmse[i,11]<-sqrt((tru.est[i,2]-weib.est[i,21])^2)#
weib.rmse[i,12]<-sqrt((tru.est[i,3]-weib.est[i,23])^2)#
weib.rmse[i,13]<-sqrt((tru.est[i,4]-weib.est[i,25])^2)#
weib.rmse[i,14]<-sqrt((tru.est[i,5]-weib.est[i,27])^2)#
weib.rmse[i,15]<-sqrt((tru.est[i,6]-weib.est[i,29])^2)#
#
#calculate upper and lower 95% CI's#
b0.lower<-output.BayesZWeibull$CI[1,1]#
b0.upper<-output.BayesZWeibull$CI[1,5]#
b1.lower<-output.BayesZWeibull$CI[2,1]#
b1.upper<-output.BayesZWeibull$CI[2,5]#
g0.lower<-output.BayesZWeibull$CI[3,1]#
g0.upper<-output.BayesZWeibull$CI[3,5]#
g1.lower<-output.BayesZWeibull$CI[4,1]#
g1.upper<-output.BayesZWeibull$CI[4,5]#
g2.lower<-output.BayesZWeibull$CI[5,1]#
g2.upper<-output.BayesZWeibull$CI[5,5]#
p.lower<-output.BayesZWeibull$CI[6,1]#
p.upper<-output.BayesZWeibull$CI[6,2]#
# g0.lower<-weib.est[i,19]-(1.959964*weib.est[i,20])#
# g0.upper<-weib.est[i,19]+(1.959964*weib.est[i,20])#
# g1.lower<-weib.est[i,21]-(1.959964*weib.est[i,22])#
# g1.upper<-weib.est[i,21]+(1.959964*weib.est[i,22])#
# g2.lower<-weib.est[i,23]-(1.959964*weib.est[i,24])#
# g2.upper<-weib.est[i,23]+(1.959964*weib.est[i,24])#
# b0.lower<-weib.est[i,25]-(1.959964*weib.est[i,26])#
# b0.upper<-weib.est[i,25]+(1.959964*weib.est[i,26])#
# b1.lower<-weib.est[i,27]-(1.959964*weib.est[i,28])#
# b1.upper<-weib.est[i,27]+(1.959964*weib.est[i,28])#
# p.lower<-weib.est[i,29]-(1.959964*weib.est[i,30])#
# p.upper<-weib.est[i,29]+(1.959964*weib.est[i,30])#
#
#store coverage parameters#
weib.cp[i,10]<-ifelse(tru.est[i,3]>g0.lower & tru.est[i,3]<g0.upper, 1,0)#
weib.cp[i,11]<-ifelse(tru.est[i,4]>g1.lower & tru.est[i,4]<g1.upper, 1,0)#
weib.cp[i,12]<-ifelse(tru.est[i,5]>g2.lower & tru.est[i,5]<g2.upper, 1,0)#
weib.cp[i,13]<-ifelse(tru.est[i,1]>b0.lower & tru.est[i,1]<b0.upper, 1,0)#
weib.cp[i,14]<-ifelse(tru.est[i,2]>b1.lower & tru.est[i,2]<b1.upper, 1,0)#
weib.cp[i,15]<-ifelse(tru.est[i,6]>p.lower & tru.est[i,6]<p.upper, 1,0)#
#
#combine matrices and label variables#
main.data[i, ]<-c(tru.est[i, ],cox.est[i, ],exp.est[i, ],weib.est[i, ],cox.rmse[i, ],exp.rmse[i, ],weib.rmse[i, ],#
                  cox.cp[i, ],exp.cp[i, ],weib.cp[i, ])#
#
}
colMeans(main.data[1:10,])
mcmcOF2
betas.post2
